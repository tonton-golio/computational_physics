{
  "meta": {
    "generatedAt": "2026-02-17T19:49:05.434981+00:00",
    "embeddingModel": "text-embedding-3-small",
    "projection": "tsne-2d",
    "inputCount": 105,
    "perplexity": 17
  },
  "topics": [
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning"
    },
    {
      "topicId": "applied-machine-learning",
      "topicTitle": "Applied Machine Learning"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models"
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing"
    }
  ],
  "points": [
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "analysis-and-theory",
      "lessonTitle": "Analysis and Theory of Deep Learning",
      "x": 0.2605413794517517,
      "y": 0.191894069314003,
      "searchText": "analysis and theory of deep learning\n# analysis and theory of deep learning\n\n## the puzzle of generalization\n\nclassical learning theory predicts that models with more parameters than training examples should overfit catastrophically. yet deep networks with millions of parameters generalize well even when they can perfectly memorize the training data. understanding this contradiction is a central challenge in deep learning theory.\n\n## generalization bounds\n\n**pac-bayes bounds** provide some of the tightest generalization guarantees for neural networks. for a posterior distribution $q$ over hypotheses and a prior $p$:\n\n$$\n\\mathbb{e}_{h \\sim q}[\\mathcal{l}(h)] \\leq \\mathbb{e}_{h \\sim q}[\\hat{\\mathcal{l}}(h)] + \\sqrt{\\frac{d_{\\text{kl}}(q \\| p) + \\ln(n/\\delta)}{2n}},\n$$\n\nwhere $\\hat{\\mathcal{l}}$ is the empirical loss, $n$ is the number of training examples, and $\\delta$ is the failure probability. the bound favors posteriors that are both accurate and close to the prior.\n\n**rademacher complexity** measures the ability of a function class to fit random labels:\n\n$$\n\\mathcal{r}_n(\\mathcal{f}) = \\mathbb{e}\\left[\\sup_{f \\in \\mathcal{f}} \\frac{1}{n} \\sum_{i=1}^{n} \\sigma_i f(x_i)\\right],\n$$\n\nwhere $\\sigma_i \\in \\{-1, +1\\}$ are random signs. lower rademacher complexity implies better generalization.\n\n## double descent\n\nthe **double descent** phenomenon (belkin et al., 2019) shows that the test error follows a u-shaped curve in the underparameterized regime, peaks at the interpolation threshold (where the model just fits the training data exactly), and then *decreases again* as the model becomes increasingly overparameterized.\n\nthis challenges the classical bias-variance trade-off and suggests that overparameterization acts as an implicit regularizer. the phenomenon has been observed in:\n\n- model-wise double descent: varying the number of parameters.\n- epoch-wise double descent: varying training time.\n- sample-wise double descent: varying the number of training examples.\n\n## the neural tangent kernel (ntk)\n\nin the **infinite-width limit**, a neural network trained with gradient descent behaves like kernel regression with a fixed kernel called the **neural tangent kernel**:\n\n$$\n\\theta(\\mathbf{x}, \\mathbf{x}') = \\left\\langle \\nabla_\\theta f(\\mathbf{x}; \\theta_0), \\, \\nabla_\\theta f(\\mathbf{x}'; \\theta_0) \\right\\rangle,\n$$\n\nwhere $\\theta_0$ are the initial parameters. in this regime:\n\n- the ntk remains approximately constant during training (**lazy training**).\n- training dynamics become linear, and convergence to a global minimum is guaranteed.\n- the trained network is equivalent to kernel ridge regression with the ntk.\n\n**limitations**: the ntk theory describes an idealization. finite-width networks exhibit **feature learning**, where the kernel itself evolves during training. this feature learning is believed to be essential for the practical success of deep learning.\n\n## loss landscapes\n\nthe loss function of a deep network defines a high-dimensional surface over the parameter space. key properties:\n\n- **local minima vs saddle points**: in high dimensions, most critical points are saddle points rather than local minima. the loss at local minima tends to be close to the global minimum.\n- **mode connectivity**: different solutions found by sgd are often connected by paths of nearly constant loss (**linear mode connectivity**).\n- **sharpness and generalization**: flatter minima tend to generalize better than sharp minima. this motivates techniques like sharpness-aware minimization (sam).\n\n[[simulation adl-pca-demo]]\n\n## adversarial robustness\n\n**adversarial examples** are imperceptibly perturbed inputs that cause confident misclassification:\n\n$$\nx_{\\text{adv}} = x + \\epsilon \\cdot \\text{sign}(\\nabla_x \\mathcal{l}(x, y; \\theta)).\n$$\n\nthis is the **fast gradient sign method** (fgsm). stronger attacks (pgd, c&w) use iterative optimization.\n\n**adversarial training** augments the training set with adversarial examples, solving:\n\n$$\n\\min_\\theta \\mathbb{e}_{(x,y)} \\left[\\max_{\\|\\delta\\| \\leq \\epsilon} \\mathcal{l}(x + \\delta, y; \\theta)\\right].\n$$\n\na fundamental trade-off exists: robustness to adversarial perturbations typically comes at the cost of reduced clean accuracy.\n\n## uncertainty quantification\n\nneural networks are often overconfident in their predictions. methods for calibrating uncertainty:\n\n- **mc dropout**: run multiple forward passes with dropout enabled; the variance across predictions estimates uncertainty.\n- **deep ensembles**: train multiple models with different initializations; disagreement indicates uncertainty.\n- **temperature scaling**: post-hoc calibration by dividing logits by a learned temperature $t$.\n- **bayesian neural networks**: place a prior over weights and perform approximate posterior inference (variational inference, mcmc).\n\n## interpretability\n\nunderstanding what deep networks learn:\n\n- **gradient-based methods** (saliency maps, grad-cam): highlight input regions that most affect the output.\n- **feature visualization**: optimize an input to maximally activate a specific neuron or layer.\n- **probing classifiers**: train simple models on intermediate representations to test what information is encoded.\n- **mechanistic interpretability**: reverse-engineer the computations performed by individual circuits within the network.\n"
    },
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "ann",
      "lessonTitle": "Artificial Neural Networks",
      "x": 0.199682354927063,
      "y": 0.09707757085561752,
      "searchText": "artificial neural networks\n# artificial neural networks\n\n## introduction\n\nto get started with artificial neural networks, we work with the **mnist dataset**. this dataset contains 28x28 grayscale images of handwritten digits (0-9), each labeled with the digit it represents.\n\n[[simulation adl-activation-functions]]\n\n## multilayer perceptron model\n\nwe load data with:\n```python\ntrain_data = datasets.mnist(root=filepath_assets+'data',\n                            train=true, download=true,\n                            transform=transforms.totensor())\n```\n\nwe then pass it into a data loader, which batches and shuffles the data for training:\n```python\ntrain_loader = torch.utils.data.dataloader(train_data, batch_size=100, shuffle=true)\n```\n\nthe **multilayer perceptron** (mlp) is a feedforward neural network consisting of an input layer, one or more hidden layers, and an output layer:\n```python\nclass multilayerperceptron(nn.module):\n    def __init__(self, in_sz=784, out_sz=10, layers=[120, 84]):\n        super().__init__()\n        self.fc1 = nn.linear(in_sz, layers[0])\n        self.fc2 = nn.linear(layers[0], layers[1])\n        self.out = nn.linear(layers[1], out_sz)\n\n    def forward(self, x):\n        x = f.relu(self.fc1(x))\n        x = f.relu(self.fc2(x))\n        x = self.out(x)\n        return f.log_softmax(x, dim=1)\n```\n\nwe then instantiate the model, define the loss function and optimizer:\n```python\nmodel = multilayerperceptron()\ncriterion = nn.crossentropyloss()\noptimizer = torch.optim.adam(model.parameters(), lr=0.001)\n```\n\n## training and evaluation\n\nwe train the model by iterating over batches, computing the loss, and updating parameters via backpropagation. the training loop tracks loss and accuracy over epochs.\n"
    },
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "cnn",
      "lessonTitle": "Convolutional Neural Networks",
      "x": 0.20728151500225067,
      "y": 0.06918521225452423,
      "searchText": "convolutional neural networks\n# convolutional neural networks\n\n## introduction\n\n**convolutional neural networks** (cnns) are better suited for image recognition than fully connected networks because they exploit spatial structure and recognize patterns at multiple scales.\n\n[[simulation adl-convolution-demo]]\n\n## kernel types\n\nwe may choose from a variety of convolution kernels:\n- **averaging**: `np.ones(k,k)/k**2` (simple blur)\n- **gaussian blur**: weighted average with gaussian falloff\n- **dilated (atrous) convolution**: expands the receptive field without increasing parameters\n\n## cnn model\n\n```python\nclass convolutionalnetwork(nn.module):\n    '''\n    architecture:\n    - convolutional layer -> max pooling\n    - convolutional layer -> max pooling\n    - fully connected layer -> output layer\n\n    takes a 28x28 image and outputs a 10-dim vector of logits.\n    '''\n    def __init__(self, im_shape=(1, 28, 28), n_classes=10, batch_size=100):\n        super().__init__()\n        self.batch_size = batch_size\n        self.im_shape = im_shape\n        self.n_classes = n_classes\n\n        self.conv1 = nn.conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.linear(in_features=8*7*7, out_features=32)\n        self.fc2 = nn.linear(in_features=32, out_features=10)\n\n    def forward(self, x):\n        x = f.relu(self.conv1(x))\n        x = f.max_pool2d(x, kernel_size=2, stride=2)\n        x = f.relu(self.conv2(x))\n        x = f.max_pool2d(x, kernel_size=2, stride=2)\n        x = x.view(-1, 8*7*7)\n        x = f.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```\n\n## evaluation\n\nthe cnn achieves approximately 97.5% accuracy on the mnist test set, with a network about 1/8th the size of the fully connected mlp (which achieved 95.5%). this demonstrates the efficiency of exploiting spatial structure through convolutions.\n"
    },
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "design-and-optimization",
      "lessonTitle": "Design and Optimization of Deep Learning",
      "x": 0.24708148837089539,
      "y": 0.1717764288187027,
      "searchText": "design and optimization of deep learning\n# design and optimization of deep learning\n\n## optimization algorithms\n\ntraining a deep network means minimizing a loss function $\\mathcal{l}(\\theta)$ over parameters $\\theta$. the choice of optimizer profoundly affects convergence speed and final performance.\n\n**stochastic gradient descent** (sgd) updates parameters using a mini-batch gradient estimate:\n\n$$\n\\theta_{t+1} = \\theta_t - \\eta \\, \\hat{g}_t, \\qquad \\hat{g}_t = \\frac{1}{|b|} \\sum_{i \\in b} \\nabla_\\theta \\mathcal{l}_i(\\theta_t).\n$$\n\n**sgd with momentum** accumulates a velocity term that smooths oscillations:\n\n$$\nv_{t+1} = \\mu v_t + \\hat{g}_t, \\qquad \\theta_{t+1} = \\theta_t - \\eta v_{t+1}.\n$$\n\n## adaptive learning rate methods\n\n**adam** (kingma and ba, 2015) combines momentum with per-parameter adaptive learning rates:\n\n$$\nm_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t, \\qquad v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2,\n$$\n\n$$\n\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\qquad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}, \\qquad \\theta_{t+1} = \\theta_t - \\frac{\\eta \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}.\n$$\n\ndefault hyperparameters: $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, $\\epsilon = 10^{-8}$.\n\n**variants**:\n\n- **adamw**: decouples weight decay from the gradient update, which improves generalization.\n- **lamb**: layer-wise adaptive learning rates for large-batch training.\n- **adafactor**: memory-efficient by factorizing the second-moment matrix.\n\n## learning rate schedules\n\nthe learning rate $\\eta$ often varies during training:\n\n- **step decay**: reduce $\\eta$ by a factor at specified epochs.\n- **cosine annealing**: $\\eta_t = \\eta_{\\min} + \\frac{1}{2}(\\eta_{\\max} - \\eta_{\\min})(1 + \\cos(\\pi t / t))$.\n- **warmup**: linearly increase $\\eta$ from zero over the first few thousand steps to stabilize early training.\n- **one-cycle policy**: warmup then cosine decay; often yields faster convergence.\n\n## regularization techniques\n\n**dropout** (srivastava et al., 2014) randomly sets each hidden unit to zero with probability $p$ during training. at test time, weights are scaled by $(1-p)$. dropout acts as an implicit ensemble over exponentially many sub-networks.\n\n**batch normalization** (ioffe and szegedy, 2015) normalizes activations within each mini-batch:\n\n$$\n\\hat{x}_i = \\frac{x_i - \\mu_b}{\\sqrt{\\sigma_b^2 + \\epsilon}}, \\qquad y_i = \\gamma \\hat{x}_i + \\beta,\n$$\n\nwhere $\\mu_b$ and $\\sigma_b^2$ are the batch mean and variance, and $\\gamma, \\beta$ are learnable parameters. benefits include smoother loss landscapes, faster training, and reduced sensitivity to initialization.\n\n**layer normalization** normalizes across features instead of across the batch, making it suitable for transformers and variable-length sequences.\n\n**data augmentation** enlarges the effective training set through transformations (rotations, crops, color jitter, mixup). for images, augmentation is one of the most effective regularizers.\n\n**weight decay** adds an $l_2$ penalty $\\lambda \\|\\theta\\|^2$ to the loss, shrinking parameters toward zero and discouraging overfitting.\n\n[[simulation adl-activation-functions]]\n\n## hyperparameter tuning\n\nsystematic approaches to finding good hyperparameters:\n\n- **grid search**: exhaustive but exponentially expensive.\n- **random search** (bergstra and bengio, 2012): samples hyperparameters randomly; often more efficient than grid search because not all hyperparameters are equally important.\n- **bayesian optimization**: builds a surrogate model (e.g., gaussian process) of the validation loss and selects the next hyperparameters to maximize expected improvement.\n- **population-based training**: combines random search with online adaptation by periodically replacing poorly performing configurations with perturbed copies of better ones.\n\n## initialization\n\nproper weight initialization prevents vanishing or exploding gradients:\n\n- **xavier/glorot**: $w \\sim \\mathcal{n}(0, 2/(n_{\\text{in}} + n_{\\text{out}}))$. designed for linear or sigmoid activations.\n- **he/kaiming**: $w \\sim \\mathcal{n}(0, 2/n_{\\text{in}})$. designed for relu activations.\n\nthe goal is to keep the variance of activations and gradients approximately constant across layers.\n"
    },
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "gan",
      "lessonTitle": "Generative Adversarial Networks",
      "x": 0.3367373049259186,
      "y": 0.07330182194709778,
      "searchText": "generative adversarial networks\n# generative adversarial networks\n\n## the adversarial framework\n\na **generative adversarial network** (gan) consists of two neural networks trained in opposition. the **generator** $g$ maps random noise $\\mathbf{z} \\sim p_z(\\mathbf{z})$ to synthetic data $g(\\mathbf{z})$, while the **discriminator** $d$ tries to distinguish real data from generated samples. training proceeds as a minimax game:\n\n$$\n\\min_g \\max_d \\; \\mathbb{e}_{\\mathbf{x} \\sim p_{\\text{data}}}[\\log d(\\mathbf{x})] + \\mathbb{e}_{\\mathbf{z} \\sim p_z}[\\log(1 - d(g(\\mathbf{z})))].\n$$\n\nat the nash equilibrium, the generator produces samples indistinguishable from real data, and the discriminator outputs $d(\\mathbf{x}) = 1/2$ everywhere. in practice, training alternates between updating $d$ (to better classify real vs. fake) and updating $g$ (to better fool $d$).\n\n## architecture\n\na basic gan for image generation uses:\n\n- **generator**: takes a latent vector $\\mathbf{z} \\in \\mathbb{r}^{d}$ (typically $d = 100$) and maps it through fully connected or transposed convolutional layers to produce an image. batch normalization and relu activations are standard in intermediate layers, with a tanh output.\n\n- **discriminator**: takes an image and outputs a single scalar (real/fake probability) through convolutional layers with leakyrelu activations and a sigmoid output.\n\n**dcgan** (deep convolutional gan) established key architectural guidelines: replace pooling with strided convolutions, use batch normalization in both networks, remove fully connected hidden layers, and use relu in the generator but leakyrelu in the discriminator.\n\n## training challenges\n\ngan training is notoriously unstable due to several failure modes:\n\n- **mode collapse**: the generator produces only a few distinct outputs, ignoring the diversity of the training distribution. the discriminator may oscillate between rejecting and accepting these modes.\n\n- **vanishing gradients**: if the discriminator becomes too strong, $d(g(\\mathbf{z})) \\approx 0$ and the gradient of $\\log(1 - d(g(\\mathbf{z})))$ vanishes, stalling generator learning. a practical fix is to train $g$ to maximize $\\log d(g(\\mathbf{z}))$ instead.\n\n- **training instability**: the two-player game may not converge, with loss oscillating rather than decreasing. techniques like label smoothing, gradient penalty, and careful learning rate tuning help stabilize training.\n\n## improved loss functions\n\n**wasserstein gan** (wgan) replaces the js divergence implicit in the original loss with the earth mover distance. the discriminator (called a \"critic\") outputs an unbounded score, and the loss becomes\n\n$$\n\\min_g \\max_{d \\in \\mathcal{d}} \\; \\mathbb{e}_{\\mathbf{x}}[d(\\mathbf{x})] - \\mathbb{e}_{\\mathbf{z}}[d(g(\\mathbf{z}))],\n$$\n\nwhere $\\mathcal{d}$ is the set of 1-lipschitz functions. the lipschitz constraint is enforced via **gradient penalty** (wgan-gp):\n\n$$\n\\lambda \\, \\mathbb{e}_{\\hat{\\mathbf{x}}}[(\\|\\nabla_{\\hat{\\mathbf{x}}} d(\\hat{\\mathbf{x}})\\|_2 - 1)^2],\n$$\n\nwhere $\\hat{\\mathbf{x}}$ is interpolated between real and generated samples. wgan provides more meaningful loss curves and stable training.\n\n## conditional gans\n\n**conditional gans** (cgan) condition both generator and discriminator on additional information $\\mathbf{y}$ (e.g., class labels):\n\n$$\n\\min_g \\max_d \\; \\mathbb{e}_{\\mathbf{x}}[\\log d(\\mathbf{x}, \\mathbf{y})] + \\mathbb{e}_{\\mathbf{z}}[\\log(1 - d(g(\\mathbf{z}, \\mathbf{y}), \\mathbf{y}))].\n$$\n\nthis enables controlled generation: producing images of a specific digit, translating between image domains (pix2pix), or generating data with desired physical properties.\n\n## applications\n\ngans have found applications across science and engineering:\n\n- **image synthesis**: stylegan generates photorealistic faces by controlling style at different spatial scales.\n- **data augmentation**: generating synthetic training data when real samples are scarce.\n- **super-resolution**: srgan recovers high-resolution images from low-resolution inputs.\n- **physics simulations**: fast surrogate generators for expensive monte carlo simulations in particle physics and cosmology.\n- **anomaly detection**: the discriminator score identifies out-of-distribution samples.\n\n## evaluation metrics\n\nevaluating generative models is inherently difficult since we lack ground truth for the generated distribution. common metrics include:\n\n- **frechet inception distance** (fid): measures the distance between feature distributions of real and generated images. lower is better.\n- **inception score** (is): evaluates both quality (sharp class predictions) and diversity (uniform class distribution). higher is better.\n- **visual inspection**: remains important for catching artifacts that quantitative metrics may miss.\n\n[[simulation adl-convolution-demo]]\n"
    },
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "home",
      "lessonTitle": "Advanced Deep Learning",
      "x": 0.21744519472122192,
      "y": 0.20472003519535065,
      "searchText": "advanced deep learning\n# advanced deep learning\n\n## course overview\n\nthis course covers **state-of-the-art methods** in deep learning, including modern architectures, training techniques, theoretical foundations, and open research questions. topics evolve yearly to reflect the rapidly advancing field.\n\n- architecture: from cnns and autoencoders to transformers and diffusion models.\n- design: optimization algorithms, regularization strategies, and hyperparameter tuning.\n- analysis: generalization bounds, loss landscapes, and interpretability.\n- theory: approximation theory, neural tangent kernels, and adversarial robustness.\n\n## why this topic matters\n\n- deep learning has achieved superhuman performance in vision, language, and game-playing.\n- understanding *why* these models work (and when they fail) is an active research frontier.\n- designing training procedures and architectures requires principled methodology, not just trial and error.\n- adversarial robustness and uncertainty quantification are critical for deploying models safely.\n\n## key mathematical ideas\n\n- backpropagation and automatic differentiation.\n- optimization landscapes: convexity, saddle points, and implicit regularization.\n- generalization theory: pac-bayes bounds, double descent, and overparameterization.\n- information-theoretic perspectives on representation learning.\n- attention mechanisms and self-supervised learning objectives.\n\n## prerequisites\n\n- machine learning a or equivalent introduction.\n- deep learning fundamentals: feedforward networks, cnns, backpropagation.\n- strong python and pytorch/tensorflow skills.\n- linear algebra, multivariate calculus, and probability.\n\n## recommended reading\n\n- goodfellow, bengio, and courville, *deep learning*.\n- research papers from neurips, icml, and iclr.\n- course notes announced each semester.\n\n## learning trajectory\n\nthis module covers architectures, training methodology, and theory:\n\n- artificial neural networks: mlps, activation functions, universal approximation.\n- convolutional neural networks: convolution, pooling, modern architectures (resnet, etc.).\n- autoencoders and vaes: representation learning and generative modeling.\n- generative adversarial networks: adversarial training and mode collapse.\n- u-net and image segmentation architectures.\n- transformers: attention mechanisms, bert, gpt, and vision transformers.\n- design and optimization: adam variants, learning rate schedules, regularization.\n- analysis and theory: generalization, double descent, ntk, adversarial robustness.\n"
    },
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "transformers",
      "lessonTitle": "Transformers and Attention Mechanisms",
      "x": 0.27576544880867004,
      "y": 0.1372772455215454,
      "searchText": "transformers and attention mechanisms\n# transformers and attention mechanisms\n\n## the attention mechanism\n\nthe **attention mechanism** allows a model to focus on different parts of the input when producing each element of the output. given queries $q$, keys $k$, and values $v$, **scaled dot-product attention** computes:\n\n$$\n\\text{attention}(q, k, v) = \\text{softmax}\\!\\left(\\frac{qk^t}{\\sqrt{d_k}}\\right) v,\n$$\n\nwhere $d_k$ is the dimension of the keys. the scaling factor $\\sqrt{d_k}$ prevents the dot products from growing too large, which would push the softmax into saturated regions with tiny gradients.\n\nthe attention weights $\\text{softmax}(qk^t / \\sqrt{d_k})$ form a matrix where each row sums to one, representing a learned soft alignment between query and key positions.\n\n## multi-head attention\n\nrather than computing a single attention function, the **transformer** uses multiple **attention heads** in parallel:\n\n$$\n\\text{multihead}(q, k, v) = \\text{concat}(\\text{head}_1, \\ldots, \\text{head}_h) w^o,\n$$\n\nwhere each head computes attention on a different linear projection:\n\n$$\n\\text{head}_i = \\text{attention}(q w_i^q, k w_i^k, v w_i^v).\n$$\n\ndifferent heads can learn to attend to different types of relationships (syntactic, semantic, positional).\n\n## the transformer architecture\n\nthe **transformer** (vaswani et al., 2017) replaces recurrence entirely with attention. the encoder-decoder architecture consists of:\n\n**encoder block** (repeated $n$ times):\n1. multi-head self-attention.\n2. add & layer normalization.\n3. position-wise feedforward network.\n4. add & layer normalization.\n\n**decoder block** (repeated $n$ times):\n1. masked multi-head self-attention (causal mask prevents attending to future tokens).\n2. multi-head cross-attention (attends to encoder output).\n3. position-wise feedforward network.\n4. add & layer normalization at each step.\n\n**positional encoding** injects sequence order information since attention is permutation-invariant:\n\n$$\n\\text{pe}_{(pos, 2i)} = \\sin(pos / 10000^{2i/d}), \\qquad \\text{pe}_{(pos, 2i+1)} = \\cos(pos / 10000^{2i/d}).\n$$\n\n[[simulation adl-activation-functions]]\n\n## bert: bidirectional encoder representations\n\n**bert** (devlin et al., 2019) uses only the encoder stack with two pre-training objectives:\n\n- **masked language modeling** (mlm): randomly mask 15% of input tokens and predict them from context.\n- **next sentence prediction** (nsp): predict whether two sentences are consecutive.\n\nbert's bidirectional attention allows each token to attend to both left and right context, unlike autoregressive models. fine-tuning bert on downstream tasks (classification, ner, qa) achieved state-of-the-art results across nlp benchmarks.\n\n## gpt: generative pre-trained transformer\n\n**gpt** (radford et al., 2018) uses only the decoder stack with causal (left-to-right) attention. pre-training uses autoregressive language modeling:\n\n$$\n\\mathcal{l} = -\\sum_{t} \\log p(x_t \\mid x_1, \\ldots, x_{t-1}).\n$$\n\nscaling laws (kaplan et al., 2020) showed that model performance improves predictably as a power law in model size, dataset size, and compute. this motivated the development of increasingly large models (gpt-2, gpt-3, gpt-4).\n\n## vision transformers (vit)\n\n**vision transformers** (dosovitskiy et al., 2021) apply the transformer architecture to images by:\n\n1. splitting the image into fixed-size patches (e.g., 16x16 pixels).\n2. linearly embedding each patch into a vector.\n3. adding positional embeddings.\n4. processing the sequence of patch embeddings through a standard transformer encoder.\n\nvits demonstrate that the inductive biases of cnns (translation equivariance, locality) are not strictly necessary. with sufficient data, transformers match or exceed cnn performance on image classification.\n\n[[simulation adl-convolution-demo]]\n\n## scaling laws and emergent abilities\n\nkey empirical findings about transformer scaling:\n\n- **loss scales as a power law** in model parameters $n$, dataset size $d$, and compute $c$.\n- **emergent abilities**: certain capabilities (arithmetic, chain-of-thought reasoning) appear only above a threshold model size.\n- **compute-optimal training** (chinchilla scaling): for a fixed compute budget, model size and dataset size should be scaled proportionally.\n\nthese observations have shaped modern training strategies and motivated the development of ever-larger models.\n"
    },
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "unet",
      "lessonTitle": "U-Net Model",
      "x": 0.17588070034980774,
      "y": 0.03483066335320473,
      "searchText": "u-net model\n# u-net model\n\n## introduction\n\n**u-net** is a fully convolutional network for fast image segmentation. the network takes an image as input and returns a segmentation mask of the same spatial dimensions.\n\nu-net uses an **encoder-decoder architecture with skip connections**. skip connections concatenate the output of an encoder layer with the corresponding decoder layer, preserving spatial information that would otherwise be lost during downsampling.\n\n## the model\n\n```python\nclass u_net(nn.module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.conv2d(1, 16, 3, 1, 1)\n        self.conv2 = nn.conv2d(16, 32, 3, 1, 1)\n        self.conv3 = nn.conv2d(32, 64, 3, 1, 1)\n        self.conv4 = nn.conv2d(64, 128, 3, 1, 1)\n        self.conv5 = nn.conv2d(128, 64, 3, 1, 1)\n        self.conv6 = nn.conv2d(64, 32, 3, 1, 1)\n        self.conv7 = nn.conv2d(32, 16, 3, 1, 1)\n        self.conv8 = nn.conv2d(16, 10, 3, 1, 1)\n        self.pool = nn.maxpool2d(2, 2)\n        self.up = nn.upsample(scale_factor=2, mode='bilinear', align_corners=true)\n        self.drop = nn.dropout2d(0.2)\n        self.relu = nn.relu()\n        self.softmax = nn.softmax(dim=1)\n\n    def forward(self, x):\n        # encoder\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.pool(x)\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = self.pool(x)\n        # decoder\n        x = self.relu(self.conv5(x))\n        x = self.relu(self.conv6(x))\n        x = self.up(x)\n        x = self.relu(self.conv7(x))\n        x = self.relu(self.conv8(x))\n        x = self.up(x)\n        x = self.softmax(x)\n\n        return x\n```\n"
    },
    {
      "topicId": "advanced-deep-learning",
      "topicTitle": "Advanced Deep Learning",
      "routeSlug": "advanced-deep-learning",
      "lessonSlug": "vae",
      "lessonTitle": "Variational Autoencoders",
      "x": 0.34873706102371216,
      "y": 0.13419592380523682,
      "searchText": "variational autoencoders\n# variational autoencoders\n\n## introduction\n\n**variational autoencoders** (vaes) are symmetric encoder-decoder neural networks used for data compression, dimensionality reduction, image generation, and intrinsic dimensionality estimation.\n\na standard autoencoder maps input data to a fixed-dimensional latent space through an encoder and reconstructs the input from the latent representation through a decoder. the objective is to minimize the reconstruction loss.\n\na vae extends this by adding a **probabilistic layer** to the encoder that models the probability distribution of the latent space. this regularization ensures the latent space is smooth and continuous, enabling meaningful interpolation and generation.\n\n[[simulation adl-pca-demo]]\n\n## vae model (fully connected)\n\n```python\nclass vae(nn.module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.linear(784, 400)\n        self.fc2 = nn.linear(400, 8)\n        self.fc3 = nn.linear(8, 400)\n        self.fc4 = nn.linear(400, 784)\n        self.relu = nn.relu()\n        self.sigmoid = nn.sigmoid()\n        self.fc__ = nn.linear(400, 400)\n\n    def encode(self, x):\n        h1 = self.relu(self.fc1(x))\n        h1 = self.relu(self.fc__(h1))\n        return self.fc2(h1)\n\n    def reparameterize(self, mu):\n        std = torch.exp(0.5*mu)\n        eps = torch.randn_like(std)\n        return mu + eps*std\n\n    def decode(self, z):\n        h3 = self.relu(self.fc3(z))\n        h3 = self.relu(self.fc__(h3))\n        return self.sigmoid(self.fc4(h3))\n\n    def forward(self, x):\n        mu = self.encode(x.view(-1, 784))\n        z = self.reparameterize(mu)\n        return self.decode(z), mu\n```\n\n## vae with convolutional layers\n\n```python\nclass vae_with_conv2d(nn.module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.conv2d(1, 16, 3, padding=1)\n        self.conv2 = nn.conv2d(16, 32, 3, padding=1)\n        self.conv2_ = nn.conv2d(32, 16, 3, padding=1)\n        self.conv1_ = nn.conv2d(16, 1, 3, padding=1)\n        self.flatten = nn.flatten()\n        self.fc1 = nn.linear(784, 256)\n        self.fc2 = nn.linear(256, 64)\n        self.fc3 = nn.linear(64, 16)\n        self.fc4 = nn.linear(16, 4)\n        self.fc4_ = nn.linear(2, 16)\n        self.fc3_ = nn.linear(16, 64)\n        self.fc2_ = nn.linear(64, 256)\n        self.fc1_ = nn.linear(256, 784)\n        self.relu = nn.relu()\n        self.sigmoid = nn.sigmoid()\n\n    def encode(self, x):\n        h1 = self.relu(self.conv1(x))\n        h1 = self.relu(self.conv2(h1))\n        h1 = self.relu(self.conv2_(h1))\n        h1 = self.conv1_(h1)\n        h1 = self.flatten(h1)\n        h1 = self.relu(self.fc1(h1))\n        h1 = self.relu(self.fc2(h1))\n        h1 = self.relu(self.fc3(h1))\n        return self.fc4(h1)\n\n    def reparameterize(self, mu_std):\n        std = mu_std[:, 2:]\n        mu = mu_std[:, :2]\n        eps = torch.randn_like(std)\n        return mu + eps*std\n\n    def decode(self, z):\n        h3 = self.relu(self.fc4_(z))\n        h3 = self.relu(self.fc3_(h3))\n        h3 = self.relu(self.fc2_(h3))\n        h3 = self.fc1_(h3)\n        h3 = h3.view(-1, 1, 28, 28)\n        return self.sigmoid(h3)\n\n    def forward(self, x):\n        mu_std = self.encode(x)\n        z = self.reparameterize(mu_std)\n        return self.decode(z), mu_std\n```\n\n## latent space visualization\n\nwe take a single batch, encode all images, and examine where they fall in the latent space. by mapping the latent space to 2d using pca, we can visualize how different digits cluster. selecting a point on this 2d map and decoding it produces a generated image, demonstrating the smooth interpolation property of the vae latent space.\n"
    },
    {
      "topicId": "applied-machine-learning",
      "topicTitle": "Applied Machine Learning",
      "routeSlug": "applied-machine-learning",
      "lessonSlug": "dimensionality-reduction",
      "lessonTitle": "Dimensionality Reduction",
      "x": 0.37074393033981323,
      "y": 0.20574307441711426,
      "searchText": "dimensionality reduction\n# dimensionality reduction\n\ndimensionality reduction helps us compress, denoise, and visualize high-dimensional data.\n\n## pca: linear projection\nprincipal component analysis (pca) finds orthogonal directions of maximal variance.\n\nfor centered data matrix $x$:\n$$\nc=\\frac{1}{n-1}x^\\top x,\\quad z=x v_k\n$$\nwhere columns of $v_k$ are top eigenvectors of covariance matrix $c$.\n\nuse pca for:\n- fast baseline embeddings,\n- preprocessing before downstream models,\n- explained-variance diagnostics.\n\n## t-sne: neighborhood-preserving embedding\nt-sne is a nonlinear method that preserves local neighborhoods and is useful for visual inspection of clusters. axes in t-sne plots are not directly interpretable coordinates.\n\n## umap: scalable manifold embedding\numap often preserves local structure while scaling well and can show clearer global organization than t-sne in some settings.\n\n## method selection guide\n- **need speed and linear interpretability:** pca.\n- **need detailed local clusters for visualization:** t-sne.\n- **need fast nonlinear embedding with strong practical defaults:** umap.\n\n## interactive simulations\n[[simulation aml-pca-correlated-data]]\n\n[[simulation aml-explained-variance]]\n\n[[simulation aml-tsne-umap-comparison]]\n\n## practical warnings\n- standardize features before pca in most cases.\n- t-sne/umap output can vary with seed and hyperparameters.\n- do not over-interpret apparent distances between far clusters in t-sne.\n"
    },
    {
      "topicId": "applied-machine-learning",
      "topicTitle": "Applied Machine Learning",
      "routeSlug": "applied-machine-learning",
      "lessonSlug": "generative-adversarial-networks",
      "lessonTitle": "Generative Adversarial Networks (Extension)",
      "x": 0.3362688422203064,
      "y": 0.05062684044241905,
      "searchText": "generative adversarial networks (extension)\n# generative adversarial networks (extension)\n\ngenerative adversarial networks (gans) train two models in competition:\n- a **generator** that creates synthetic samples,\n- a **discriminator** that distinguishes real from generated samples.\n\n## adversarial objective (conceptual)\n$$\n\\min_g \\max_d \\; \\mathbb{e}_{x\\sim p_{data}}[\\log d(x)] + \\mathbb{e}_{z\\sim p_z}[\\log(1-d(g(z)))]\n$$\n\nthis adversarial game encourages generated samples to match the target data distribution.\n\n## practical stability notes\n- gan training is sensitive to architecture and optimizer settings.\n- common issues: mode collapse, unstable gradients, discriminator overpowering.\n- common improvements: wasserstein objectives, gradient penalties, spectral normalization.\n\n## cross-topic ownership\ngans are covered in depth in advanced deep learning. use this page as context and transition:\n- `/topics/advanced-deep-learning/gan`\n\n## recommended use in this module\ntreat gans as a bridge from classical applied ml to modern deep generative modeling.\n"
    },
    {
      "topicId": "applied-machine-learning",
      "topicTitle": "Applied Machine Learning",
      "routeSlug": "applied-machine-learning",
      "lessonSlug": "graph-neural-networks",
      "lessonTitle": "Graph Neural Networks",
      "x": 0.26578909158706665,
      "y": 0.030970146879553795,
      "searchText": "graph neural networks\n# graph neural networks\n\ngraphs represent entities and relations directly. graph neural networks (gnns) learn on this structure without forcing data into fixed grids.\n\n## why graphs\nmany systems are relational:\n- molecules (atoms and bonds),\n- social and communication networks,\n- recommendation systems,\n- physical interaction graphs.\n\n## message passing view\na standard gnn layer aggregates neighborhood information:\n$$\nm_v^{(l+1)}=\\bigoplus_{u\\in\\mathcal{n}(v)}\\phi^{(l)}(h_v^{(l)},h_u^{(l)},e_{uv})\n$$\n$$\nh_v^{(l+1)}=\\psi^{(l)}(h_v^{(l)},m_v^{(l+1)})\n$$\n\npopular architectures include gcn, graphsage, and gat.\n\n## gcn normalization\nfor adjacency $a$:\n$$\n\\tilde{a}=a+i,\\quad\nh^{(l+1)}=\\sigma\\left(\\tilde{d}^{-1/2}\\tilde{a}\\tilde{d}^{-1/2}h^{(l)}w^{(l)}\\right)\n$$\n\n## interactive simulations\n[[simulation aml-graph-convolution-intuition]]\n\n[[simulation aml-graph-adjacency-demo]]\n\n[[simulation aml-graph-message-passing]]\n\n## practical notes\n- aggregation must be permutation-invariant.\n- deeper vanilla gcns can oversmooth node representations.\n- task formulation matters: node-level, edge-level, and graph-level objectives differ.\n"
    },
    {
      "topicId": "applied-machine-learning",
      "topicTitle": "Applied Machine Learning",
      "routeSlug": "applied-machine-learning",
      "lessonSlug": "home",
      "lessonTitle": "Applied Machine Learning",
      "x": 0.307283490896225,
      "y": 0.2706572413444519,
      "searchText": "applied machine learning\n# applied machine learning\n\napplied machine learning studies how to design models that generalize well to new data while remaining computationally practical. this module emphasizes intuition through losses, optimization, representation learning, and graph-structured data.\n\n## what you will learn\n- how loss functions encode modeling goals for classification and regression.\n- why optimization dynamics (learning rate, momentum, adaptivity) matter.\n- when to use tree ensembles, and how they compare to neural approaches.\n- how pca, t-sne, and umap reveal structure in high-dimensional data.\n- how graph neural networks operate on relational data.\n\n## concept map\n1. loss design and gradient-based optimization.\n2. validation protocols and overfitting diagnostics.\n3. tree-based models and ensemble methods.\n4. dimensionality reduction and latent representations.\n5. sequence and graph model extensions.\n\n## quick interactive previews\n[[simulation aml-loss-landscape]]\n\n[[simulation aml-tree-ensemble-xor]]\n\n[[simulation aml-tsne-umap-comparison]]\n\n## prerequisites\n- linear algebra (vectors, matrices, eigenvalues/eigenvectors).\n- probability and statistics.\n- multivariable calculus (gradients and chain rule).\n- introductory python or javascript-level programming familiarity.\n\n## recommended progression\n- start with `loss-optimization`.\n- continue with `trees-ensembles`.\n- then study `dimensionality-reduction`.\n- move to `graph-neural-networks`.\n- use `recurrent-neural-networks` and `generative-adversarial-networks` as extension notes.\n"
    },
    {
      "topicId": "applied-machine-learning",
      "topicTitle": "Applied Machine Learning",
      "routeSlug": "applied-machine-learning",
      "lessonSlug": "loss-optimization",
      "lessonTitle": "Loss Functions and Optimization",
      "x": 0.267007440328598,
      "y": 0.25657784938812256,
      "searchText": "loss functions and optimization\n# loss functions and optimization\n\nloss functions define what \"good predictions\" mean. optimization algorithms determine whether we can actually reach good parameters efficiently.\n\n## classification losses\n- **zero-one loss** is useful for evaluation, but not differentiable for gradient-based training.\n- **hinge loss** enforces margins and is common in linear margin methods.\n- **binary cross-entropy** links naturally to probabilistic outputs.\n\nfor binary cross-entropy:\n$$\n\\mathcal{l}_{bce}=-\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_i\\log\\hat{p}_i+(1-y_i)\\log(1-\\hat{p}_i)\\right)\n$$\n\n## regression losses\n- **mse** penalizes large errors strongly.\n- **mae** is robust to outliers but non-smooth at zero.\n- **huber** balances mse and mae behavior.\n\n## optimization dynamics\ngradient descent updates parameters using local slope:\n$$\n\\theta_{t+1}=\\theta_t-\\eta \\nabla_{\\theta}\\mathcal{l}(\\theta_t)\n$$\nwhere $\\eta$ is the learning rate.\n\nmodern optimizers (momentum, rmsprop, adam) improve stability and speed but still require careful tuning.\n\n## validation and overfitting\nalways separate:\n1. training set for fitting parameters.\n2. validation set for model and hyperparameter selection.\n3. test set for final unbiased performance estimate.\n\nfor time series, use chronological splits (rolling or expanding windows) instead of random k-fold to avoid leakage.\n\n## interactive simulations\n[[simulation aml-loss-functions]]\n\n[[simulation aml-loss-landscape]]\n\n[[simulation aml-validation-split]]\n\n## practical checklist\n- start with a simple baseline model and conservative learning rate.\n- monitor both training and validation metrics.\n- use early stopping and regularization when validation diverges.\n- tune one hyperparameter family at a time before broad sweeps.\n"
    },
    {
      "topicId": "applied-machine-learning",
      "topicTitle": "Applied Machine Learning",
      "routeSlug": "applied-machine-learning",
      "lessonSlug": "recurrent-neural-networks",
      "lessonTitle": "Recurrent Neural Networks (Extension)",
      "x": 0.30775177478790283,
      "y": 0.0,
      "searchText": "recurrent neural networks (extension)\n# recurrent neural networks (extension)\n\nrecurrent neural networks (rnns) are sequence models that maintain a hidden state over time. they are useful when prediction depends on order and context, such as language, sensor streams, and temporal forecasting.\n\n## core recurrence\nat timestep $t$:\n$$\nh_t=f(w_{xh}x_t + w_{hh}h_{t-1} + b_h),\\quad\ny_t=g(w_{hy}h_t+b_y)\n$$\n\n## why gated variants matter\nvanilla rnns struggle with long dependencies due to vanishing/exploding gradients. lstm and gru architectures introduce gates to improve memory and gradient flow.\n\n## where this topic fits\nthis page is intentionally lightweight in applied machine learning. for deeper architecture, training details, and sequence modeling workflows, see the broader deep learning topic:\n- `/topics/advanced-deep-learning/ann`\n\n## practical checklist\n- normalize and window sequence data carefully.\n- use chronological validation splits.\n- track both short-horizon and long-horizon error metrics.\n"
    },
    {
      "topicId": "applied-machine-learning",
      "topicTitle": "Applied Machine Learning",
      "routeSlug": "applied-machine-learning",
      "lessonSlug": "trees-ensembles",
      "lessonTitle": "Decision Trees and Ensemble Methods",
      "x": 0.2824885845184326,
      "y": 0.32649141550064087,
      "searchText": "decision trees and ensemble methods\n# decision trees and ensemble methods\n\ntree-based methods remain strong baselines for structured/tabular data because they capture nonlinear interactions with minimal feature engineering.\n\n## decision trees\na decision tree recursively partitions feature space to reduce impurity.\n\n- **gini impurity**:\n$$\ng(s)=1-\\sum_{k=1}^{k}p_k^2\n$$\n- **entropy**:\n$$\nh(s)=-\\sum_{k=1}^{k}p_k\\log p_k\n$$\n\ntrees are interpretable, but deep trees can overfit.\n\n## ensemble methods\n- **random forest (bagging):** averages many decorrelated trees to reduce variance.\n- **adaboost / gradient boosting:** builds trees sequentially, emphasizing previous errors.\n- **xgboost-style systems:** optimized gradient boosting with regularization and strong engineering.\n\n## bias-variance intuition\n- too-simple models: high bias, underfitting.\n- too-complex single trees: high variance, overfitting.\n- ensembles: often improve generalization by balancing both.\n\n## interactive simulations\n[[simulation aml-tree-split-impurity]]\n\n[[simulation aml-tree-ensemble-xor]]\n\n## model selection notes\n- prefer cross-validation for small tabular datasets.\n- tune `max_depth`, `min_samples_leaf`, `n_estimators`, and learning rate.\n- use calibration checks when probabilities are used for decisions.\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "advanced-fitting-calibration",
      "lessonTitle": "Advanced Fitting and Calibration",
      "x": 0.4828496277332306,
      "y": 0.37320876121520996,
      "searchText": "advanced fitting and calibration\n# advanced fitting and calibration\n\n## beyond simple fitting\n\nstandard least-squares fitting assumes a single functional form with normally distributed residuals. in practice, experimental data often requires more sophisticated approaches: models with multiple components, correlated parameters, systematic uncertainties, or the need to compare competing models quantitatively.\n\n**advanced fitting** extends the basic framework by addressing parameter correlations, goodness-of-fit assessment, and model comparison. **calibration** connects raw instrument readings to physical quantities through reference standards and control measurements.\n\n[[simulation applied-stats-sim-3]]\n\n## multi-component models\n\nmany physical measurements involve a **signal plus background** decomposition. the observed data follow a model\n\n$$\nf(x; \\boldsymbol{\\theta}) = s(x; \\boldsymbol{\\theta}_s) + b(x; \\boldsymbol{\\theta}_b),\n$$\n\nwhere $s$ describes the signal of interest and $b$ accounts for background contributions. the total parameter vector $\\boldsymbol{\\theta} = (\\boldsymbol{\\theta}_s, \\boldsymbol{\\theta}_b)$ is estimated simultaneously.\n\nwhen the background shape is known from control measurements or simulation, its parameters may be **constrained** by adding penalty terms to the objective function. this is equivalent to bayesian fitting with informative priors on the background parameters.\n\n## profile likelihood\n\nfor models with many parameters, the **profile likelihood** provides confidence intervals that account for correlations. given parameters of interest $\\boldsymbol{\\psi}$ and nuisance parameters $\\boldsymbol{\\lambda}$, the profile likelihood is\n\n$$\nl_p(\\boldsymbol{\\psi}) = \\max_{\\boldsymbol{\\lambda}} l(\\boldsymbol{\\psi}, \\boldsymbol{\\lambda}).\n$$\n\nat each value of $\\boldsymbol{\\psi}$, the nuisance parameters are re-optimized. a confidence region at level $\\alpha$ is defined by\n\n$$\n-2 \\ln \\frac{l_p(\\boldsymbol{\\psi})}{l_p(\\hat{\\boldsymbol{\\psi}})} \\leq \\chi^2_{k, \\alpha},\n$$\n\nwhere $k = \\dim(\\boldsymbol{\\psi})$. this correctly propagates parameter correlations into the uncertainty.\n\n## goodness of fit\n\nafter fitting, we must assess whether the model adequately describes the data.\n\nthe **chi-squared statistic** $\\chi^2 = \\sum_i (y_i - f(x_i; \\hat{\\boldsymbol{\\theta}}))^2 / \\sigma_i^2$ should follow a $\\chi^2$ distribution with $n - p$ degrees of freedom if the model is correct. the **reduced chi-squared** $\\chi^2_\\nu = \\chi^2 / (n - p)$ should be approximately 1. values much greater than 1 indicate a poor fit or underestimated uncertainties; values much less than 1 suggest overestimated uncertainties.\n\nthe **p-value** gives the probability of obtaining a $\\chi^2$ at least as large as observed, assuming the model is correct. small p-values (typically $< 0.05$) suggest the model is inadequate.\n\n## model comparison\n\nwhen multiple models could describe the data, we need principled criteria for selection.\n\nthe **likelihood ratio test** compares nested models (where one is a special case of the other). the test statistic $\\lambda = -2\\ln(l_0 / l_1)$ follows a $\\chi^2$ distribution with degrees of freedom equal to the difference in number of parameters.\n\nfor non-nested models, **information criteria** penalize model complexity:\n\n$$\n\\text{aic} = -2\\ln l + 2p, \\qquad \\text{bic} = -2\\ln l + p\\ln n,\n$$\n\nwhere $p$ is the number of parameters and $n$ the number of data points. lower values indicate a better balance of fit quality and parsimony. bic penalizes complexity more heavily and tends to favor simpler models.\n\n## calibration\n\n**calibration** establishes the relationship between a measured quantity (instrument response) and a known reference standard. the calibration function $r = g(s; \\boldsymbol{\\theta})$ maps the true physical signal $s$ to the instrument response $r$.\n\na typical calibration procedure involves:\n\n1. **reference measurements**: measure known standards spanning the range of interest.\n2. **fit the calibration curve**: determine $g$ and its parameters from the reference data.\n3. **invert for unknowns**: given a new measurement $r_{\\text{obs}}$, solve $r_{\\text{obs}} = g(s; \\hat{\\boldsymbol{\\theta}})$ for $s$.\n4. **propagate uncertainties**: include both statistical uncertainty from the measurement and systematic uncertainty from the calibration curve.\n\n## control channels\n\n**control channels** (or sidebands) are data regions where the signal is absent but the background is present. they provide an independent constraint on background parameters and reduce the uncertainty on the signal.\n\nin a simultaneous fit, the likelihood combines the signal region and control region:\n\n$$\nl_{\\text{total}} = l_{\\text{signal}}(\\boldsymbol{\\theta}_s, \\boldsymbol{\\theta}_b) \\times l_{\\text{control}}(\\boldsymbol{\\theta}_b).\n$$\n\nthe control channel pins down $\\boldsymbol{\\theta}_b$, effectively reducing the number of free parameters in the signal region. this technique is standard in particle physics (sidebands), astrophysics (off-source regions), and medical imaging (baseline measurements).\n\n## systematic uncertainties\n\nsystematic uncertainties arise from imperfect knowledge of the experimental setup: detector response, energy scale, efficiency corrections, and theoretical modeling. they are handled by introducing **nuisance parameters** $\\boldsymbol{\\lambda}$ with constraint terms:\n\n$$\n-2\\ln l_{\\text{constrained}} = -2\\ln l(\\boldsymbol{\\theta}, \\boldsymbol{\\lambda}) + \\sum_k \\frac{(\\lambda_k - \\hat{\\lambda}_k)^2}{\\sigma_{\\lambda_k}^2}.\n$$\n\neach nuisance parameter is profiled out during the fit. the resulting uncertainty on parameters of interest automatically includes systematic contributions.\n\n[[simulation applied-stats-sim-8]]\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "anova",
      "lessonTitle": "Analysis of Variance (ANOVA)",
      "x": 0.3775877356529236,
      "y": 0.45793601870536804,
      "searchText": "analysis of variance (anova)\n# analysis of variance (anova)\n\n## the idea behind anova\n\n**analysis of variance** tests whether the means of three or more groups differ significantly. despite its name, anova works by comparing variability *between* groups to variability *within* groups.\n\nthe key insight: if group means differ substantially, the between-group variance will be large relative to the within-group variance.\n\n## one-way anova\n\nfor $k$ groups with $n_i$ observations each, the model is:\n\n$$\ny_{ij} = \\mu + \\alpha_i + \\varepsilon_{ij}, \\qquad \\varepsilon_{ij} \\sim \\mathcal{n}(0, \\sigma^2),\n$$\n\nwhere $\\mu$ is the grand mean, $\\alpha_i$ is the effect of group $i$, and $\\varepsilon_{ij}$ is random error.\n\nthe total sum of squares decomposes as:\n\n$$\n\\text{ss}_{\\text{total}} = \\text{ss}_{\\text{between}} + \\text{ss}_{\\text{within}}.\n$$\n\nthe **f-statistic** is:\n\n$$\nf = \\frac{\\text{ss}_{\\text{between}} / (k - 1)}{\\text{ss}_{\\text{within}} / (n - k)} = \\frac{\\text{ms}_{\\text{between}}}{\\text{ms}_{\\text{within}}}.\n$$\n\nunder $h_0: \\alpha_1 = \\cdots = \\alpha_k = 0$, the statistic follows an $f(k-1, n-k)$ distribution.\n\n**assumptions**:\n\n- independence of observations.\n- normality within each group.\n- homogeneity of variances (**homoscedasticity**); checked with levene's test or bartlett's test.\n\n[[simulation applied-stats-sim-1]]\n\n## two-way anova\n\nwhen two factors ($a$ and $b$) are varied simultaneously:\n\n$$\ny_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} + \\varepsilon_{ijk}.\n$$\n\nthis decomposes variability into:\n\n- main effect of $a$: do levels of factor $a$ differ on average?\n- main effect of $b$: do levels of factor $b$ differ on average?\n- **interaction** $a \\times b$: does the effect of $a$ depend on the level of $b$?\n\ninteraction effects are often the most scientifically interesting finding.\n\n## factorial designs\n\na **full factorial design** tests all combinations of factor levels. for factors with $a$ and $b$ levels, there are $a \\times b$ treatment combinations. factorial designs are efficient because every observation contributes information about every factor.\n\n**balanced designs** (equal sample sizes per cell) simplify the analysis and make the f-tests exact.\n\n## post-hoc tests\n\nwhen anova rejects $h_0$, we need to determine *which* groups differ. multiple comparison procedures control the family-wise error rate:\n\n- **tukey's hsd**: compares all pairs of group means; controls the simultaneous confidence level.\n- **bonferroni correction**: divides $\\alpha$ by the number of comparisons; conservative but general.\n- **scheff\u00e9's method**: allows arbitrary contrasts; most conservative.\n- **dunnett's test**: compares each treatment to a single control group.\n\n## non-parametric alternative: kruskal-wallis\n\nwhen normality or homoscedasticity assumptions are violated, the **kruskal-wallis test** provides a non-parametric alternative to one-way anova. it tests whether group medians differ by ranking all observations and comparing mean ranks across groups.\n\n$$\nh = \\frac{12}{n(n+1)} \\sum_{i=1}^{k} n_i (\\bar{r}_i - \\bar{r})^2,\n$$\n\nwhere $\\bar{r}_i$ is the mean rank in group $i$. under $h_0$, $h \\sim \\chi^2(k-1)$ approximately.\n\nif significant, pairwise comparisons can be performed with the **dunn test** (with bonferroni correction).\n\n[[simulation applied-stats-sim-2]]\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "bayesian-statistics",
      "lessonTitle": "Bayesian Statistics and Multivariate Analysis",
      "x": 0.3703639507293701,
      "y": 0.36487317085266113,
      "searchText": "bayesian statistics and multivariate analysis\n# bayesian statistics and multivariate analysis\n\n## bayes' theorem\n\n**bayesian statistics** is a framework for statistical inference in which beliefs about the probability of an event are updated as new data is obtained. this contrasts with frequentist statistics, which treats probability as a fixed, long-run frequency.\n\n**bayes' theorem** states that the posterior probability of a hypothesis $h$ given data $d$ is:\n\n$$\np(h|d) = \\frac{p(d|h) \\cdot p(h)}{p(d)}\n$$\n\nwhere:\n- $p(h|d)$ is the **posterior**: the updated belief after seeing the data.\n- $p(d|h)$ is the **likelihood**: the probability of the data given the hypothesis.\n- $p(h)$ is the **prior**: the belief before seeing the data.\n- $p(d)$ is the **evidence**: a normalization constant.\n\n## multivariate analysis (mva)\n\n**multivariate analysis** encompasses statistical techniques for data with more than one variable. key techniques include:\n\n- **principal component analysis** (pca): identifies directions of maximum variance in the data, enabling dimensionality reduction.\n- **factor analysis**: identifies underlying latent factors that explain correlations between observed variables.\n- **cluster analysis**: groups similar observations together based on multiple variables.\n- **discriminant analysis**: classifies observations into groups based on multiple variables.\n- **multivariate regression**: models relationships between multiple independent variables and a dependent variable.\n\n## the linear fisher discriminant\n\nthe **fisher discriminant** finds the linear combination of features that best separates two classes. the discriminant direction is:\n\n$$\n\\mathbf{w} = s^{-1}(\\boldsymbol{\\mu}_0 - \\boldsymbol{\\mu}_1)\n$$\n\nwhere $\\boldsymbol{\\mu}_0$ and $\\boldsymbol{\\mu}_1$ are the class means and $s$ is the **pooled within-class covariance matrix**:\n\n$$\ns = \\frac{1}{n}(s_0 + s_1)\n$$\n\nwhere $s_0$ and $s_1$ are the covariance matrices for each class and $n$ is the total number of observations.\n\na new observation $\\mathbf{x}$ is classified by computing the projection $\\mathbf{w}^t \\mathbf{x}$ and comparing to a threshold.\n\nthis method assumes the classes have normal distributions with identical covariance matrices. when these assumptions are violated, other approaches (e.g., quadratic discriminant analysis or nonlinear classifiers) should be considered.\n\n[[simulation applied-stats-sim-5]]\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "design-of-experiments",
      "lessonTitle": "Basic Design of Experiments",
      "x": 0.3609936535358429,
      "y": 0.4887739419937134,
      "searchText": "basic design of experiments\n# basic design of experiments\n\n## principles of experimental design\n\ngood experimental design maximizes the information obtained while controlling for confounding factors. three foundational principles guide every well-designed experiment:\n\n- **randomization**: randomly assign experimental units to treatments to eliminate systematic bias.\n- **replication**: repeat measurements to estimate variability and increase precision.\n- **blocking**: group experimental units by a known source of variability to reduce noise.\n\n## completely randomized design (crd)\n\nthe simplest design assigns all experimental units to treatments purely at random. the crd is appropriate when units are homogeneous and no blocking variable is identified.\n\nthe model is identical to one-way anova:\n\n$$\ny_{ij} = \\mu + \\tau_i + \\varepsilon_{ij},\n$$\n\nwhere $\\tau_i$ is the treatment effect.\n\n**advantages**: simple to implement and analyze.\n**limitation**: if units vary substantially, the within-group variance is inflated, reducing power.\n\n## randomized block design (rbd)\n\nwhen a nuisance variable is known (e.g., batch, day, or subject), blocking removes its effect:\n\n$$\ny_{ij} = \\mu + \\tau_i + \\beta_j + \\varepsilon_{ij},\n$$\n\nwhere $\\beta_j$ is the block effect. each treatment appears exactly once in each block.\n\n**advantage**: removes block-to-block variability from the error term, increasing the f-statistic for the treatment effect.\n\nthe **relative efficiency** of blocking compares the precision of rbd to crd:\n\n$$\n\\text{re} = \\frac{\\text{ms}_{\\text{blocks}} + (b-1)\\,\\text{ms}_{\\text{error,rbd}}}{b\\,\\text{ms}_{\\text{error,rbd}}},\n$$\n\nwhere $b$ is the number of blocks. values greater than 1 indicate that blocking was beneficial.\n\n## power and sample size\n\n**statistical power** is the probability of correctly rejecting $h_0$ when a true effect exists:\n\n$$\n\\text{power} = 1 - \\beta = p(\\text{reject } h_0 \\mid h_1 \\text{ true}).\n$$\n\npower depends on:\n\n- **effect size** ($\\delta$): the magnitude of the difference to detect.\n- **sample size** ($n$): more observations increase power.\n- **significance level** ($\\alpha$): relaxing $\\alpha$ increases power at the cost of more false positives.\n- **variability** ($\\sigma$): less noise increases power.\n\nfor a two-sample t-test, the required sample size per group to achieve power $1 - \\beta$ at level $\\alpha$ for detecting a difference $\\delta$ is approximately:\n\n$$\nn \\approx \\frac{2(z_{\\alpha/2} + z_\\beta)^2 \\sigma^2}{\\delta^2}.\n$$\n\n**cohen's conventions** for effect size $d = \\delta/\\sigma$: small ($d = 0.2$), medium ($d = 0.5$), large ($d = 0.8$).\n\n## practical considerations\n\n- always determine sample size *before* starting the experiment.\n- pre-register the analysis plan to avoid p-hacking.\n- use pilot studies to estimate $\\sigma$ when it is unknown.\n- consider multiple testing corrections when evaluating many endpoints.\n\n[[simulation applied-stats-sim-5]]\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "home",
      "lessonTitle": "Applied Statistics",
      "x": 0.3993849754333496,
      "y": 0.3141086995601654,
      "searchText": "applied statistics\n# applied statistics\n\n## course overview\n\napplied statistics focuses on **practical statistical analysis** through project-based learning. students conduct statistical projects related to experiments or investigations, preferably using real data, while building fluency in the methods that underpin modern data analysis.\n\n- classical statistics: estimation, hypothesis testing, confidence intervals.\n- applied statistics: model selection, validation, interpretation, and communication of results.\n- emphasis on understanding when each method is appropriate and what its assumptions require.\n\n## why this topic matters\n\n- every experimental science relies on statistical reasoning to distinguish signal from noise.\n- choosing the wrong test or violating assumptions leads to false conclusions.\n- modern datasets require regression, anova, mixed models, and longitudinal methods.\n- statistical literacy is essential for reading and producing scientific literature.\n\n## key mathematical ideas\n\n- probability distributions and likelihood functions.\n- parametric and non-parametric hypothesis tests.\n- linear models: regression, anova, and their generalizations.\n- random effects and hierarchical/mixed models.\n- experimental design: randomization, blocking, and power analysis.\n\n## prerequisites\n\n- introductory statistics: variation, estimation, confidence intervals, hypothesis tests.\n- one-way anova and simple linear regression.\n- basic familiarity with r or rstudio.\n\n## recommended reading\n\n- draper and smith, *applied regression analysis*.\n- agresti, *statistical methods for the social sciences*.\n- course notes and r documentation.\n\n## learning trajectory\n\nthis module progresses from basic comparisons to advanced modeling:\n\n- introduction to data types and basic statistical concepts.\n- probability density functions and distributions.\n- hypothesis testing and confidence intervals.\n- simulation and fitting methods.\n- anova: one-way, two-way, and factorial designs.\n- linear and multilinear regression with diagnostics.\n- design of experiments: randomization, blocking, and power.\n- random effects and mixed models.\n- longitudinal data and repeated measures.\n- advanced fitting, calibration, and bayesian approaches.\n- machine learning and modern data analysis.\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "hypothesis-testing",
      "lessonTitle": "Hypothesis Testing and Limits",
      "x": 0.4280356168746948,
      "y": 0.4461509585380554,
      "searchText": "hypothesis testing and limits\n# hypothesis testing and limits\n\n## hypothesis testing\n\nwe can perform either **one-tailed** or **two-tailed** tests depending on the alternative hypothesis.\n\n### one-sample z test\n\nusually not used in practice since the population standard deviation is typically unknown.\n\n1. state the null hypothesis: $h_0: \\mu = 100$.\n2. state the alternative hypothesis: $h_1: \\mu > 100$.\n3. state the significance level: $\\alpha = 0.05$.\n4. find the rejection region from the z-table. an area of 0.05 corresponds to a z-score of 1.645.\n5. calculate the test statistic:\n\n$$\nz = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n$$\n\n6. if $z$ exceeds the critical value from step 4, reject the null hypothesis.\n\n### student's t-test\n\nthe **t-test** is more commonly used because it does not require knowing the population standard deviation.\n\na student's t-test determines if there is a significant difference between the means of two groups. there are two types:\n\n- **one-sample t-test**: compares the mean of a single sample to a known or hypothesized population mean.\n- **two-sample t-test**: compares the means of two independent samples.\n\nthe t-test assumes the data is approximately normally distributed and (for the two-sample version) that the variances of the two groups are equal. the test statistic is the difference between the sample mean and the population mean, divided by the standard error. this is compared to a $t$-distribution with the appropriate degrees of freedom.\n\n[[simulation applied-stats-sim-4]]\n\n### kolmogorov-smirnov test\n\nthe **kolmogorov-smirnov test** (k-s test) is a non-parametric test that compares a sample with a reference probability distribution (one-sample), or compares two samples (two-sample). it returns a p-value indicating whether the samples are drawn from the same distribution.\n\n### runs test\n\na non-parametric test that checks the randomness hypothesis for a two-valued data sequence. an example sequence is:\n\n> $+ + + + - - - + + + - - + + + + + + - - - -$\n\n## confidence intervals\n\na **confidence interval** is a range of values derived from sample data, used to estimate an unknown population parameter. the interval has an associated confidence level quantifying the probability that the true parameter lies within the interval.\n\nfor example, a 95% confidence interval means that if the sampling process were repeated many times, 95% of the calculated intervals would contain the true population parameter.\n\nthe interval is calculated from the point estimate (e.g., sample mean), the standard error, and the desired confidence level.\n\n## simpson's paradox\n\n**simpson's paradox** occurs when a trend that appears in different groups of data disappears or reverses when the groups are combined. this happens when a lurking variable affects the relationship between the variables differently across groups.\n\nfor example, a study might find that men have a higher average salary than women in each department within a company. however, when all departments are combined, the overall average salary for women may be higher. this reversal is explained by the proportion of men and women in each department.\n\nsimpson's paradox highlights the importance of considering all relevant factors when interpreting data.\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "introduction-concepts",
      "lessonTitle": "Introduction, General Concepts, and Chi-Square Method",
      "x": 0.5128602385520935,
      "y": 0.40549179911613464,
      "searchText": "introduction, general concepts, and chi-square method\n# introduction, general concepts, and chi-square method\n\n## measures of central tendency\n\n### mean\n\nthe mean tells us about the bulk magnitude-tendency of data.\n\n### geometric mean\n\nthe $n$-th root of the product:\n\n$$\n\\bar{x}_\\text{geo} = \\left( \\prod_i^n x_i\\right)^{1/n} = \\exp\\left(\\frac{1}{n}\\sum_{i}^n\\ln x_i \\right)\n$$\n\nthis is equivalent to the arithmetic mean in log-scale.\n\n```python\ndef geometric(arr):\n    return np.prod(arr)**(1/len(arr))\n\ndef geometric(arr):\n    # a sum of logs is less prone to\n    # under-/over-flow than a product.\n    return np.exp(np.mean(np.log(arr)))\n```\n\n### arithmetic mean\n\nthe equal-weight center:\n\n$$\n\\hat{\\mu} = \\bar{x} = \\langle x \\rangle = \\frac{1}{n}\\sum_i^n x_i\n$$\n\n```python\ndef arithmetic(arr):\n    return np.sum(arr) / len(arr)\n    # or equivalently: np.mean(arr)\n```\n\n### median\n\nthe counting center of the data (the middle value when sorted).\n\n```python\ndef median(arr):\n    n = len(arr)\n    return arr[n//2] if n % 2 == 0 else arr[n//2]\n```\n\n### mode\n\nthe most typical data point (the value that occurs most frequently).\n\n### harmonic mean\n\n$$\n\\bar{x}_\\text{harm} = \\left[\\frac{1}{n}\\sum_i^n \\frac{1}{x_i}\\right]^{-1}\n$$\n\n```python\ndef harmonic(x):\n    return (np.sum(x**(-1)) / len(x))**(-1)\n```\n\n### truncated mean\n\nthe arithmetic mean of the data with its tails cut off:\n\n```python\ndef truncated(arr, k):\n    arr_sorted = np.sort(arr)\n    return np.mean(arr_sorted[k:-k])\n```\n\n## standard deviation\n\nstandard deviation measures how much data points deviate from the dataset mean:\n\n$$\n\\hat{\\sigma} = \\sqrt{\\frac{1}{n}\\sum_i^n (x_i - \\mu)^2}\n$$\n\nin estimating this, we assume we know the true mean. in practice we use the sample mean $\\bar{x}$, which requires **bessel's correction** (dividing by $n-1$ instead of $n$ to account for the lost degree of freedom):\n\n$$\n\\tilde{\\sigma} = \\sqrt{\\frac{1}{n-1}\\sum_i(x_i-\\bar{x})^2}\n$$\n\n## normal distribution\n\nthe normal (gaussian) distribution is fundamental in statistics.\n\n[[simulation applied-stats-sim-2]]\n\n## weighted mean\n\nhow to average data with different uncertainties and what is the uncertainty on the average?\n\n$$\n\\hat{\\mu} = \\frac{\\sum x_i / \\sigma_i^2}{\\sum 1 / \\sigma_i^2}, \\qquad \\hat{\\sigma}_\\mu = \\sqrt{\\frac{1}{\\sum 1/\\sigma_i^2}}\n$$\n\nthe uncertainty decreases with the square root of the number of samples:\n\n$$\n\\hat{\\sigma}_\\mu = \\hat{\\sigma}/\\sqrt{n}.\n$$\n\n## correlation\n\ncorrelation measures whether a feature varies in concordance with another. from the variance we obtain the **covariance**:\n\n$$\n\\begin{aligned}\nv = \\sigma^2 &= \\frac{1}{n}\\sum_i^n(x_i-\\mu)^2 = e[(x-\\mu)^2] = e[x^2] - \\mu^2 \\\\\nv_{xy} &= e[(x_i-\\mu_x)(y_i-\\mu_y)] =\n\\begin{bmatrix}\n\\sigma_{11}^2 & \\sigma_{12}^2 & \\ldots\\\\\n\\sigma_{21}^2 & \\ldots & \\ldots\n\\end{bmatrix}\n\\end{aligned}\n$$\n\nnormalizing by the widths gives **pearson's (linear) correlation coefficient**:\n\n$$\n\\rho_{xy} = \\frac{v_{xy}}{\\sigma_x\\sigma_y}, \\qquad -1 \\leq \\rho_{xy} \\leq 1\n$$\n\nnote that $\\rho_{xy} = 0$ only indicates the absence of *linear* correlation. always plot the data to check for non-linear relationships.\n\n### rank correlation\n\n**rank correlation** tests for non-linear monotonic relationships. it compares the ranking between two sets. **spearman's $\\rho$** and **kendall's $\\tau$** are the most common:\n\n$$\n\\rho_s = 1 - \\frac{6\\sum_i (r_i - s_i)^2}{n^3-n}\n$$\n\nkendall's $\\tau$ compares the number of concordant pairs to discordant pairs.\n\n### other non-linear correlation measures\n\n- maximal information coefficient (mic)\n- mutual information (mi)\n- distance correlation (dc)\n\n## linear regression\n\nlinear regression models the relationship between a dependent variable and one or more independent variables. the simple linear regression model is:\n\n$$\ny = \\beta_0 + \\beta_1 x + \\epsilon\n$$\n\nwhere $\\beta_0$ is the intercept, $\\beta_1$ is the slope, and $\\epsilon$ is the error term.\n\n[[simulation applied-stats-sim-1]]\n\n## central limit theorem\n\nthe central limit theorem answers the question: *why do statistics in the limit of large $n$ tend toward a gaussian?*\n\nthe distribution of the mean of $n$ independent samples from any distribution (with finite variance) approaches a gaussian as $n$ increases. this holds regardless of the original distribution's shape.\n\n[[simulation applied-stats-sim-3]]\n\nfor the clt to work well, the standard deviations of the contributing distributions must be similar. distributions with heavy tails (like the cauchy distribution) may require truncation since they lack finite variance.\n\n**the central limit theorem ensures that uncertainties are gaussian distributed** (under suitable conditions), which is why gaussian error analysis is so widely applicable.\n\n## error propagation\n\nif we have a function $y(x_i)$ and we know the uncertainty $\\sigma(x_i)$, how do we find $\\sigma(y)$? it depends on the gradient of $y$ with respect to $x$:\n\n$$\n\\sigma(y) = \\frac{\\partial y}{\\partial x}\\sigma(x_i)\n$$\n\nif $y$ is smooth around $x_i$ this works well. the slope should be relatively constant over the uncertainty range in $x_i$.\n\nfor multiple variables with correlations, the general formula is:\n\n$$\n\\sigma_y^2 = \\sum_{i,j}^n \\frac{\\partial y}{\\partial x_i} \\frac{\\partial y}{\\partial x_j} v_{ij}\n$$\n\nif there are no correlations, only the diagonal terms (individual errors) contribute. this lets us identify which parameters dominate the total uncertainty.\n\n### addition\n\n$$\ny = x_1 + x_2 \\implies \\sigma_y^2 = \\sigma_{x_1}^2 + \\sigma_{x_2}^2 + 2v_{x_1, x_2}\n$$\n\n### multiplication\n\n$$\ny = x_1 x_2 \\implies \\sigma_y^2 = (x_2\\sigma_{x_1})^2 + (x_1\\sigma_{x_2})^2 + 2x_1 x_2 v_{x_1, x_2}\n$$\n\ndividing by $y^2$ gives the relative uncertainties. by using negative error correlations, we can cancel out errors (e.g., harrison's gridiron pendulum).\n\n### simulating error propagation\n\nchoose random inputs $x_i$ and record the output $y$. if $y(x)$ is not smooth, this will not yield gaussian-distributed $y$, even with gaussian errors in $x_i$."
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "longitudinal-data",
      "lessonTitle": "Longitudinal Data and Repeated Measures",
      "x": 0.3219294548034668,
      "y": 0.4283362925052643,
      "searchText": "longitudinal data and repeated measures\n# longitudinal data and repeated measures\n\n## what makes longitudinal data special\n\n**longitudinal data** arise when the same subjects are measured repeatedly over time. this creates two fundamental challenges:\n\n- **within-subject correlation**: measurements from the same individual are not independent.\n- **time structure**: the spacing and ordering of observations carry information about dynamics.\n\nignoring these features and applying standard methods leads to incorrect inference.\n\n## repeated measures anova\n\nthe classical approach extends anova to handle within-subject factors. for a single within-subject factor with $k$ time points:\n\n$$\ny_{ij} = \\mu + \\pi_i + \\tau_j + \\varepsilon_{ij},\n$$\n\nwhere $\\pi_i$ is the subject effect and $\\tau_j$ is the time effect.\n\n**sphericity assumption**: the variances of all pairwise differences between time points must be equal. mauchly's test checks this assumption. when sphericity is violated:\n\n- **greenhouse-geisser correction**: reduces the degrees of freedom to control type i error (conservative).\n- **huynh-feldt correction**: less conservative alternative.\n\n**limitation**: repeated measures anova requires complete data (no missing time points) and equally spaced measurements.\n\n## linear mixed models for longitudinal data\n\n**linear mixed models** (lmms) overcome the limitations of repeated measures anova by modeling the correlation structure directly:\n\n$$\ny_{ij} = \\beta_0 + \\beta_1 t_{ij} + u_{0i} + u_{1i} t_{ij} + \\varepsilon_{ij},\n$$\n\nwhere $u_{0i}$ is a **random intercept** (each subject starts at a different level) and $u_{1i}$ is a **random slope** (each subject changes at a different rate).\n\nthe random effects are assumed multivariate normal:\n\n$$\n\\begin{pmatrix} u_{0i} \\\\ u_{1i} \\end{pmatrix} \\sim \\mathcal{n}\\!\\left(\\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} \\sigma_0^2 & \\rho\\sigma_0\\sigma_1 \\\\ \\rho\\sigma_0\\sigma_1 & \\sigma_1^2 \\end{pmatrix}\\right).\n$$\n\n**advantages over repeated measures anova**:\n\n- handles missing data naturally (uses all available observations).\n- accommodates unequally spaced time points.\n- models individual trajectories, not just group means.\n- allows complex correlation structures.\n\n## growth curve models\n\nwhen the outcome follows a nonlinear trajectory over time, polynomial or nonlinear growth curves can be fit within the mixed-model framework:\n\n$$\ny_{ij} = \\beta_0 + \\beta_1 t_{ij} + \\beta_2 t_{ij}^2 + u_{0i} + u_{1i} t_{ij} + \\varepsilon_{ij}.\n$$\n\nthe fixed effects $(\\beta_0, \\beta_1, \\beta_2)$ describe the population-average trajectory, while the random effects $(u_{0i}, u_{1i})$ capture individual deviations.\n\n## autocorrelation\n\nin longitudinal data, residuals from adjacent time points are often more correlated than residuals from distant time points. common correlation structures:\n\n- **compound symmetry**: constant correlation between all pairs (equivalent to random intercept).\n- **ar(1)**: correlation decays exponentially with time lag: $\\text{cor}(\\varepsilon_{ij}, \\varepsilon_{ik}) = \\phi^{|j-k|}$.\n- **unstructured**: separate correlation for each pair (most flexible but parameter-intensive).\n\nmodel selection among correlation structures uses **aic** or **bic**.\n\n## handling missing data\n\nlongitudinal studies inevitably have missing observations. the mechanism matters:\n\n- **mcar** (missing completely at random): missingness is unrelated to any data. standard methods remain valid.\n- **mar** (missing at random): missingness depends on observed data but not on the missing values themselves. lmms under maximum likelihood provide valid inference.\n- **mnar** (missing not at random): missingness depends on the unobserved values. requires specialized models (selection models, pattern-mixture models).\n\nlmms estimated by maximum likelihood or reml are valid under mar, making them the preferred approach for longitudinal analysis with incomplete data.\n\n[[simulation applied-stats-sim-7]]\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "machine-learning-data-analysis",
      "lessonTitle": "Machine Learning and Data Analysis",
      "x": 0.34450027346611023,
      "y": 0.3145564794540405,
      "searchText": "machine learning and data analysis\n# machine learning and data analysis\n\n## overview\n\nmachine learning (ml) provides algorithms that learn patterns from data without being explicitly programmed for each case. in experimental physics and data analysis, ml methods complement traditional statistical techniques for tasks like **classification** (separating signal from background), **regression** (predicting continuous quantities), and **clustering** (discovering structure in unlabelled data).\n\nml algorithms fall into two broad categories. **supervised learning** trains on labelled examples and predicts labels for new data. **unsupervised learning** finds structure in data without labels.\n\n## supervised learning: classification\n\ngiven training data $\\{(\\mathbf{x}_i, y_i)\\}$ where $y_i \\in \\{0, 1\\}$ labels signal vs. background, a classifier learns a decision boundary in feature space.\n\n**logistic regression** models the probability of the positive class as\n\n$$\np(y=1 | \\mathbf{x}) = \\frac{1}{1 + e^{-\\mathbf{w}^t \\mathbf{x} - b}},\n$$\n\nwhere $\\mathbf{w}$ and $b$ are learned by maximizing the likelihood. despite its simplicity, logistic regression is effective when classes are approximately linearly separable.\n\n**decision trees** recursively partition feature space by selecting the feature and threshold that best separates classes at each node. they are interpretable but prone to overfitting. **random forests** reduce overfitting by averaging predictions from many trees, each trained on a bootstrap sample with a random subset of features.\n\n**boosted decision trees** (bdt) build an ensemble sequentially, with each new tree focusing on the examples misclassified by the previous ones. gradient boosting (e.g., xgboost) is among the most powerful classifiers for tabular data and is widely used in particle physics for event selection.\n\n## supervised learning: regression\n\nfor predicting continuous targets, the same algorithms adapt. linear regression minimizes squared residuals, while **ridge** and **lasso** regression add $l_2$ and $l_1$ penalty terms respectively:\n\n$$\n\\hat{\\mathbf{w}} = \\arg\\min_{\\mathbf{w}} \\sum_i (y_i - \\mathbf{w}^t\\mathbf{x}_i)^2 + \\lambda \\|\\mathbf{w}\\|_p^p.\n$$\n\nlasso ($p=1$) performs automatic feature selection by driving irrelevant coefficients to zero. ridge ($p=2$) handles correlated features more gracefully.\n\n## neural networks\n\na feedforward neural network with $l$ layers computes\n\n$$\n\\mathbf{h}^{(l)} = \\sigma\\bigl(w^{(l)} \\mathbf{h}^{(l-1)} + \\mathbf{b}^{(l)}\\bigr), \\quad l = 1, \\ldots, l,\n$$\n\nwhere $\\sigma$ is a nonlinear activation function (relu, sigmoid, or tanh) and $\\mathbf{h}^{(0)} = \\mathbf{x}$. the parameters are optimized by **backpropagation** using gradient descent on a loss function.\n\nneural networks can approximate any continuous function (universal approximation theorem) and excel when feature engineering is difficult. however, they require large training sets, careful regularization, and are less interpretable than tree-based methods.\n\n## unsupervised learning\n\n**k-means clustering** partitions data into $k$ groups by iteratively assigning points to the nearest centroid and updating centroids. it requires specifying $k$ in advance and assumes roughly spherical clusters.\n\n**principal component analysis** (pca) finds the directions of maximum variance in the data. the principal components are the eigenvectors of the covariance matrix. projecting onto the top $d$ components reduces dimensionality while preserving the most information.\n\n## model evaluation\n\nthe critical concern in ml is **generalization**: performance on unseen data, not just the training set.\n\n**cross-validation** splits the data into $k$ folds, trains on $k-1$, and tests on the held-out fold, rotating through all folds. the average test performance estimates generalization error.\n\nfor classifiers, key metrics include:\n- **accuracy**: fraction of correct predictions.\n- **precision**: $\\text{tp} / (\\text{tp} + \\text{fp})$, the purity of selected events.\n- **recall (sensitivity)**: $\\text{tp} / (\\text{tp} + \\text{fn})$, the efficiency for signal.\n- **roc curve**: plots true positive rate vs. false positive rate as the decision threshold varies. the area under the curve (auc) summarizes overall discrimination power.\n\n**overfitting** occurs when the model memorizes training noise. it is detected by a gap between training and validation performance and mitigated by regularization, early stopping, or ensemble methods.\n\n## time series analysis\n\nmany experiments produce sequential measurements where temporal correlations matter. **autocorrelation** quantifies how a signal correlates with itself at different time lags:\n\n$$\nr(\\tau) = \\frac{1}{n} \\sum_{t=1}^{n-\\tau} (x_t - \\bar{x})(x_{t+\\tau} - \\bar{x}).\n$$\n\n**moving averages** smooth noisy signals, while **autoregressive (ar) models** predict the next value from a linear combination of previous values. the **fourier transform** (covered in the fft topic) reveals periodic components in the frequency domain.\n\n[[simulation applied-stats-sim-8]]\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "probability-density-functions",
      "lessonTitle": "Probability Density Functions",
      "x": 0.47422754764556885,
      "y": 0.4253557622432709,
      "searchText": "probability density functions\n# probability density functions\n\n## probability density functions (pdfs)\n\na **probability density function** is a function of a continuous random variable whose integral across an interval gives the probability that the value of the variable lies within that interval:\n\n$$\nf_x(x) = \\frac{1}{\\delta x}\\int_{x_0}^{x_0+\\delta x} f(x) \\, dx\n$$\n\nwhen fitting with pdfs, we should consider the error stemming from the bin-widths.\n\nwe may also consider the **cumulative distribution function**: the integral from $-\\infty$,\n\n$$\nf_x(x) = \\int_{-\\infty}^{x} f(x') \\, dx'.\n$$\n\n## distributions\n\n### binomial\n\n$n$ trials, $p$ chance of success, how many successes should you expect?\n\n$$\n\\begin{aligned}\nf(n;n,p) &= \\frac{n!}{n!(n-n)!}p^n(1-p)^{n-n}\\\\\n\\langle f(n;n,p)\\rangle &= np \\\\\n\\sigma^2 &= np(1-p)\n\\end{aligned}\n$$\n\nnote that this is a **discrete** distribution.\n\n[[simulation applied-stats-sim-1]]\n\n### poisson\n\nif $n\\rightarrow \\infty$ and $p\\rightarrow 0$, but $np\\rightarrow\\lambda$ (some finite number), then the binomial approaches a **poisson** distribution:\n\n$$\nf(n, \\lambda) = \\frac{\\lambda^n}{n!}e^{-\\lambda}\n$$\n\n**example**: a large number of people go into traffic every day ($n\\rightarrow\\infty$), the probability of being killed in traffic is tiny ($p\\rightarrow 0$), but some people do get killed in traffic every year ($\\lambda\\neq 0$).\n\nthe poisson distribution has mean and variance both equal to $\\lambda$. the error on a poisson count is the square root of that count.\n\n**a useful case**: the error to assign a bin in a histogram if there are reasonable statistics ($n \\approx 5{-}20$) in each bin. if there are low statistics in a bin, we cannot make the gaussian approximation.\n\nthe sum of independent poissons is a poisson: $\\lambda = \\lambda_a + \\lambda_b$.\n\nif $\\lambda \\rightarrow \\infty$, the poisson approaches a gaussian (practically, $\\lambda \\gtrsim 20$).\n\n### gaussian\n\nthe **normal distribution**:\n\n$$\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left[-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2\\right]\n$$\n\ngiven a large number of samples, we usually observe this distribution (by the central limit theorem), and it is convenient to work with analytically.\n\n### student's t-distribution\n\nuseful for **low statistics**, because it accounts for the uncertainty in the estimated $\\mu$ and $\\sigma$. when the number of samples $\\rightarrow\\infty$, the $t$-distribution converges to the gaussian. its heavier tails make it more robust for small sample sizes.\n\n## maximum likelihood estimation\n\nwe seek the parameters $\\theta$ that maximize the **likelihood** $\\mathcal{l}$ given the observed data:\n\n$$\n\\mathcal{l}(\\theta) = \\prod_i f(x_i; \\theta)\n$$\n\nwe are prone to rounding errors when multiplying many small numbers together, so we instead maximize the **log-likelihood**. assuming gaussian errors:\n\n$$\n-2\\ln(\\mathcal{l}) = \\chi^2 + \\text{const.}\n$$\n\nproperties of maximum likelihood estimators:\n- **consistent**: converges to the true value as $n \\to \\infty$.\n- **asymptotically normal**: errors become gaussian for large $n$.\n- **efficient**: reaches the minimum variance bound (cramer-rao bound) for large $n$.\n\nthe fitting procedure:\n1. choose a model and compute the likelihood for the data.\n2. optimize parameters to maximize $\\mathcal{l}$ (or equivalently, minimize $-\\ln\\mathcal{l}$).\n3. test the fit by comparing with the data distribution.\n\nnote: there are different methods depending on whether we use individual data points (unbinned) or histogram bins and counts (binned). consider the binned approach for very large samples since the unbinned likelihood calculation can be expensive.\n\n## the likelihood ratio test\n\nif we have two different hypotheses, the test statistic is\n\n$$\nd = -2\\ln\\frac{\\mathcal{l}_\\text{null}}{\\mathcal{l}_\\text{alt}} = -2\\ln(\\mathcal{l}_\\text{null}) + 2\\ln(\\mathcal{l}_\\text{alt})\n$$\n\nunder the null hypothesis, $d$ follows a $\\chi^2$ distribution with degrees of freedom equal to the difference in the number of parameters between the two models. greater degrees of freedom will necessarily yield a higher likelihood, so the test accounts for model complexity.\n\n[[simulation applied-stats-sim-2]]\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "random-effects",
      "lessonTitle": "Random Effects and Mixed Models",
      "x": 0.31758636236190796,
      "y": 0.45329049229621887,
      "searchText": "random effects and mixed models\n# random effects and mixed models\n\n## fixed vs random effects\n\nin standard anova and regression, all effects are **fixed**: they represent specific levels of interest (e.g., drug a vs drug b). when the levels in the study are a random sample from a larger population of possible levels, the effect is **random**.\n\n- **fixed effect**: the specific levels are of direct interest. inference applies only to those levels.\n- **random effect**: the levels are sampled from a population. inference generalizes to the entire population of levels.\n\nexamples of random effects:\n\n- subjects in a repeated-measures study (each subject is one realization from a population).\n- classrooms in an educational study (each classroom is a cluster).\n- batches in an industrial process.\n\n## the mixed-effects model\n\na **mixed model** contains both fixed and random effects. for a simple random-intercept model:\n\n$$\ny_{ij} = \\mu + \\beta x_{ij} + u_i + \\varepsilon_{ij},\n$$\n\nwhere $\\beta$ is a fixed effect (e.g., treatment), $u_i \\sim \\mathcal{n}(0, \\sigma_u^2)$ is a random intercept for group $i$, and $\\varepsilon_{ij} \\sim \\mathcal{n}(0, \\sigma_\\varepsilon^2)$ is the residual error.\n\nthe random effect $u_i$ captures the correlation among observations within the same group: measurements from the same subject or cluster are more similar than measurements from different groups.\n\n## intraclass correlation coefficient (icc)\n\nthe **icc** quantifies the proportion of total variance attributable to the grouping factor:\n\n$$\n\\text{icc} = \\frac{\\sigma_u^2}{\\sigma_u^2 + \\sigma_\\varepsilon^2}.\n$$\n\n- icc $\\approx 0$: observations within groups are no more similar than observations between groups.\n- icc $\\approx 1$: nearly all variability is between groups; within-group observations are highly correlated.\n\nthe icc determines whether ignoring the grouping structure is safe. when icc is substantial, standard methods that assume independence will produce incorrect standard errors and p-values.\n\n## variance components\n\nin a **variance components model**, all factors are random:\n\n$$\ny_{ijk} = \\mu + a_i + b_{j(i)} + \\varepsilon_{ijk},\n$$\n\nwhere $a_i \\sim \\mathcal{n}(0, \\sigma_a^2)$ and $b_{j(i)} \\sim \\mathcal{n}(0, \\sigma_b^2)$ represent nested random effects.\n\n**restricted maximum likelihood** (reml) is the standard estimation method for variance components. unlike ordinary maximum likelihood, reml accounts for the loss of degrees of freedom due to estimating fixed effects, producing unbiased variance estimates.\n\n## applications to clustered data\n\nmixed models are essential when data have a **hierarchical structure**:\n\n- students nested within classrooms nested within schools.\n- repeated measurements nested within patients nested within hospitals.\n- cells nested within wells nested within experimental plates.\n\nignoring this structure and treating all observations as independent leads to:\n\n- underestimated standard errors (pseudo-replication).\n- inflated type i error rates.\n- misleading p-values.\n\nthe mixed model correctly partitions variability across levels of the hierarchy, producing valid inference even with unbalanced designs and missing data.\n\n[[simulation applied-stats-sim-6]]\n"
    },
    {
      "topicId": "applied-statistics",
      "topicTitle": "Applied Statistics",
      "routeSlug": "applied-statistics",
      "lessonSlug": "simulation-fitting",
      "lessonTitle": "Simulation and More Fitting",
      "x": 0.5014954805374146,
      "y": 0.4531627595424652,
      "searchText": "simulation and more fitting\n# simulation and more fitting\n\n## producing random numbers\n\nfor producing random numbers from arbitrary distributions, there are two main approaches: the **transformation method** and the **accept-reject method**.\n\n## transformation method\n\nthe transformation method proceeds in three steps:\n\n1. verify the pdf is normalized.\n2. compute the cumulative distribution function (cdf).\n3. invert the cdf.\n\n$$\nf(x) = \\int_{-\\infty}^x f(x') \\, dx'\n$$\n\n### example: exponential distribution\n\nconsider the exponential distribution:\n\n$$\nf(x) = \\lambda \\exp(-\\lambda x), \\quad x \\in [0, \\infty)\n$$\n\nthis is normalized. the cdf is:\n\n$$\nf(x) = 1 - \\exp(-\\lambda x)\n$$\n\ninverting gives:\n\n$$\nf^{-1}(p) = -\\frac{\\ln(1-p)}{\\lambda}\n$$\n\nto sample, draw $p$ uniformly from $[0,1]$ and compute $x = f^{-1}(p)$.\n\n## accept-reject method\n\nthe **accept-reject method** (also called the von neumann method) generates random samples from a proposal distribution and accepts or rejects them according to acceptance criteria.\n\nthe idea: given a target pdf $f(x)$ and a proposal distribution $g(x)$ with $f(x) \\leq m \\cdot g(x)$ for some constant $m$:\n\n1. sample $x$ from $g(x)$.\n2. sample $u$ uniformly from $[0, 1]$.\n3. accept $x$ if $u \\leq f(x) / (m \\cdot g(x))$; otherwise reject and repeat.\n\n```python\ndef accept_reject_sample(target_pdf, proposal_sample, proposal_pdf, m, num_samples):\n    samples = []\n    while len(samples) < num_samples:\n        x = proposal_sample()\n        u = random.uniform(0, 1)\n        if u <= target_pdf(x) / (m * proposal_pdf(x)):\n            samples.append(x)\n    return samples\n```\n\n## comparison of methods\n\n**monte carlo integration** converges as $1/\\sqrt{n}$ regardless of dimensionality, while deterministic numerical methods (e.g., trapezoidal rule) converge as $1/n^{2/d}$, where $d$ is the dimensionality. this means monte carlo becomes increasingly competitive for high-dimensional problems.\n\n[[simulation applied-stats-sim-3]]\n"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "agentbased",
      "lessonTitle": "Agent-Based Models and Stochastic Simulation",
      "x": 0.5346930623054504,
      "y": 0.5832178592681885,
      "searchText": "agent-based models and stochastic simulation\n# agent-based models and stochastic simulation\n\n## from equations to agents\n\nin many systems, the relevant actors are discrete individuals, not continuous fields. **agent-based models** (abms) simulate autonomous agents following local rules, and emergent collective behavior arises from their interactions.\n\nabms are particularly powerful when:\n\n- the population is **heterogeneous** (agents differ in attributes or behavior).\n- spatial structure matters (local interactions dominate over global averages).\n- stochasticity at the individual level drives macroscopic phenomena.\n\n## cellular automata: the game of life\n\n**conway's game of life** is the canonical deterministic agent-based model. on a 2d grid, each cell is alive or dead, and its state updates synchronously based on its eight neighbors:\n\n- a live cell **survives** if it has exactly 2 or 3 live neighbors; otherwise it dies.\n- a dead cell **is born** if it has exactly 3 live neighbors.\n\ndespite these simple rules, the game of life produces remarkable emergent behavior: gliders that translate across the grid, oscillators with fixed periods, and self-replicating structures. it is turing-complete, meaning it can in principle simulate any computation.\n\n[[simulation game-of-life]]\n\n## stochastic simulation and the gillespie algorithm\n\nwhen reactions involve small numbers of molecules, deterministic rate equations (odes) fail to capture the inherent randomness. the **gillespie algorithm** (stochastic simulation algorithm) provides exact trajectories from the chemical master equation.\n\nat each step:\n\n1. compute all reaction **propensities** $a_i$ (rate $\\times$ number of reactant combinations).\n2. compute the total propensity $a_0 = \\sum_i a_i$.\n3. draw the **waiting time** to the next reaction: $\\delta t \\sim \\text{exp}(a_0)$.\n4. select **which reaction** fires with probability $a_i / a_0$.\n5. update the state and repeat.\n\nthe algorithm generates sample paths that are statistically exact solutions of the master equation, at the cost of simulating one reaction at a time.\n\n## predator-prey dynamics\n\nthe **lotka-volterra model** describes the interaction between predators (foxes) and prey (rabbits). in the agent-based version:\n\n- rabbits reproduce with some probability at each step.\n- foxes eat nearby rabbits and reproduce; they die if they go too long without eating.\n- both species move randomly on a spatial grid.\n\nthe ode (mean-field) version predicts sustained oscillations:\n\n$$\n\\frac{dr}{dt} = \\alpha r - \\beta r f, \\qquad \\frac{df}{dt} = \\delta r f - \\gamma f.\n$$\n\nthe agent-based version reveals phenomena invisible to the ode: spatial clustering, local extinctions, and stochastic fluctuations that can drive one species to global extinction.\n\n## random walks and diffusion\n\n**random walks** are the simplest stochastic models. a walker on a lattice takes steps in random directions at each time step.\n\nkey results for an unbiased random walk in $d$ dimensions:\n\n- mean displacement: $\\langle \\mathbf{r}(t) \\rangle = 0$.\n- mean-squared displacement: $\\langle r^2(t) \\rangle = 2d \\, d \\, t$, where $d$ is the diffusion coefficient.\n- **recurrence**: the walker returns to the origin with probability 1 in 1d and 2d, but not in 3d and higher (**polya's theorem**).\n\nthe **langevin equation** provides a continuous-time description:\n\n$$\n\\frac{dx}{dt} = -\\frac{\\partial u}{\\partial x} + \\sqrt{2d} \\, \\xi(t),\n$$\n\nwhere $\\xi(t)$ is gaussian white noise with $\\langle \\xi(t) \\xi(t') \\rangle = \\delta(t - t')$.\n\n## applications of agent-based models\n\n- **epidemics**: sir models on contact networks, with heterogeneous transmission rates and super-spreaders.\n- **opinion dynamics**: voter models, bounded-confidence models, and polarization.\n- **flocking**: vicsek model, where agents align their velocity with neighbors plus noise, producing collective motion.\n- **traffic flow**: nagel-schreckenberg model for traffic jams as emergent phenomena.\n- **social networks**: information cascades and the spread of content through heterogeneous networks.\n\nthe advantage of agent-based modeling is its flexibility: any mechanism can be incorporated at the individual level, and the macroscopic behavior is observed rather than assumed.\n\n[[simulation lorenz-attractor]]\n"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "criticalPhenomena",
      "lessonTitle": "Critical Phenomena",
      "x": 0.6728882193565369,
      "y": 0.6717182993888855,
      "searchText": "critical phenomena\n# critical phenomena\n\n## universality\n\nnear a continuous phase transition, systems that are microscopically very different exhibit the same macroscopic behavior. this remarkable property is called **universality**: the critical exponents depend only on a few features of the system, specifically the spatial dimensionality $d$ and the symmetry of the order parameter.\n\nsystems in the same **universality class** share identical critical exponents. for example, the liquid-gas critical point and the 3d ising ferromagnet belong to the same class despite being physically distinct.\n\n## critical exponents and scaling laws\n\nnear the critical temperature $t_c$, thermodynamic quantities diverge or vanish as power laws. the **reduced temperature** $t = (t - t_c)/t_c$ measures distance from criticality.\n\nkey critical exponents:\n\n- **order parameter**: $m \\sim |t|^\\beta$ for $t < t_c$.\n- **susceptibility**: $\\chi \\sim |t|^{-\\gamma}$.\n- **heat capacity**: $c \\sim |t|^{-\\alpha}$.\n- **correlation length**: $\\xi \\sim |t|^{-\\nu}$.\n- **correlation function at $t_c$**: $g(r) \\sim r^{-(d-2+\\eta)}$.\n\nthese exponents are not independent. **scaling relations** connect them:\n\n$$\n\\alpha + 2\\beta + \\gamma = 2 \\qquad \\text{(rushbrooke)},\n$$\n\n$$\n\\gamma = \\nu(2 - \\eta) \\qquad \\text{(fisher)},\n$$\n\n$$\n\\nu d = 2 - \\alpha \\qquad \\text{(josephson / hyperscaling)}.\n$$\n\n## mean-field theory and its limitations\n\n**mean-field theory** replaces fluctuations with their average, yielding the landau free energy:\n\n$$\nf(m) = a_0 + a_2 t \\, m^2 + a_4 m^4 + \\cdots\n$$\n\nminimizing gives mean-field exponents: $\\beta = 1/2$, $\\gamma = 1$, $\\alpha = 0$, $\\nu = 1/2$.\n\nmean-field theory is exact above the **upper critical dimension** $d_c = 4$ for the ising model. below $d_c$, fluctuations are too strong to ignore, and the actual exponents differ from mean-field predictions.\n\n| exponent | mean-field | 2d ising | 3d ising |\n|----------|-----------|----------|----------|\n| $\\beta$  | 1/2       | 1/8      | 0.326    |\n| $\\gamma$ | 1         | 7/4      | 1.237    |\n| $\\nu$    | 1/2       | 1        | 0.630    |\n\n[[simulation phase-transition-ising-1d]]\n\n## the renormalization group\n\nthe **renormalization group** (rg) provides the theoretical framework for understanding universality and scaling. the idea is to systematically coarse-grain the system:\n\n1. **block spins**: group neighboring spins into blocks and define a new effective spin for each block.\n2. **rescale**: shrink the lattice back to its original size.\n3. **renormalize**: adjust the coupling constants so the partition function is preserved.\n\nthis defines a flow in the space of coupling constants. **fixed points** of the rg flow correspond to scale-invariant systems (critical points). the critical exponents are determined by the eigenvalues of the linearized rg transformation at the fixed point.\n\nnear a fixed point, the rg flow has **relevant** directions (which grow under iteration and drive the system away from criticality) and **irrelevant** directions (which shrink and do not affect universal behavior). this explains why microscopic details are irrelevant at the critical point.\n\n## correlation functions\n\nthe **two-point correlation function** measures how fluctuations at two points are statistically related:\n\n$$\ng(\\mathbf{r}) = \\langle s(\\mathbf{0}) \\, s(\\mathbf{r}) \\rangle - \\langle s \\rangle^2.\n$$\n\naway from $t_c$, correlations decay exponentially:\n\n$$\ng(r) \\sim e^{-r/\\xi},\n$$\n\nwhere $\\xi$ is the **correlation length**. at the critical point $\\xi \\to \\infty$, and correlations decay as a power law:\n\n$$\ng(r) \\sim \\frac{1}{r^{d-2+\\eta}},\n$$\n\nwhere $\\eta$ is the anomalous dimension. the divergence of $\\xi$ at $t_c$ means the system develops correlations on all length scales, which is the physical origin of scale invariance and universality.\n\n## finite-size scaling\n\nin simulations, the system size $l$ is finite, so true divergences cannot occur. **finite-size scaling** relates observables in a finite system to the infinite-system critical behavior:\n\n$$\n\\chi(t, l) = l^{\\gamma/\\nu} \\, \\tilde{\\chi}(t \\, l^{1/\\nu}),\n$$\n\nwhere $\\tilde{\\chi}$ is a universal scaling function. by plotting data for different system sizes as a function of $t l^{1/\\nu}$, all curves collapse onto a single master curve when the correct exponents are used. this **data collapse** is a powerful method for extracting critical exponents from numerical simulations.\n\n[[simulation ising-model]]\n"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "econophysics",
      "lessonTitle": "Econophysics",
      "x": 0.5244752168655396,
      "y": 0.5319133400917053,
      "searchText": "econophysics\n# econophysics\n\n## statistical mechanics of financial markets\n\n**econophysics** applies methods from statistical mechanics and complex systems to understand financial markets. the central observation is that financial time series share many statistical properties with physical systems: heavy-tailed distributions, long-range correlations, and scaling behavior.\n\n## brownian motion and stock prices\n\nthe simplest model treats log-returns as a random walk. let $s_t$ be the closing price and $x_t = \\log(s_t)$. the variance at lag $\\tau$ is:\n\n$$\n\\text{var}(\\tau) = \\langle (x_{t+\\tau} - x_t)^2 \\rangle.\n$$\n\nfor **geometric brownian motion** (the foundation of the black-scholes model), variance grows linearly with lag:\n\n$$\n\\text{var}(\\tau) \\propto \\tau.\n$$\n\nin practice, real stock returns deviate from pure brownian motion: they exhibit heavier tails (large moves are more frequent than a gaussian predicts) and volatility clustering (large changes tend to follow large changes).\n\n[[simulation stock-variance]]\n\n## the hurst exponent\n\nthe **hurst exponent** $h$ measures long-range dependence in time series. for the rescaled range $r/s$ of a time series with $n$ data points:\n\n$$\n\\frac{r}{s} \\sim c \\, n^h \\quad \\text{as } n \\to \\infty,\n$$\n\nwhere $c$ is a constant.\n\nthe value of $h$ reveals the nature of correlations:\n\n- $h = 0.5$: uncorrelated random walk (pure brownian motion).\n- $h > 0.5$: **persistent** (trending) behavior; positive long-range correlations.\n- $h < 0.5$: **anti-persistent** (mean-reverting) behavior; negative long-range correlations.\n\nfor self-similar time series, $h$ is directly related to the fractal dimension: $d = 2 - h$.\n\n[[simulation hurst-exponent]]\n\n## the fear-factor model\n\nif stock prices follow a biased random walk, let $q$ be the probability of the stock moving up under normal conditions. introduce a **collective fear event** with probability $p$ that forces all stocks down simultaneously.\n\nthe effective probabilities become:\n\n- stock goes up: $(1-p)q$.\n- stock goes down: $p + (1-p)(1-q)$.\n\nfor a neutral random walk, these must be equal:\n\n$$\n(1-p)q = p + (1-p)(1-q) \\implies q = \\frac{1}{2(1-p)}.\n$$\n\nas $p$ increases, the required upward probability $q$ must increase to compensate, creating an asymmetry that mimics the observed negative skewness in stock returns. the variance of returns includes a term proportional to $p$ that represents systematic risk.\n\n## bet hedging\n\n**bet hedging** is a strategy where an organism (or investor) sacrifices expected performance to reduce variance, analogous to portfolio diversification.\n\nin a stochastic growth model, consider a population with growth rate $r_t$ drawn from a distribution at each time step. the long-run growth rate is not the arithmetic mean but the **geometric mean**:\n\n$$\n\\bar{r}_{\\text{long-run}} = \\langle \\ln r_t \\rangle = \\langle r_t \\rangle - \\frac{1}{2} \\text{var}(r_t) + \\cdots\n$$\n\nthis **arithmetic-geometric inequality** means that variance always reduces long-run growth. an organism that reduces its variance (by hedging its bets across strategies) can outperform a specialist that maximizes expected growth, especially when the noise is large.\n\nkey insight: the optimal strategy depends on the **noise size** relative to the expected return.\n\n[[simulation bet-hedging]]\n"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "home",
      "lessonTitle": "Complex Physics",
      "x": 0.6289456486701965,
      "y": 0.5685654282569885,
      "searchText": "complex physics\n# complex physics\n\n## course overview\n\ncomplex physics studies systems composed of many interacting components whose collective behavior cannot be predicted from individual parts alone. these systems exhibit **emergent phenomena** such as phase transitions, self-organization, power-law distributions, and fractal geometry.\n\n- classical physics: few-body systems, exact solutions, linear superposition.\n- complex physics: many-body interactions, statistical descriptions, nonlinear dynamics, universality.\n\ncore approach:\n\n1. identify the relevant degrees of freedom and their interactions.\n2. use statistical mechanics to connect microscopic rules to macroscopic observables.\n3. recognize universal scaling behavior near critical points.\n4. simulate complex systems computationally when analytical solutions fail.\n\n## why this topic matters\n\n- phase transitions underpin phenomena from magnetism to superconductivity.\n- percolation theory models fluid flow through porous media, disease spreading, and network resilience.\n- self-organized criticality explains power laws in earthquakes, forest fires, and biological evolution.\n- network science describes the structure of the internet, social systems, and gene regulation.\n- agent-based models capture emergent collective behavior from simple local rules.\n- econophysics applies statistical mechanics to financial markets and wealth distributions.\n\n## key mathematical ideas\n\n- partition functions, free energy, and thermodynamic observables.\n- order parameters, critical exponents, and scaling relations.\n- renormalization group and universality classes.\n- power-law distributions and fractal dimensions.\n- monte carlo sampling and markov chain methods.\n- graph theory and network metrics.\n\n## prerequisites\n\n- probability and statistical reasoning.\n- calculus and linear algebra.\n- basic thermodynamics and classical mechanics.\n- familiarity with python for computational exercises.\n\n## recommended reading\n\n- thurner, hanel, and klimek, *introduction to the theory of complex systems*.\n- sethna, *statistical mechanics: entropy, order parameters, and complexity*.\n- newman, *networks: an introduction*.\n\n## learning trajectory\n\nthis module is organized from equilibrium foundations to complex emergent behavior:\n\n- statistical mechanics: ensembles, partition functions, and the ising model.\n- phase transitions: mean-field theory, monte carlo simulation, order parameters.\n- critical phenomena: universality, scaling laws, renormalization group.\n- percolation and fractals: connectivity thresholds, fractal dimension, self-similarity.\n- self-organized criticality: sandpile models, avalanches, power-law distributions.\n- networks: graph metrics, scale-free structures, dynamics on networks.\n- agent-based models: stochastic simulation, gillespie algorithm, cellular automata.\n- econophysics: brownian motion in markets, hurst exponent, bet hedging.\n"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "Networks",
      "lessonTitle": "Networks",
      "x": 0.5603526830673218,
      "y": 0.6237884163856506,
      "searchText": "networks\n# networks\n\n## graph theory basics\n\na **network** (graph) consists of nodes (vertices) connected by edges (links). networks provide a natural language for describing complex systems where relationships between components matter as much as the components themselves.\n\nexamples of real-world networks:\n\n- **social networks**: individuals connected by friendships or interactions.\n- **world wide web**: pages connected by hyperlinks.\n- **biological networks**: proteins connected by interactions, genes by regulatory links.\n- **infrastructure**: power grids, transportation systems, the internet.\n\n## network metrics\n\nkey quantities that characterize a network:\n\n- **degree** $k_i$: the number of edges connected to node $i$. the **degree distribution** $p(k)$ describes the probability that a randomly chosen node has degree $k$.\n- **clustering coefficient**: measures the fraction of a node's neighbors that are also connected to each other. high clustering indicates **cliquishness**.\n- **betweenness centrality**: the fraction of shortest paths between all pairs of nodes that pass through a given node. high centrality indicates a hub or bottleneck.\n- **connectedness**: a measure of resilience. how many nodes must be removed to disconnect the network?\n- **modularity**: the strength of division into communities. zero modularity means no meaningful partition.\n\nthe **amplification factor** of a node in an undirected graph is $\\mathcal{a} = k - 1$. the network-average amplification factor involves the second moment of the degree distribution:\n\n$$\n\\langle \\mathcal{a} \\rangle = \\frac{\\langle k^2 \\rangle}{\\langle k \\rangle} - 1.\n$$\n\nthis quantity diverges for scale-free networks with exponent $\\gamma \\leq 3$, with profound consequences for epidemic spreading and network robustness.\n\n## small-world networks\n\n**small-world networks** (watts and strogatz, 1998) combine two properties:\n\n- **high clustering**: like a regular lattice, neighbors of a node tend to be connected.\n- **short path lengths**: like a random graph, any two nodes are connected by a short chain.\n\nthe watts-strogatz model starts from a regular ring lattice and randomly rewires each edge with probability $p$. even a small rewiring probability ($p \\sim 0.01$) dramatically reduces the average path length while preserving high clustering.\n\nthe **six degrees of separation** phenomenon (milgram, 1967) is a manifestation of the small-world property in social networks.\n\n## scale-free networks\n\n**scale-free networks** have a degree distribution that follows a power law:\n\n$$\np(k) \\sim k^{-\\gamma},\n$$\n\ntypically with $2 < \\gamma < 3$. this means a few nodes (hubs) have very many connections, while most nodes have few.\n\nexamples of scale-free networks:\n\n- the world wide web ($\\gamma \\approx 2.1$ for in-degree).\n- protein interaction networks.\n- citation networks.\n- software dependency graphs.\n\n[[simulation scale-free-network]]\n\n## preferential attachment\n\nthe **barabasi-albert model** (1999) generates scale-free networks through **preferential attachment**: new nodes connect preferentially to existing nodes that already have many connections (\"the rich get richer\").\n\nalgorithm:\n\n1. start with $m_0$ connected nodes.\n2. add new nodes one at a time, each connecting to $m$ existing nodes.\n3. the probability of connecting to node $i$ is proportional to its degree: $\\pi(k_i) = k_i / \\sum_j k_j$.\n\nthis produces a power-law degree distribution with exponent $\\gamma = 3$.\n\n## dynamics on networks\n\nnetworks are not just static structures; processes unfold on them:\n\n- **epidemic spreading** (sir/sis models): on scale-free networks, the epidemic threshold vanishes in the thermodynamic limit, meaning even weakly infectious diseases can spread.\n- **diffusion and synchronization**: random walks on networks explore hubs quickly; coupled oscillators synchronize more easily on networks with high connectivity.\n- **information cascades**: content spreads through social networks via threshold mechanisms.\n\n## robustness and attacks\n\nnetworks respond differently to random failures versus targeted attacks:\n\n- **random failure**: removing random nodes has little effect on scale-free networks because most nodes have low degree.\n- **targeted attack**: removing hubs rapidly fragments the network, dramatically increasing path lengths and disconnecting components.\n\nthis **robustness-yet-fragility** property of scale-free networks has implications for infrastructure protection, disease control, and cybersecurity.\n"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "percolation_and_fractals",
      "lessonTitle": "Percolation and Fractals",
      "x": 0.670404851436615,
      "y": 0.642130970954895,
      "searchText": "percolation and fractals\n# percolation and fractals\n\n## percolation theory\n\n**percolation theory** studies the connectivity of random media. the fundamental question is: when does a connected pathway spanning the entire system first appear?\n\nin **site percolation** on a lattice, each site is independently occupied with probability $p$ and empty with probability $1-p$. occupied neighbors form clusters.\n\n- for small $p$, only small isolated clusters exist.\n- at the **percolation threshold** $p_c$, a giant cluster first spans the system.\n- for $p > p_c$, the giant cluster contains a finite fraction of all sites.\n\nthe percolation threshold depends on the lattice geometry:\n\n| lattice | $p_c$ (site) |\n|---------|-------------|\n| square | 0.5927 |\n| triangular | 0.5000 |\n| honeycomb | 0.6962 |\n\nnear $p_c$, the system exhibits critical behavior analogous to thermal phase transitions.\n\n[[simulation percolation]]\n\n## critical exponents in percolation\n\nnear the threshold, key quantities follow power laws in $|p - p_c|$:\n\n- **order parameter** (fraction in spanning cluster): $p_\\infty \\sim (p - p_c)^\\beta$ for $p > p_c$.\n- **mean cluster size** (excluding the spanning cluster): $\\langle s \\rangle \\sim |p - p_c|^{-\\gamma}$.\n- **correlation length** (typical cluster radius): $\\xi \\sim |p - p_c|^{-\\nu}$.\n\nin 2d: $\\beta = 5/36$, $\\gamma = 43/18$, $\\nu = 4/3$. these exponents are universal within the percolation universality class.\n\n## the bethe lattice\n\nthe **bethe lattice** (cayley tree) is an infinite tree where each node has exactly $z$ neighbors. percolation on the bethe lattice is exactly solvable:\n\n$$\np_c = \\frac{1}{z - 1}.\n$$\n\nfor $z = 3$: $p_c = 1/2$. the bethe lattice provides the mean-field theory for percolation and gives exact critical exponents $\\beta = 1$, $\\gamma = 1$, $\\nu = 1/2$.\n\n[[simulation bethe-lattice]]\n\n## fractals and self-similarity\n\na **fractal** is a geometric object that exhibits self-similarity: it looks similar at different scales of magnification. fractals arise naturally in percolation clusters at criticality.\n\nthe **fractal dimension** $d_f$ characterizes how the mass of an object scales with its linear size:\n\n$$\nm(l) \\sim l^{d_f}.\n$$\n\nfor ordinary objects in $d$ dimensions, $d_f = d$. for fractals, $d_f$ is typically non-integer.\n\nexamples:\n\n- koch snowflake: $d_f = \\log 4 / \\log 3 \\approx 1.26$.\n- sierpinski triangle: $d_f = \\log 3 / \\log 2 \\approx 1.58$.\n- percolation cluster at $p_c$ in 2d: $d_f = 91/48 \\approx 1.896$.\n\n[[simulation fractal-dimension]]\n\n## the mandelbrot set\n\nthe **mandelbrot set** is defined in the complex plane as the set of values $c$ for which the iteration\n\n$$\nz_{n+1} = z_n^2 + c, \\qquad z_0 = 0,\n$$\n\nremains bounded. the boundary of the mandelbrot set is a fractal with infinite detail at every scale.\n\nthe **escape-time algorithm** colors each point $c$ by the number of iterations needed for $|z_n|$ to exceed a threshold (typically 2), producing the iconic visualizations of the set.\n\n[[simulation mandelbrot-fractal]]\n\n## box-counting dimension\n\nthe **box-counting method** provides a practical way to estimate the fractal dimension of any set:\n\n1. cover the set with boxes of side length $\\epsilon$.\n2. count the number $n(\\epsilon)$ of boxes needed.\n3. the fractal dimension is $d_f = -\\lim_{\\epsilon \\to 0} \\frac{\\log n(\\epsilon)}{\\log \\epsilon}$.\n\nin practice, $\\log n(\\epsilon)$ is plotted against $\\log(1/\\epsilon)$, and $d_f$ is estimated from the slope of the linear region.\n"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "phaseTransitions",
      "lessonTitle": "Phase Transitions",
      "x": 0.7053886651992798,
      "y": 0.7139297723770142,
      "searchText": "phase transitions\n# phase transitions\n\n## ising model simulation\n\nthe ising model demonstrates phase transitions in magnetic systems. watch how the system orders below the critical temperature.\n\n[[simulation ising-model]]\n\n## mean-field hamiltonian\nby approximating the energy acting on a spin in the 1d ising model, not as the sum of nearest neighbors but instead the mean of the chain, we may simplify interesting terms. we obtain the mean-field hamiltonian, \n    \n$$\n\\begin{align*}\n    \\mathcal{h}_\\mathrm{mf}\n    &= \n    \\frac{j n z}{2} m^2 \n    - \\left( j z m + h \\right) \\sum_i s_i.\n\\end{align*}\n$$\nhere $z$ is number of nearest-neighbor spins and division by 2 is\nfor avoiding overlap.\n\n## mean-field hamiltonian (derivation)\n#### hamiltonian\nthe hamiltonian of the ising model is\n$$\n    \\mathcal{h} \n    = \n    -j \\sum_{\\left<i j\\right>} s_i s_j - h \\sum_i s_i.\n$$\n\nwe cannot caliculate partition function directly except for \n1d-lattice case and 2d-lattice case.\nhowever, by approximating hamiltonian with mean field, we can \nanalytically obtain partition function.\nlet's approxiomate hamiltonian.\n#### ignoring high-order fluctuation\nfirst, let's replace $s_i$ with mean $\\left< s_i \\right>$ and \nfluctuation from mean $\\delta s_i = s_i - \\left< s_i \\right>$.\n$$\n\\begin{align*}\n    s_i \n    &= \n    \\left< s_i \\right> + \\delta s_i\n    \\\\&= \n    \\left< s_i \\right> \n    + \\left( s_i - \\left< s_i \\right> \\right)\n\\end{align*}\n$$\nhere $\\left< s_i \\right>$ means\n$$\n    \\left< s_i \\right>\n    =\n    \\frac{1}{z} \\sum_{n=1}^{2^n} s_i \\exp \\left( -\\beta e_n \\right).\n$$\n$n$ is index of state \n(total number of all state is $2^n$, $n$ is number of spin). \ninside of sum of first term of hamiltonian becomes\n$$\n\\begin{align*}\n    s_i s_j\n    &=\n    \\left( \n        \\left< s_i \\right> + \\delta s_i\n    \\right) \n    \\left( \n        \\left< s_j \\right> + \\delta s_j\n    \\right) \n    \\\\&=\n    \\left< s_i \\right> \\left< s_j \\right>\n    + \n    \\left< s_i \\right> \\delta s_j\n    + \n    \\delta s_i \\left< s_j \\right> \n    + \n    \\delta s_i \\delta s_j\n    \\\\& \\approx\n    \\left< s_i \\right> \\left< s_j \\right>\n    + \n    \\left< s_i \\right> \\delta s_j\n    + \n    \\delta s_i \\left< s_j \\right> \n    \\\\&=\n    \\left< s_i \\right> \\left< s_j \\right>\n    + \n    \\left< s_i \\right> \n    \\left( \n        s_j - \\left< s_j \\right>\n    \\right) \n    + \n    \\left( \n        s_i - \\left< s_i \\right>\n    \\right) \n    \\left< s_i \\right> \n    \\\\&=\n    \\left< s_i \\right> \\left< s_j \\right>\n    + \n    \\left< s_i \\right> \n    \\left( \n        s_j - \\left< s_j \\right>\n    \\right) \n    + \n    \\left( \n        s_i - \\left< s_i \\right>\n    \\right) \n    \\left< s_i \\right> \n    \\\\&=\n    -\\left< s_i \\right>^2\n    + \n    \\left< s_i \\right> \n    \\left( \n        s_i + s_j \n    \\right) \n\\end{align*}\n$$\nwe ignore the fluctuation with second order.\nwe also used \n$$\n\\left< s_1 \\right> \n= \\left< s_2 \\right> \n= \\cdots\n= \\left< s_i \\right> \n= \\cdots\n= \\left< s_n \\right>\n$$\nbecause all spins are equivalent.\n\nwhat we need to notice is that magnetization in equilibrium state\nis equivalent to mean of spin $\\left< s_i \\right>$.\n$$\n\\begin{align*}\n    m \n    &= \n    \\frac{1}{n} \\sum_{i=1}^n \\left< s_i \\right>\n    \\\\&= \n    \\frac{1}{n} \\left< s_i \\right> \\sum_{i=1}^n\n    \\\\&= \n    \\frac{1}{n} \\left< s_i \\right> n\n    \\\\&= \n    \\left< s_i \\right>\n\\end{align*}\n$$\nthus we can replace $\\left< s_i \\right>$ with $m$.\n$$\n    s_i s_j\n    \\approx \n    - m^2 + m(s_i + s_j)\n$$\n#### mean-field hamiltonian\nthen, mean-field hamiltonian $\\mathcal{h}_\\mathrm{mf}$ beocomes\n$$\n\\begin{align*}\n    \\mathcal{h}_\\mathrm{mf}\n    &= \n    -j \\sum_{\\left<i j\\right>} \n    \\left(- m^2 + m(s_i + s_j) \\right) \n    - h \\sum_i s_i\n    \\\\&= \n    j m^2 \\sum_{\\left<i j\\right>}  \n    - j \\sum_{\\left<i j\\right>} m(s_i + s_j)\n    - h \\sum_i s_i\n\\end{align*}\n$$\nlet's think about first term.\n$$\n\\begin{align*}\n    j m^2 \\sum_{\\left<i j\\right>}\n    &=\n    j m^2 \\frac{1}{2} \n    \\sum_{i} \\sum_{\\left<j\\right>}\n    \\\\&=\n    j m^2 \\frac{1}{2} \n    \\sum_{i=1}^n z\n    \\\\&=\n    \\frac{j n z}{2} m^2 \n\\end{align*}\n$$\nhere $z$ is number of nearest-neighbor spins and division by 2 is\nfor avoiding overlap.\n\nmove on to second term.\n$$\n\\begin{align*}\n    - j \\sum_{\\left<i j\\right>} m(s_i + s_j)\n    &=\n    - j m \n    \\left( \n        \\sum_{\\left<i j\\right>} s_i + \\sum_{\\left<i j\\right>} s_j\n    \\right)\n    \\\\&=\n    - 2 j m \\sum_{\\left<i j\\right>} s_i\n    \\\\&=\n    - 2 j m \\frac{1}{2} \\sum_{i} s_i \\sum_{\\left<j\\right>} \n    \\\\&=\n    - j z m  \\sum_{i} s_i\n\\end{align*}\n$$\nfinally, mean-field hamiltonian becomes\n$$\n\\begin{align*}\n    \\mathcal{h}_\\mathrm{mf}\n    &= \n    \\frac{j n z}{2} m^2 \n    - j z m  \\sum_{i} s_i\n    - h \\sum_i s_i\n    \\\\&= \n    \\frac{j n z}{2} m^2 \n    - \\left( j z m + h \\right) \\sum_i s_i\n\\end{align*}\n$$\n\n## mf: z, m, tc, f & critical exponent\nthe partition function, magnetization, critical temperature and free energy, in this approximation, become:\n$$\n    \\begin{align*}\n    z_{\\mathrm{mf}}\n    &= \n    \\exp \n    \\left(\n        - \\beta\\frac{j n z}{2} m^2 \n    \\right)\n    \\left[\n    2\\cosh\n    \\left(\n        \\beta j z m + \\beta h\n    \\right)\n    \\right]^n\n    \\\\\n    m \n    &= \\left<s_i\\right>\n    =\n    \\tanh\n    \\left(\n        \\beta j z m + \\beta h \n    \\right)\n    \\\\\n    t_c &= \\frac{jz}{k_b}\n    \\\\\n    f_{\\mathrm{mf}} &=\n    \\frac{jnz}{2}m^2\n    - \\frac{n}{\\beta} \\ln\n    \\left[\n        2 \\cosh \\left(\\beta jzm + \\beta h \\right)\n    \\right]\n\\end{align*}\n$$\n\n## mf: z, m, tc, f & critical exponent (derivation)\n#### mean-field partition function\nthe partition function of the ising model is\n$$\n    \\begin{align*}\n        z\n        &= \n        \\mathrm{tr}\n        \\left(\n        e^{-\\beta \\mathcal{h}}\n        \\right)\n        &= \n        \\sum_{\\{s_i\\}} \n        e^{-\\beta \\mathcal{h}\\left(\\{s_i\\}\\right)}\n        &= \n        \\sum_n^{2^n} \n        \\left\\langle n \\right\\vert\n        e^{-\\beta \\mathcal{h}}\n        \\left\\vert n \\right\\rangle\n        &= \n        \\sum_{n}^{2^n} \n        e^{-\\beta e_n}\n    \\end{align*}\n$$\nhere $n$ is index of stat"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "selfOrganizedCriticality",
      "lessonTitle": "Self-Organized Criticality",
      "x": 0.6094433069229126,
      "y": 0.6610114574432373,
      "searchText": "self-organized criticality\n# self-organized criticality\n\n## the concept of soc\n\n**self-organized criticality** (soc) is a property of dynamical systems that spontaneously evolve toward a critical state without any external tuning of parameters. unlike equilibrium phase transitions, where criticality requires fine-tuning the temperature to $t_c$, soc systems naturally drive themselves to the critical point.\n\nat criticality, the system displays **scale invariance** in both space and time: events of all sizes occur, with their frequency following power-law distributions.\n\nkey signatures of soc:\n\n- power-law distributed event sizes (avalanches).\n- $1/f$ noise in temporal fluctuations.\n- fractal spatial structure.\n- separation of time scales between slow driving and fast relaxation.\n\n## the sandpile model (btw)\n\nthe **bak-tang-wiesenfeld sandpile model** (1987) is the paradigmatic example of soc.\n\non a 2d grid, each site $i$ has a height $z_i$. sand is added one grain at a time at random sites. when $z_i$ exceeds a threshold $z_c$ (typically 4 for a square lattice), the site **topples**:\n\n$$\nz_i \\to z_i - 4, \\qquad z_j \\to z_j + 1 \\quad \\text{for each neighbor } j.\n$$\n\ntoppling can trigger neighbors to topple in turn, creating an **avalanche**. grains that topple off the boundary are lost (open boundary conditions).\n\nafter a transient, the system reaches a statistically steady state where the avalanche size distribution follows a power law:\n\n$$\np(s) \\sim s^{-\\tau},\n$$\n\nwith $\\tau \\approx 1.1$ in 2d. the distribution of avalanche areas, durations, and lifetimes also follow power laws.\n\n[[simulation sandpile-model]]\n\n## the bak-sneppen model\n\nthe **bak-sneppen model** (1993) applies soc to biological evolution. consider $n$ species arranged on a ring, each with a random fitness value $f_i \\in [0, 1]$.\n\nat each time step:\n\n1. find the species with the **lowest fitness**.\n2. replace its fitness and the fitness of its two neighbors with new random values from $[0, 1]$.\n\nthe model self-organizes to a critical state where most fitness values exceed a threshold $f_c \\approx 0.667$ (in 1d). below this threshold, species are unstable and trigger cascading replacements, which are the **avalanches** of the model.\n\navalanches in the bak-sneppen model are correlated both **spatially** (consecutive replacements cluster in space) and **temporally** (avalanche durations are power-law distributed).\n\n[[simulation bak-sneppen]]\n\n## first-return times of random walks\n\nthe connection between soc and random walks provides theoretical insight. consider a 1d random walk starting at the origin. the **first-return time** $t$ is the number of steps until the walker returns to the origin.\n\nfor an unbiased random walk:\n\n$$\np(t = 2n) \\sim n^{-3/2},\n$$\n\na power law with exponent $-3/2$. this result connects to soc because avalanches in many soc models can be mapped to random-walk first-return problems.\n\n[[simulation random-walk-first-return]]\n\n## non-equilibrium steady states\n\nsoc systems are inherently **out of equilibrium**: energy (or sand, or fitness) is continuously injected and dissipated. the critical state is a non-equilibrium steady state where the rate of injection balances the average rate of dissipation.\n\nthis distinguishes soc from equilibrium critical phenomena:\n\n- no detailed balance.\n- no free energy or partition function.\n- the steady state is maintained by the balance of driving and dissipation.\n- fluctuations (avalanches) are the mechanism of transport.\n\n## power laws in nature\n\nsoc has been proposed as an explanation for power-law distributions observed in:\n\n- **earthquakes**: the gutenberg-richter law $\\log n(m) = a - bm$ relates earthquake magnitude $m$ to frequency.\n- **forest fires**: fire size distributions in some models follow power laws.\n- **neuronal avalanches**: cascades of neural activity in cortical circuits show power-law size distributions.\n- **solar flares**: the energy distribution of solar flares follows a power law over several decades.\n\nnot all power laws indicate soc. alternative mechanisms include preferential attachment, multiplicative processes, and finite-size effects. careful statistical testing is needed to distinguish true power laws from other heavy-tailed distributions.\n"
    },
    {
      "topicId": "complex-physics",
      "topicTitle": "Complex Physics",
      "routeSlug": "complex-physics",
      "lessonSlug": "statisticalMechanics",
      "lessonTitle": "Statistical Mechanics",
      "x": 0.7339248657226562,
      "y": 0.7460019588470459,
      "searchText": "statistical mechanics\n# statistical mechanics\n\n## microcanonical ensemble\nthe central assumption of statistical mechanics is the principle of *equal a priori probabilities*, which argues that all states that share an energy level are equally likely to exist in the system.\n\nwith this assumption one can say that the system become particular state\n$i$ with probability\n$$\n    p_i = \\frac{1}{\\omega}.\n$$\nhere $\\omega$ is the total number of (quantum) microstate of the \nsystem with energy $e$.\n\n\naccording to ludwig boltzmann, entropy of system with microcanonical \nensemble of the system with fixed energy $e$ is expressed as\n$$\n    s = k_\\mathrm{b} \\ln \\omega.\n$$ \nhere $k_\\mathrm{b}$ is boltzmann's constant.\n\nin this system, temperature $t$ is statistically defined as \n$$ \n\\begin{align*}\n    \\frac{1}{t} \n    &= \\frac{\\partial s}{\\partial e} \n    &= k_\\mathrm{b} \\frac{\\partial}{\\partial e} \\ln \\omega\n\\end{align*}\n$$\n\n\n## canonical ensemble\n#### temperature of system and reservoir become same in equilibrium\nlet's consider subsystem of whole system of microcanonical ensemble. \nfor simplicity, we only consider only one subsystem and assuming it \nis small enough comparing to the rest of the system. let's say this \nsmall part as \n\"system\" and rest of enoumous part of the original microcanonical \nsystem as \"reservoir\" or \"heat bath\".\nby defining the system's energy as $e_\\mathrm{s}$ and reservoir's \nenergy as $e_\\mathrm{r}$, we consider the energy exchange \nbetween these two. because total energy conserved, the sum of two \nenergy is constant value.\n$$ \n    e_\\mathrm{t} = e_\\mathrm{s} + e_\\mathrm{r} \n$$\nhere $e_\\mathrm{t}$ is total energy of whole system.\n\nlet's think about number of state.\n$\\omega(e_\\mathrm{t})$ is the total number of states with energy \n$e_\\mathrm{t}$.\n$\\omega(e_\\mathrm{s}, e_\\mathrm{r})$ is the total number of states with \nsystem has energy $e_\\mathrm{s}$ and system has energy $e_\\mathrm{r}$.\nit can be the product of total number of state of system and reservoir.\n$$\n    \\omega(e_\\mathrm{s}, e_\\mathrm{r})\n    = \\omega_\\mathrm{s}(e_\\mathrm{s}) \\omega_\\mathrm{r}(e_\\mathrm{r})\n$$\nentropy of whole system become\n$$\n    s_\\mathrm{t} =  k_\\mathrm{b} \\ln \\omega(e_\\mathrm{s}, e_\\mathrm{r}).\n$$\nentropy of the system and reservoir become\n$$\n    s_\\mathrm{s} =  k_\\mathrm{b} \\ln \\omega(e_\\mathrm{s}),\n$$\n$$\n    s_\\mathrm{r} =  k_\\mathrm{b} \\ln \\omega(e_\\mathrm{r}).\n$$\nthus total entropy become sum of system and reservoir.\n$$\n    s_\\mathrm{t} = s_\\mathrm{s} + s_\\mathrm{r}.\n$$\n\nprobability of finding the state system energy $e_\\mathrm{s}$ and \nreservoir energy $e_\\mathrm{r}$ is\n$$\n\\begin{align*}\n    p(e_\\mathrm{s}, e_\\mathrm{r}) \n    &= \\frac{\\omega(e_\\mathrm{s}, e_\\mathrm{r})}{\\omega(e_\\mathrm{t})}\n    \\&= \\frac{\\omega_\\mathrm{s}(e_\\mathrm{s}) \n    \\omega_\\mathrm{r}(e_\\mathrm{r})}\n    {\\omega(e_\\mathrm{t})}\n\\end{align*}\n$$\nmost probable state (thermodynamical equilibrium state) satisfies\n$$\n    \\frac{\\partial p(e_\\mathrm{s}, e_\\mathrm{r})}{\\partial e_\\mathrm{s}}\n    =0\n$$\nthis condition does not change with logarithmic scale.\n$$\n    \\frac{\\partial \\ln \n    p(e_\\mathrm{s}, e_\\mathrm{r})}{\\partial e_\\mathrm{s}}\n    =0\n$$\nusing number of state, this condition can be expressed as \n$$\n\\begin{align*}\n    0 &= \n        \\frac{\\partial \\ln \n        p(e_\\mathrm{s}, e_\\mathrm{r})}{\\partial e_\\mathrm{s}}\n        \\&= \n        \\frac{\\partial}{\\partial e_\\mathrm{s}} \n        \\ln \\frac{\\omega_\\mathrm{s}(e_\\mathrm{s}) \n        \\omega_\\mathrm{r}(e_\\mathrm{r})}{\\omega(e)}\n        \\&= \n        \\frac{\\partial}{\\partial e_\\mathrm{s}} \n        \\ln \\omega_\\mathrm{s}(e_\\mathrm{s}) \n        +\n        \\frac{\\partial}{\\partial e_\\mathrm{r}} \n        \\frac{\\partial e_\\mathrm{r}}{\\partial e_\\mathrm{s}} \n        \\ln \\omega_\\mathrm{r}(e_\\mathrm{r})\n        \\&= \n        \\frac{1}{k_\\mathrm{b}}\n        \\frac{\\partial s_\\mathrm{s}}{\\partial e_\\mathrm{s}} \n        -\n        \\frac{1}{k_\\mathrm{b}}\n        \\frac{\\partial s_\\mathrm{r}}{\\partial e_\\mathrm{r}} \n        \\&= \n        \\frac{t_\\mathrm{s}}{k_\\mathrm{b}}\n        -\n        \\frac{t_\\mathrm{r}}{k_\\mathrm{b}}.\n\\end{align*}\n$$\nhere $t_\\mathrm{s}$ is temperature of system and $t_\\mathrm{r}$ is \ntemperature of reservoir.\nfrom this result, we can say in equilibrium system's temperature \nand reservoir's temperature is same.\n$$\n        t_\\mathrm{s} = t_\\mathrm{r}\n\n$$\nif two system and reservoir exchange the energy, they have same \ntemperature.\n\n#### boltzmann distribution \nwhen system is in state $i$ and has energy $e_i$, reservoir has energy\n$e_\\mathrm{t} - e_i$, probability of happening this state $i$ is \n$$\n\\begin{align*}\n    p_i \n    &\\propto \n        \\omega_\\mathrm{r}(e_\\mathrm{t} - e_i) \n    \\&= \n        \\exp \n        \\left[ \\frac{1}{k_\\mathrm{b}} s_r(e_\\mathrm{t} - e_i) \n\\right]\n    \\approx \n        \\exp \\left[ \\frac{1}{k_\\mathrm{b}} \n        \\left(s_\\mathrm{r}(e_\\mathrm{t}) \n        - \\left. \n        \\frac{\\mathrm{d}s_\\mathrm{r}}{\\mathrm{d}e} \n        \n\\right|_{e=e_\\mathrm{t}}e_i\n\\right)\n        \n\\right]\n    \\&= \n        \\exp \\left[ \\frac{1}{k_\\mathrm{b}} \n        \\left(s_\\mathrm{r}(e_\\mathrm{t}) \n        - \\frac{e_i}{t_\\mathrm{r}}\n\\right)\n        \n\\right]\n    \\&\\propto \n        \\exp \\left( \n        -\\frac{e_i}{k_\\mathrm{b}t_\\mathrm{r}} \n        \n\\right)\n\\end{align*}\n$$\nwe used taylor series expansion because $e_\\mathrm{t}\\gg e_i$.\nthe term \n$\\exp \\left(-\\frac{e_i}{k_\\mathrm{b}t} \n\\right)$\ncalled \"boltzmann distribution\".\nthe probability that state $i$ happens is proportional to boltzmann \ndistribution\n$p_i \\propto \\exp \\left(-\\frac{e_i}{k_\\mathrm{b}t} \n\\right)$.\n\n#### partition function, free energy and thermodynamical observable\nthe partition function is defined as the sum of the boltzmann factor \nof all states of system.\n$$\n\\begin{align*}\n    z &= \\sum_i \\exp \\left({-\\frac{e_i}{k_\\mathrm{b}t}} \n\\right)\n        \\&= \\sum_i \\exp \\left({-\\beta e_i}\n\\right).\n\\end{align*}\n$$\nhere $\\beta = \\frac{1}{k_\\mathrm{b}t}$.\nthus probability of finding system with state $i$ with energy $e_i$ \nbe"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "contapprox",
      "lessonTitle": "Continuum Approximation",
      "x": 0.8155340552330017,
      "y": 0.5725803375244141,
      "searchText": "continuum approximation\n# continuum approximation\n\n\n\n## introduction\nthe physics of continuum mechanics, requires that a mass of particles can be \nmodelled as continuous matter where the particles are infinitesimal. \nthis approximation depends on the degree of precision required, as benny puts it;\n\n\"whether a given number of molecules is large enough to warrant the use of\na smooth continuum description of matter depends on the desired precision. \nsince matter is never continuous at sufficiently high precision, continuum \nphyiscs is always an approximation. but as long as the fluctuations in \nphysical quantities caused by the discreteness of matter are smaller than \nthe desired precision, matter may be taken to be continuous. to observe the \ncontinuity, one must so to speak avoid looking too sharply at material bodies. \nfontenelle stated in a similar context that; \n\n\"science originates from curiosity and bad eyesight\".\"\n\nfrom physics of continuous matter 2nd edition by benny lautrup\n\n\n\n## density fluctuations\nthe density of a pure gas is given as;\n$$\n\\rho = \\frac{n m}{v}\n$$\nwhere $n$ is the number of molecules, $v$ is the volume and $m$ is the mass of the molecules.\nfrom general statistics, it can be shown that the fluctuations in $n$ follows the rms of the number of molecules and since the density is linear depended on $n$ this gives;\n$$\n\\frac{\\delta \\rho}{\\rho} = \\frac{\\delta n}{n} = \\frac{1}{\\sqrt{n}}\n$$\nso if we require a relative precision of $\\epsilon = 10^{-3} > \\frac{\\delta \\rho}{\\rho} $ in the density fluctuations there must be $n > \\epsilon^{-2}$ molecules. they occupy a volume of $\\epsilon^{-2}l_{molecule}^3$, where $l_{molecule}$ is the molecular seperation length. \nat the scale of $l_{molecule}$ the continuum approximation completely breaks down, and to ensure correct approximation within a certain precision the minimum cell size that we consider is given as;\n$$\nl_{micro} = \\epsilon^{-2}l_{molecule}^3=\\epsilon^{-2} \\left( \\frac{m_{molecule}}{\\rho n_a} \\right)\n$$\n$$\nl_{molecule} =\\left( \\frac{v}{n} \\right)^{1/3} = \\left( \\frac{m_{molecule}}{\\rho n_a} \\right)^{1/3} \n$$\nwhere $l_{micro}^*$ is the sidelength of the cubic cell that satisfies the precision condition, $m_{molecule}$ is the molar mass of the substance.\n\n## macroscopic smoothness\nanother criteria for the continuum approximation is the macroscopic smoothness. \nwe require the relative change in density between cells to be less than the \nprecision $\\epsilon$ along any direction.\n$$\n\\left( \\frac{\\partial \\rho}{\\partial x} \\right) < \\frac{\\rho}{l_{macro}} =  \\epsilon \\frac{\\rho^2 n_a}{m_{molecule}}\\hspace{10mm} \\text{where} \\hspace{10mm} l_{macro} = \\epsilon^{-1} l_{micro}\n$$\n  \nif the above is fulfilled, the change in density can be assumed to vary smooth, and the continuum approximation holds. however, the thickness of interfaces between macroscopic bodies are typically on the order of $l_{molecule}$ and not $l_{macro}$, we instead represent these as *surface discontinuities*.\n\n\n## velocity fluctuations\nfor gases (and in general fluids), we may devide movement into two categories, *bulk motion* of a volume like the winds or *molecular motion* like thermal energy. in continuum mechanics we are often interested in the bulk motion of the continuum and in order to assume the gas as a continuum, we require that the molecular speeds do not dominate the fluctuations.\nthe average root-mean-square speed of particles in a gas will be\n$$\nv_{mol}=\\sqrt{\\frac{3 r_{mol}t}{m_{mol}}}\n$$\nwhere $r_{mol}=8.31447 jk^{-1}mol^{-1}$ is the universal molar gas constant and t the absolute temperature. for air at room temperature, this is $\\approx 500ms^{-1}$\n\nin order to guarantee a relative precision of $\\epsilon$ is the velocity fluctuations, we require $\\delta v/v \\lessapprox \\epsilon$, implying that the length of the gas volume must be larger than\n$$\nl_{micro}^*=\\left( \\frac{v_{mol}}{v} \\right)^{2/3}l_{micro}\n$$\nso if we require $\\epsilon=10^{-3}$ precision in velocity, the minimum sidelength of the volume becomes $l_{micro}^*=100l_{micro}$ for air at room temperature.\n## mean-free-path\nto be written."
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "coursequote",
      "lessonTitle": "Course Overview",
      "x": 0.920463502407074,
      "y": 0.4340980052947998,
      "searchText": "course overview\n# course overview\n\n\n\n#course quotes\nthe following are quotes from the coursed deemed worthy to save.\n\n*if the berg is full of water or if its full of iceberg, it doesnt matter! \njust imagine an iceberg made of water, a so called waterberg.*\n\n*for a concept, the stress deviator doesn't exactly live up to its name*\n\n*with that in mind, consider a one cubic meter of gouda cheese*"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "dynamics",
      "lessonTitle": "Dynamics",
      "x": 0.9180103540420532,
      "y": 0.5998820066452026,
      "searchText": "dynamics\n# dynamics\n\n\n\n## introduction\n\nsample text\n\n\n## definitions\nmass definition\n$$\nm = \\int_v \\rho dv\n$$\n\nmomentum definition\n$$\np = \\int_v \\rho \\vec{v} dv\n$$\nwhere v is the specific momentum density, and combined with $\\rho$ gives the momentum density\n\n\nangular momentum definition\n$$\nl = \\int_v \\vec{x} \\times \\rho \\vec{v} dv\n$$\n\nkinetic energy\n$$\nk = \\int_v = \\frac{1}{2}  \\rho v^2 dv\n$$\n\nconservation of mass\n$$\n\\frac{d}{dt} \\int_v \\rho dv = - \\int_s \\rho v \\cdot n da \n$$\n\nusing gauss divergence theorem gives:\n\n$$\n\\frac{\\partial \\rho}{\\partial t} + \\nabla \\cdot (\\rho \\vec{v}) dv = 0\n$$\n$$\n= \\frac{\\partial \\rho}{\\partial t} + \\nabla \\cdot (\\rho \\vec{v})\n$$\n\n\n\nbig d means derivative while travelling along some speed (with respect to a new reference). named material derivative, comoving derivative. (not yet defined)\n$$\n\\frac{dm}{dt} = 0\n$$\n\n$$\n\\frac{dp}{dt} = - \\vec{f}\n$$\n\nq is some macroscopic quantity (fx. temperature)\n$$\nq = \\int_v \\rho q dv\n$$\nwhere q is the microscopic quantity\n\n$$\n\\frac{dq}{dt}= int_v \\rho \\frac{dq}{dt}dv\n$$\n\n$$\n= \\frac{\\partial q}{\\partial t} + \\dot{q}_{boundary}\n$$\n\nimagine a box, with various q's. imagine the box moving, how much q is lost and how much is gained is given by the boundary.\n\n$$\n\\frac{\\partial}{\\partial t} \\int_v \\rho q dv + \\int_s \\rho q(v\\cdot n)da\n$$\n$$\n=\\frac{\\partial}{\\partial t} \\int_v \\rho q dv+ \\int_v \\nabla \\cdot (\\rho q \\vec{v}) dv\n$$\n$$\n\\frac{\\partial (\\rho q)}{\\partial t} + \\nabla \\cdot (\\rho q \\vec{v})\n$$\n\n$$\n= q (\\frac{\\partial \\rho}{\\partial t} + \\nabla (\\rho \\vec{v})) + \\rho (\\frac{\\partial q}{\\partial t}+ (\\vec{v}\\cdot \\nabla)q)\n$$\nthe first term becomes zero, because of mass conservation leaving\n\n$$\n\\frac{dq}{dt}=\\rho (\\frac{\\partial q}{\\partial t}+ (\\vec{v}\\cdot \\nabla)q)\n$$\nthe first term defines the local derivative and the second describes the change as the \"box\" is moving.\nif we imagine flowspeed, the second describes the acceleration\n\nthe lagrangian perspective is the moving perspective, the eularian perspective is the static one.\n\n$$\n\\frac{dp}{dt}=\\vec{f}\n$$\n\n$$\n\\int_v \\rho \\frac{d\\vec{v}}{dt} dv\n$$\n\n$$\n\\frac{d\\rho}{dt}= \\frac{\\partial \\rho}{\\partial t} + (\\vec{v}\\cdot \\vec{nabla})\\rho\n$$\n$$\n\\frac{\\partial \\rho}{\\partial t} +  \\nabla \\cdot (\\rho v)- \\rho(\\nabla \\cdot v)\n$$\n\nthe first and second term becomes zero because of mass conservation\ngiving\n\n$$\n\\frac{d\\rho}{dt}= - \\rho (\\nabla \\cdot \\vec{v})\n$$\n\n$$\n\\frac{dx}{dt}= (v \\cdot \\nabla) \\vec{x}= v\n$$\n\n$$\n\\vec{v}=\\frac{d\\vec{u}}{dt}=\\frac{\\partial \\vec{u}}{\\partial} + (\\vec{v}\\cdot \\nabla)\\vec{u}\n$$\n\n## __cauchy equation\n$$\n\\rho \\frac{d\\vec{v}}{dt}=f*\n$$\nwhere f* is the body forces plus the divergence of the stress tensor\nwriting out the gives\n\n$$\n\\rho \\frac{\\partial}\n$$\n"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "elasticity",
      "lessonTitle": "Elasticity",
      "x": 0.9334139227867126,
      "y": 0.5286781787872314,
      "searchText": "elasticity\n# elasticity\n\n\n\n## introduction\nfrom mechanics, we are familiar with *hooke's law*. describing the relationship between force and extention for an object attached to a spring as\n$$\nf = -kx\n$$\nwhere k is the spring constant. this is all well and dandy, but only describes elasticity in one dimension. \nin this topic we expand the law to 3 dimensions.\n\n## young's modulus, poisson's ratio and lame coefficients\nyoung's modulus $e$ is a measure of the instretchability of a continuum. its definition and its relation to the spring constant is\n$$\ne=\\frac{\\sigma_{xx}}{u_{xx}}=\\frac{f/a}{x/l}=k\\frac{l}{a}\n$$\nwhere a is the cross-section, l is the total length, f is the force and x is the absolute deformation which mean $x/l$ is the *relative* deformation.\n\n\nsuppose a block of cheese is deformed by placing a weight on top of it. by intuition, we would assume that when we squeeze, \npoisson's ratio is a measure of the relative *shrinking* in the perpendicular direction to the \n## generalized hooke's law\nthe general case, hookes law can be expressed as\n$$\n\\sigma = e u\n$$\nwhere e is a rank 4 tensor, relating all the components of the cauchy strain tensor and the cauchy stress tensor. \n\nthe problem then becomes given in terms of the force density $f^*$.\n$$\nf^* = f + \\nabla \\cdot \\sigma\n$$\nwhere $f$ is the body forces like gravity. this is analytically unsolvable for most systems, we can however use finite difference approximations to solve it numerically.\n\n## work and energy\nwork can be defined for deformations in a continuum. \nits defined by the \":\" operator.\n$$\nw=\\sigma:u\n$$\nwhere $\\sigma$ is the cauchy stress tensor and $u$ is the cauchy strain tensor.\nthe \":\" operator takes sum of the elementvise product, i.e.\n$$\nw=\\sum_{ij} \\sigma_{ij} u_{ij}\n$$\nthe units will be in pascal, which essentially is the same as joules.\n\n## linear elastostatics\n-\\nabla \\cdot \\sigma = f\n\\sigma = 2 \\mu \\epsilon. blah\n\n\n\n## beam profile\n\n## slender rods\n\n## vibrations and sound\nsound, wirte eq 24.5\n\nexamples of vibration; platetectonics and earthquakes.\nbruel and kj\u00e6r uses microphones on objects and when vibrated using inverse problems can tell alot of the object.\n\ntwo types of waves, l-ongditudinal or p. divergence and curl free, producing pressure and shear waves.\n\nalso known as primary and secondary waves\npressure faster than shear.\n\nfor poisson coefficients of $1/3$, $c_l=2c_p$\n\ninsert picture of plane wave propagation for comparision.\nfor pressure waves, the polarization vector is aligned with the wavevector $\\vec{k}$.\n\nfor shear waves, there exists two polarization vectors perpendicular to the wavevector $\\vec{k}$.\n\n\n"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "examdisp",
      "lessonTitle": "Exam Dispensation",
      "x": 0.8853614330291748,
      "y": 0.537834882736206,
      "searchText": "exam dispensation\n# exam dispensation\n\n\nvan de waals forces and lennard jones potential.\n\n## 1. hydrostatics, buoyancy\nto do:\nvan de waals forces and lennard jones potential. cont approx and field description should be optional.\n__continuum approximation__\n\nmolecular separation length\n$$\nl_{mol}=\\left( \\frac{v}{n} \\right)^{1/3} = \\left( \\frac{m_{mol}}{\\rho n_a} \\right)^{1/3}\n$$\ndensity fluctuations\n$$\nl_{micro}=\\epsilon^{-2/3}l_{mol}\n$$\nmacroscopic smoothness\n$$\nl_{macro}=\\epsilon^{-1} l_{micro} \n$$\nvelocity fluctuations\n$$\nl\u00b4_{micro}= \\left( \\frac{v_{mol}}{v} \\right)^{2/3} l_{micro}\n$$\n\n__field description of continuum physics__\n$$\nd\\mathbf{m} = \\rho(\\vec{x},t)dv, \\hspace{3mm} d\\mathbf{p}=\\vec{v}(\\vec{x},t)d\\mathbf{m}, \\hspace{3mm} d\\mathbf{f}=\\vec{g}(\\vec{x},t)d\\mathbf{m}\n$$\nnoting that g could be any force field permeating the body. other note worthy fields used in the course are temperature, velocity, gravity, pressure, stress and strain.\n\n__pressure__\n$$\nd\\mathbf{f}=-p(\\vec{x})d\\mathbf{s}, \\hspace{3mm} \\mathbf{f}=-\\int_s p \\hspace{1mm} d\\mathbf{s}\n$$\n\nvan de waals forces and lennard jones potential and its relation to the bulk modulus.\n\n\n\nbulk modulus, how pressure acts on a body\n\n__buoyancy and achimedes principle__\n$$\n\\mathbf{f}=\\mathbf{f_g}+\\mathbf{f_b}=\\int_v \\rho \\vec{g}\\hspace{1mm} dv - \\oint_s p \\hspace{1mm}d\\vec{s}\n$$\nfixed gravity field implies deplacement equal to the weight\n\nfor hydrostatics we find the _local equation of hydrostatic equilibrium_\n$$\n\\mathbf{f_g}=\\mathbf{f_b},\\hspace{3mm}\\nabla p = \\rho \\vec{g}\n$$\n\n__examples__\nships, icebergs, how to calculate if cont approx is valid.\n\n## 2. stress & strain\n__tensor fundamentals__\n\n__stress tensor__\n\n__strain tensor__\n\n__relating to fluids and solids__\n\n__examples__\nfem modelling, glacier valley + crevasses\n\n## 3. elasticity & vibrations\n__stretching regime__\nwhere is linear elasticity valid?\n\n__poissons ratio, youngs modolus, lam\u00e9 coefficients__\n\n__generalized hookes law__\n\n__slender rods__\n\n__energy and work__\n\n__vibrations__\np and s waves, roughly derived from navier-stokes.\n\n__examples__\nelastic shelf assignment, cheese\n\n## 4. continuum mechanics\n__cauchy equation__\n\n\n## 5. (nearly) ideal flows and the sverdrup balance\nwhat is an ideal flow?\n\n__gravity waves__\n\n__vorticity vs. circulation__\n\n__sverdrup balance__\n\n## 6. viscous flows\n__newtonian vs non-newtonian__\n\n__stress and strain relation__\n\n__examples__\ncustard, quicksand, potatostarch\n\n## 7. stokes flows and channels & pipes\n__strong form vs weak form__\n\n__boundary conditions__\n\n__examples__\nglacier assignment\n"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "fem",
      "lessonTitle": "Finite Element Method",
      "x": 0.7650846838951111,
      "y": 0.44175776839256287,
      "searchText": "finite element method\n# finite element method\n\n\n\n## introduction\nmissing: weakform description, strongform description, \n\nthe finite element modelling is a way to solve partial differential equations by approximating the *solution* to the differential equation rather than approximating the differential equation as done in the usual finite difference methods.\nits a method that is utilized in many engineering fields, such as structural analysis, heat transfer and fluid flow.\n\nit works by discretizing the spatial dimensions into smaller subspaces called *finite elements*.\nit is great for solving boundary value problems and it is easy to mesh complicated domains.\n\nthe *finite* part come from the basisfunctions usual finite structure (i.e. its 0 in all places but around a node).\n\n## weighted residuals\nconsider a 1d differential equation written as\n$$\na(u)=f\n$$\nwe then choose an approximate solution of the form\n$$\nu^n = \\sum_{i=1}^n a_i \\phi_i(x)\n$$\nwhere $\\phi_i$ are approximation functions that we may choose and $a_i$ are unknown constants to be determined. \n\nputting them together defines the *residual* $r$ of the approximation. the problem is then to choose $a_i$ such that the residual is minimized.\n$$\nr^n(x)=||a(u^n)-f||_{norm}\n$$\n\nthe choice of norm defines the *moment* of the solution and will impact the accuracy and spatial resolution of the solution.\n\n## least squares method\nif we choose the euclidian norm and define it as\n$$\n\\pi (r^n) := ||r^n||^2 := \\int_0^l (r^n(x))^2 dx\n$$\nthe solution becomes a least squares solution. if we differentiate and constrain it to zero, we obtain the elements of the n by n matrix as\n$$\n\\frac{\\partial \\pi}{\\partial a_i} = \\int_0^l 2r \\frac{\\partial r}{\\partial a_i} dx = 0\n$$\nwhich can be solved in the usual manner (see page on scientific computing or applied statistics).\n\nby increasing the norm, we *punish* larger residuals harder. \n\n## collocation method\nthe least squares method (and for other moments) punishes spatially equally everywhere. this is not the only way, and a whole range of methods exists, generally called *method of weighted residuals*.\nwe may not be interested in minimizing the *average* residual as done with the least squares method, but minimizing it around a general area. this can be done with the *collocation method*, where we force the residuals to be zero at a number of locations\n$$\nr^n(x_i)=0\n$$\nor equivalently\n$$\n\\int_0^l r^n(x) \\delta (x-x_i)dx=0\n$$\n\nimagine working at w\u00fcrth and recieving complaints from customer service, that the produced screws are constantly breaking around the screwhead.\nthe job is to determine the minimum amount of steel to be added to reinforce the screw, just below the screwhead. this addition information regarding space of interest, motivates us to choose the collocation method. \nso that we may precisely determine the minimum amount of steel necessary to strengthen the screw exactly below the screwhead.\n\n## galerkin's method\nthe most widely used method, is called *galerkin\\'s method*. to illustrate, consider the relation shown in the above.\n$$\nu-u^n=e^n \\rightarrow u=u^n + e^n\n$$\nminimizing the error is now a question of achieving orthogonality, as the error will then be smallest. unfortunately the error is unknown but we do know the residual. ofcourse the error and the residual is not identical, but they share enough properties (for example, if one is zero, the other is zero), that we may proceed anyway.\nthus our problem is forcing $r^n \\perp u^n$ by\n$$\n\\int_0^l r^n(x)u^n(x)dx = \\int_0^l r^n (x) \\sum_{i=1}^n a_i \\phi_i dx = 0\n$$\n\nthe basic \u201crecipe\u201d for the galerkin process is as follows:\n\nstep 1: compute the residual: $a(u^n)-f=r^n(x)$\n\nstep 2: force the residual to be orthogonal to each of the approximation functions: $ \\int_0^l r^n (x) \\sum_{i=1}^n a_i \\phi_i dx = 0$\n\nstep 3: solve the set of coupled equations. the equations will be linear if the\ndifferential equation is linear, and nonlinear if the differential equation is nonlinear.\n\nthe primary problem with such a general framework is that it provides no systematic\nway of choosing the approximation functions, which is strongly dependent on issues\nof possible nonsmoothness of the true solution. the basic finite element method\nhas been designed to embellish and extend the fundamental galerkin method by\nconstructing $\\phi_i$ in order to deal with such issues. in particular:\n\nit is based upon galerkin\u2019s method, it is computationally systematic and efficient and \nit is based on reformulations of the differential equation that remove the problems\nof restrictive differentiability requirements.\n\n## minimum potential energy principle\nthe weak problem is known as a variational problem, which is related to that of determning u such that the potential energy function w(u) is minimized\n\n$$\nw(u)=1/2 \\int \\epsilon (u) : \\sigma(\\epsilon(u))dv - \\int f \\cdot u dv\n$$\n\nif u mnimizes w(u) then any variation of u should lead to larger w(u)\n\ninstead of varying a scalar, we vary a functino to minize a scalar.\n\nbecause of linearity, the change in some parameter of the function, will cause a linear change in the function w, ie. the original term plus additional terms. \n\nby doing the math, we see that the variation look like a derivative, but for a functional.\nthat means that we can employ similar methods as when minimizing ordinary function. ie. setting the functional derivative to zero and solve. that found function is the true minimizer of the energy.\n\n\n\n## interactive fem 1d bar demo\n\n[[simulation fem-1d-bar-sim]]\n\n**for the practical implementation of the finite element modelling, including choice of basisfunction $\\phi_i$ and determining $a_i$ using the fenics python package, see the finite element modelling illustrator and useful python packages topics.**"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "fluids",
      "lessonTitle": "Fluids",
      "x": 0.8677557706832886,
      "y": 0.6143492460250854,
      "searchText": "fluids\n# fluids\n\n\n\n## introduction\nin physics, a fluid is a liquid, gas, or other material\nthat continuously deforms (flows) under an applied shear\nstress, or external force. they have zero shear modulus,\nor, in simpler terms, are substances which cannot resist\nany shear force applied to them.\nfluids display properties such as:\n1. lack of resistance to permanent deformation\n2. resisting only relative rates of deformation in a dissipative, frictional manner\n3. the ability to flow (also described as the ability to\ntake on the shape of the container).\n\nthese properties are typically a function of their inability to support a shear stress in static equilibrium. in\ncontrast, solids respond to shear either with a spring-\nlike restoring force, which means that deformations are\nreversible, or they require a certain initial stress before\nthey deform (known as plasticity).\nsolids respond with restoring forces to both shear\nstresses and to normal stresses both compressive and\ntensile. in contrast, ideal fluids only respond with restoring forces to normal stresses, called pressure: fluids can\nbe subjected to both compressive stress, corresponding\nto positive pressure, and to tensile stress, corresponding\nto negative pressure. both solids and liquids also have\ntensile strengths, which when exceeded in solids makes irreversible deformation and fracture, and in liquids causes\nthe onset of cavitation.\nboth solids and liquids have free surfaces, which cost\nsome amount of free energy to form. in the case of solids,\nthe amount of free energy to form a given unit of surface\narea is called surface energy, whereas for liquids the same\nquantity is called surface tension. the ability of liquids\nto flow results in different behaviour in response to surface tension than in solids, although in equilibrium both\nwill try to minimise their surface energy: liquids tend\nto form rounded droplets, whereas pure solids tend to\nform crystals. gases do not have free surfaces, and freely\ndiffuse.\n\nfrom wikipedia.\n\n## pressure\npressure\n\n## equation of state\nvan de waals\n\n## buoyancy and stability\na body will exhibit the phenomena of weight, if placed in a gravitational field. this force is given as\n$$\n\\mathbf{f}_g = \\int_v \\rho_{body} \\mathbf{g}\\hspace{0.2cm}dv\n$$\nwhen a body is submerged into a fluid such as water or air, the pressure from that fluid will act on the surface of the body causing a buoyancy effect. the force is given as\n$$\n\\mathbf{f}_b = - \\oint_s p\\hspace{0.2cm} d\\mathbf{s}\n$$\nputting them together reproduces archimedes principle:\n$$\n\\mathbf{f}=\\mathbf{f}_g + \\mathbf{f}_b =\\int_v (\\rho_{body}-\\rho_{fluid})\\mathbf{g}\\hspace{0.2cm}dv\n$$\n\\emph{the force of buoyancy is equal and opposite to the weight of the displaced fluid}\\\\\nif the gravitational field can be assumed constant in the body, the equation simplifies to\n$$\n\\mathbf{f}=\\mathbf{f}_g + \\mathbf{f}_b =(m_{body}-m_{fluid})\\mathbf{g}_0\n$$\n\nbeyond the buoyant equilibrium, for a floating body to be in total equilibrium, there must also be a balance of moments acting on the body. similar to above, the contribution of buoyancy and gravity can be expressed as\n$$\n\\mathbf{m}_g = \\int_v \\mathbf{x}\\times \\rho_{body} \\mathbf{g}\\hspace{2mm}dv,\\hspace{1cm}\\mathbf{m}_b = \\oint_s  \\mathbf{x}\\times (-p) \\hspace{2mm}dv\n$$\nsince these must be equal to be in total equilibrium we have\n$$\n\\mathbf{m}_b=-\\mathbf{m}_g\n$$\nreproducing the moment equivalent to archimedes principle\\\\\n\\emph{the moment of buoyancy is equal and opposite to the moment of weight of the displaced fluid}\\\\\n\nin a constant gravitational field the equations simplifies by introducing the center of gravity $\\mathbf{x}_g$ and the center of buoyancy $\\mathbf{x}_b$ as\n\n$$\n\\mathbf{m}_g=\\mathbf{x}_g\\times m \\mathbf{g}_0,\\hspace{0.5cm}\\mathbf{x}_g=\\frac{1}{m}\\int_v \\mathbf{x}\\rho_{body}\\hspace{2mm}dv\n$$\n$$\n\\mathbf{m}_b=-\\mathbf{x}_b\\times m \\mathbf{g}_0,\\hspace{0.5cm}\\mathbf{x}_b=\\frac{1}{m}\\int_v \\mathbf{x}\\rho_{fluid}\\hspace{2mm}dv\n$$\n$$\n\\mathbf{m}_{total}=(\\mathbf{x}_g - \\mathbf{x}_b)\\times m\\mathbf{g}_0\n$$\n\n\n## sample headline\nsample text"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "fluidsinmotion",
      "lessonTitle": "Fluids in Motion",
      "x": 0.890491247177124,
      "y": 0.5808220505714417,
      "searchText": "fluids in motion\n# fluids in motion\n\n\n\n## introduction\n\nnewtonian and non-newtoniandilatant and pseudo-plastics (power law coefficient, flow coefficient)\ndeivatoric stress and strain rate plot. (n\\<1, n=1 n\\>1)\n\n## ideal flows\nideal flows are incompressible, has no viscocity (internal friction, ie. no resistance to shear stresses).\n\n[[simulation elastic-wave]]\n\n$$\n\\sigma = -p i\n$$\n$$\n\\nabla \\cdot \\sigma = - \\nabla p\n$$\nwhere p is pressure.\n\ninputting into cauchy equation we get a simple description of flow.\n$$\n\\nabla \\cdot \\vec{v}=0, \\hspace{3mm} \\frac{d\\vec{v}}{dt}=\\vec{g}-\\frac{\\nabla p}{\\rho}\n$$\nwhich gives 4 equations.\nfrom this a poisson equation can be made, which has non-local solutions, ie. if you change the pressure in one place, it must change in all places (consequence of incompressible).\n\nimagine a pipe that narrows down \n\nbernouilli's theorem.\n$$\nh= 1/2 * v^2 + \\phi p p/ \\rho\n$$\nwhere $\\phi$ is the gravitational field ($zg$)\nmust be constant \\emph{along a flowline}. it seems similar to a energy conservation. diviing by g gives a total head/energy head. ie,\n$$\n\\frac{dh}{dt}=0\n$$\n\n$$\n\\nabla_i h= 1/2  \\nabla_i v^2 + \\nabla_i \\phi + 1/\\rho \\nabla_i p\n$$\n\nvorticity $\\omega$.\n$$\n\\nabla h = \\vec{v} \\times (\\nabla \\times \\vec{v}) - \\frac{\\partial\\vec{v}}{\\partial t}= \\omega - \\frac{\\partial\\vec{v}}{\\partial t}\n$$\nhow much is it circulating in a particular point\n\ntaking the curl and rearranging gives\n\n$$\n\\nabla \\times \\frac{\\partial \\vec{v}}{\\partial t} = \\nabla \\times (\\nabla \\times \\omega)\n$$\nshowing that if i have something that is vorticity free, it will remain vorticity free. \n\nin summation, add the following topics.\nstreamfunctions, 2d flows, vorticity, circulation, stokes theorem. reduce to qualitative conclusions, short chapter on ocean stuff.\n\n## viscosity\nviscosity is a measure of a fluid's resistance to flow, or how easily it flows under stress. it is determined by the internal friction of a fluid and the cohesive forces between its molecules. high viscosity fluids are thick and resist deformation, while low viscosity fluids are thin and flow easily. \n\nwrite down all assumptions for the various descriptions.\n\n*newton's law of viscosity*, also known as shear or dynamics viscosity:\n$$\n\\sigma_{xy}(y) = \\eta \\frac{dv_x(y)}{dy}\n$$\ngives a linear relationship between the gradient and the stress. $\\mu$ has units of  in units of pa/s. is used to model \n\n*kinematic viscosity*\nfor example used in gases \n$$\nv = \\frac{\\eta}{\\rho}\n$$\n\n*velocity-driven planar flow*:\n$$\n\\frac{\\partial v_x}{\\partial t}= v\\frac{\\partial^2 v_x}{\\partial y^2}\n$$\nwhich is a typical diffusion equation, similar to a temperature diffusion equation.\n\n*isotrpoic viscous stress*\n$$\n\\sigma = - p i + 2\\eta \\dot{\\epsilon}\n$$\nwhere e is the strain rate tensor.\n$$\n\\sigma_{ij}= - p \\delta_{ij}+ \\eta (\\nabla_i v_j + \\nabla_j v_i)\n$$\n\n*incompressible, isotrpoic, homogenous fluids - navier stokes description*.\n$$\n\\frac{\\partial \\vec{v}}{\\partial t} + (\\vec{v}\\cdot\\nabla)\\vec{v}= \\vec{g}- \\frac{1}{\\rho_0}\\nabla p + v\\nabla^2 \\vec{v}, \\hspace{5mm}\\nabla \\cdot \\vec{v}=0\n$$\nassumptions: divergence free $\\nabla \\cdot v = 0$, newtonian liquid $v$ is constant, isotropic ie. the same material properties everywhere.\n\npseudo plastics and dilatant materials. write description.\n\nreynolds number: the ratio of advective term and friction term in the navier stokes description.\n$$\nre\\approx-\\frac{|(\\vec{v}\\cdot\\nabla)\\vec{v}|}{\\vec{v}\\nabla^2\\vec{v}}\\approx\\frac{u^2/l}{vu/l^2}=\\frac{ul}{v}\n$$\nnon-dimensional navier stokes description with reynolds number.\n$$\n(\\vec{v}\\cdot \\nabla)\\vec{v}= -  \\nabla \\vec{p}\n$$\n\n## channels and pipes\nfor steady flows, the navier stokes equation becomes;\n$$\neq 16.1\n$$\nfrom this we can derive assuming steady flow and imcompressible liquid, we get __pressure driven channel flow__ between two plates, the velocity field is given as\n$$\nv_x=\\frac{g}{2 \\eta}(a^2-y^2)\n$$\nso the velocity profile at one point between the plates is a parabella. \nfor shear thickening material this shape will be more \"sharp\", for the opposite case it will be more square\n__include picture__\nalso works for other materials than water, ie. glaciers have $n>1$ and its profile is more square.\n\nreynolds number comment include.\n\n__gravity-driven planar flow__\nimagine two incline planes where gravity acts on the body of the water (think cauchys eq.)\nthe solution then becomes\n$$\n0=g_y - \\frac{\\nabla_y p}{\\rho}\\hspace{4mm}0 = g_x + \\mu \\frac{\\partial^2v_x}{\\partial y^2}\n$$\nobserving the profile like above allows one to estimate the power flow law exponent $n$.\nfor $n=1$ the solution is a parabella \n$$\nv_x=\\frac{g_0 sin(\\theta)}{2\\mu}(a^2+y^2)\n$$\n\n__laminar pipe flow__\nfor laminar pipe flow we have the velocity profile\n$$\nv_z = \\frac{g}{4\\eta}(a^2-r^2) \\hspace{4mm} eq 16.29\n$$\n$$\nq=\\\n$$\n\n\n$$\neq 16.29 + 16.39 + 16.32 + \\text{see slides from absa}\n$$\n\n## gravity waves\na ton of assumptions in this one, remember to review the notes from absa.\n\ndispersion law:\n$$\n\\tau \\approx \\frac{\\lambda}{\\sqrt{g_0 d}}\n$$\n\nshallow-water equations are:\n$$\n\\frac{\\partial v_x}{\\partial t} + (v_x\\nabla_x+v_y\\nabla_y)v_x=-g_0 \\nabla_x \\eta + f v_y\n$$\n\n$$\n\\frac{\\partial v_y}{\\partial t} + (v_x\\nabla_x+v_y\\nabla_y)v_y=-g_0 \\nabla_y \\eta + f v_x\n$$\n\n$$\n\\frac{\\partial v_y}{\\partial t} + \\nabla_x(hv_x)+ \\nabla_y(hv_y)=0\n$$\nfrom this we can arrive at the 2d inhomogeneous wave equation in $\\eta$ (wave height).\n$$\n\\left(\\frac{\\partial^2}{\\partial t^2}+f^2\\right)\\eta - g d\\nabla_h^2 \\eta=0\n$$\n\n## creeping flow - newtonian fluids\nfor low reynolds numbers and $\\frac{dv}{dt}=0$. examples are heavy oils, honey and even tight crowds of people. inertia is insignificant and internal friction dominates.\n$$\nre = \\frac{|(v\\cdot\\nabla)v|}{|v\\cdot\\nabla^2 v|} = \\frac{ul}{v}\n$$\nfor low reynolds numbers and steady flows, navier stokes eq reduces \n$$\n\\nabla p = \\eta \\nabla^2 \\vec{v}\\hspace{1cm} \\nabla \\cdot v = 0\n$$\nan approximation usually called *stokes flow*\n\n*drag and lift on a moving body*\n\nima"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "frontpagetext",
      "lessonTitle": "Welcome",
      "x": 0.8535864353179932,
      "y": 0.4937838017940521,
      "searchText": "welcome\n# welcome\n\n\n\n## introduction\nin the macroscopic world, most materials that surround us e.g. solids and liquids \ncan safely be assumed to exist as continua, that is, the materials completely \nfill the space they occupy and the underlying atomic structures \ncan be neglected. this course offers a modern introduction to the physics of\ncontinuous matter with an emphasis on examples from natural occurring \nsystems (e.g. in the physics of complex systems and the earth sciences). \nfocus is equally on the underlying formalism of continuum mechanics and \nphenomenology. in the course you will become familiar with the mechanical \nbehavior of materials ranging from viscous fluids to elastic solids. \n\na description of the deformation of solids is given, including the concepts\nof mechanical equilibrium, the stress and strain tensors, linear elasticity.\na derivation is given of the navier-cauchy equation as well as examples \nfrom elastostatics and elastodynamics including elastic waves. a \ndescription of fluids in motion is given including the euler equations, \npotential flow, stokes' flow and the navier-stokes equation. examples of \nnumerical modeling of continous matter will be given. [from course description](https://kurser.ku.dk/course/nfyk10005u)\n"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "home",
      "lessonTitle": "Continuum Mechanics",
      "x": 0.8426942229270935,
      "y": 0.5216266512870789,
      "searchText": "continuum mechanics\n# continuum mechanics\n\n## course overview\n\ncontinuum mechanics describes the physics of **continuous matter**, both solids and fluids, from viscous liquids to elastic solids. the formalism connects microscopic forces to macroscopic observables through stress and strain tensors, conservation laws, and constitutive relations.\n\n- solids: deformation, elasticity, wave propagation.\n- fluids: viscous flow, potential flow, boundary layers.\n- numerics: finite-element and finite-difference methods for real-world problems.\n\n## why this topic matters\n\n- understanding stress and strain is essential for engineering design, geophysics, and biomechanics.\n- fluid dynamics governs weather, ocean currents, blood flow, and industrial processes.\n- the navier-stokes equations remain one of the most important unsolved problems in mathematics.\n- numerical simulation of continua underpins modern engineering and earth science.\n\n## key mathematical ideas\n\n- tensor algebra: stress tensor, strain tensor, and their invariants.\n- conservation laws: mass, momentum, and energy in continuous media.\n- constitutive relations: hooke's law for solids, newtonian viscosity for fluids.\n- the navier-cauchy equation for elastic solids and the navier-stokes equation for viscous fluids.\n- dimensionless analysis and the reynolds number.\n- finite-element methods for boundary value problems.\n\n## prerequisites\n\n- vector calculus: gradient, divergence, curl.\n- linear algebra: matrices, eigenvalues, tensor notation.\n- ordinary differential equations.\n- basic thermodynamics and classical mechanics.\n\n## recommended reading\n\n- spencer, *continuum mechanics*.\n- landau and lifshitz, *theory of elasticity* and *fluid mechanics*.\n- batchelor, *an introduction to fluid dynamics*.\n\n## learning trajectory\n\nthis module progresses from the continuum approximation to numerical modeling:\n\n- the continuum approximation and when it applies.\n- tensor fundamentals: index notation and transformation rules.\n- stress and strain: definitions, measurement, and physical meaning.\n- elasticity and hooke's law: linear elastic solids.\n- the navier-cauchy equation: elastostatics and elastodynamics.\n- fluids at rest: hydrostatics, buoyancy, and stability.\n- fluids in motion: euler equations, potential flow, and stokes flow.\n- the navier-stokes equation: viscous flow, reynolds number, poiseuille flow.\n- numerical modeling: finite elements for solids, finite differences for fluids.\n"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "notebook",
      "lessonTitle": "Course Notebook",
      "x": 0.9465789794921875,
      "y": 0.3911858797073364,
      "searchText": "course notebook\n# course notebook\n\n\n2 mandatory assignments, that doesnt count towards grade.\n"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "pythonpackages",
      "lessonTitle": "Python Packages",
      "x": 0.7958359122276306,
      "y": 0.4137711822986603,
      "searchText": "python packages\n# python packages\n\n\n\n## introduction\nbeyond the usual matplotlib, numpy and scipy packages, here are a few recommendations that may help in problem solving.\n\n## shapely\nshapely provides a way to conduct easy geometric calculations and representation.\n\n[shapely documentation](https://shapely.readthedocs.io/en/stable/manual.html)\n\n[github](https://github.com/shapely/shapely/tree/main/docs/)\n\nhighlighted functions: polygon, clip_by_rect,\n\n## sympy\nsympy allows maple/wolframalpha-like calculus analysis inside python, it is very convenient for automating tensor calculations. example functions for various tensors are given below.\n\n[sympy documentation](https://docs.sympy.org/latest/index.html)\n\nhighlighted functions: lambdify, symbols\n\n## plotly\ngreatly extends the functionality of interactive 3d graphics compared to matplotlib.\n\n[plotly documentation](https://plotly.com/graphing-libraries/)\n\nhighlighted functions: graph_objects\n\n## rasterio\n\ngeographic information systems use geotiff and other formats to organize and store gridded raster datasets such as satellite imagery and terrain models. rasterio reads and writes these formats and provides a python api based on numpy n-dimensional arrays and geojson.\n\n[rasterio documentation](https://rasterio.readthedocs.io/en/latest/)\n\nhighlighted functions: \n\n## fenics\nfor solving fem systems. brace yourself and memorize all the preculiarities of this package.\n\n1d:\nhighlighted functions:\nunitintervalmesh: defines the range and discretization used.\nintervalmesh: defines the range and discretization used.\nfunctionspace: defines the function space, *lagrange* means polynomial and deg is the order (1=linear).\nexpression: defines the basisfunction.\nproject: projects the polynomial onto the functionspace. \ntrialfunction: the unknown function we wish to approximate. $u_z(z)$\ntestfunction: the weight function space. $w_i$\nsolve: find the approximated constants.\n\n2d: \nrectanglemesh(point(,0,0), point(width,height), width resolution, height resolution): meshes a rectange, ideal for 2d modelling.\nvectorfunctionspace: 2d equivalent of the functionspace function.\ntrialfunction: the unknown function we wish to approximate. $u_z(z)$\ntestfunction: the weight function space. $w_i$\ninner(): the dobbelt dot product (:)\n\non_boundary and near(): on_boundary outputs 0 or 1 depending on whether the program iterates over all the points. near defines the tolerance, such that machine precision doesnt mess it up.\ndirechletbc(on space v, set value constant((0,0)), boundary): the actual boundary condition.\nplot: plotting function from the fenics package.\n\nextracting to matplotlib looping over usol.\n\nimplementing boundary conditions:\ndef bottom_boundary(x, on_boundary): return on_boundary and near(x\\[0\\], 0) \nbc1 = dirichletbc(v, constant(0), bottom_boundary) # u_z = 0 (no displacement) at z=0 (bottom boundary)\nbcs = \\[bc1\\]\n*from nicholas notebook*\n\n## gridap\nanother fem package for julia - for illustration it can be helpful to see, that the syntax and procedure is somewhat similar\n\ngripap.github.io\n\n## gmsh\nnot exactly a python package, but a tool to build custom meshes for fenics to solve.\nhttps://gmsh.info/"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "stressandstrain",
      "lessonTitle": "Stress and Strain",
      "x": 0.988547146320343,
      "y": 0.5194594860076904,
      "searchText": "stress and strain\n# stress and strain\n\n## the stress tensor\n\nthe **stress tensor** $\\sigma_{ij}$ describes the internal forces per unit area within a continuous material. for a surface element with outward normal $\\hat{n}$, the traction vector (force per unit area) is:\n\n$$\nt_i = \\sigma_{ij} n_j.\n$$\n\nthe stress tensor is symmetric ($\\sigma_{ij} = \\sigma_{ji}$) as a consequence of angular momentum conservation. this means it has six independent components in 3d.\n\n**principal stresses** are the eigenvalues of $\\sigma_{ij}$. in the principal coordinate system, the stress tensor is diagonal and the shear stresses vanish.\n\n[[simulation stress-strain-sim]]\n\n## the strain tensor\n\nthe **strain tensor** $\\varepsilon_{ij}$ quantifies deformation. for small displacements $u_i$:\n\n$$\n\\varepsilon_{ij} = \\frac{1}{2}\\left(\\frac{\\partial u_i}{\\partial x_j} + \\frac{\\partial u_j}{\\partial x_i}\\right).\n$$\n\n- **normal strain** ($\\varepsilon_{ii}$): fractional change in length along axis $i$.\n- **shear strain** ($\\varepsilon_{ij}$, $i \\neq j$): change in angle between originally perpendicular directions.\n\n## hooke's law\n\nfor a **linear elastic** isotropic material, stress and strain are linearly related:\n\n$$\n\\sigma_{ij} = \\lambda \\, \\varepsilon_{kk} \\, \\delta_{ij} + 2\\mu \\, \\varepsilon_{ij},\n$$\n\nwhere $\\lambda$ and $\\mu$ are the **lame parameters**. equivalently, using young's modulus $e$ and poisson's ratio $\\nu$:\n\n$$\n\\varepsilon_{ij} = \\frac{1+\\nu}{e}\\sigma_{ij} - \\frac{\\nu}{e}\\sigma_{kk}\\delta_{ij}.\n$$\n\n- **young's modulus** $e$: resistance to uniaxial stretching.\n- **poisson's ratio** $\\nu$: ratio of transverse contraction to longitudinal extension.\n\n[[simulation stress-strain-curve]]\n\n## mohr's circle\n\n**mohr's circle** provides a graphical method to determine the normal and shear stresses on any plane through a material point. given principal stresses $\\sigma_1 > \\sigma_2 > \\sigma_3$, the state of stress on a plane is represented by a point within three circles in the $(\\sigma_n, \\tau)$ plane.\n\nthe maximum shear stress is $\\tau_{\\max} = (\\sigma_1 - \\sigma_3)/2$.\n\n[[simulation mohr-circle]]\n"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "tensorfundamentals",
      "lessonTitle": "Tensor Fundamentals",
      "x": 1.0,
      "y": 0.5421115159988403,
      "searchText": "tensor fundamentals\n# tensor fundamentals\n\n\n\n## introduction\nthe cauchy stress tensor, cauchy strain tensor, the stress deviator, gradient tensor and spin tensor are essential concepts in the field of continuum mechanics. the cauchy stress tensor is a mathematical construct used to describe stress in a material. the cauchy strain tensor describes the deformation of the material due to stress. the cauchy strain tensor together with the spin tensor gives the combined gradient tensor. \nthe stress deviator characterizes the state of stress in a material with respect to a reference pressure. understanding these concepts is crucial for predicting the behavior of materials under different conditions. in this introduction, we will provide an overview of these concepts and their significance in the study of continuum mechnaics.\n\n## cauchy stress tensor\nthe cauchy stress tensor is an mathematical object used to describe how forces propagate through a continuum. for 3 dimensions it is a rank 2 tensor, for 2 dimensions a rank 1 tensor and for 1 dimension a rank 0 tensor, these are usually denoted as\n$$\n\\sigma_{3d} = \\begin{pmatrix}\n\\sigma_{11} & \\sigma_{12} & \\sigma_{13}\\\\\n\\sigma_{21} & \\sigma_{22} & \\sigma_{23}\\\\\n\\sigma_{31} & \\sigma_{32} & \\sigma_{33}\\\\\n\\end{pmatrix},\n\\sigma_{2d} = \\begin{pmatrix}\n\\sigma_{11} & \\sigma_{12}\\\\\n\\sigma_{21} & \\sigma_{22}\\\\\n\\end{pmatrix},\n\\sigma_{1d} = \\sigma_{11}\n$$\n\nthe diagonal elements represent *normal stresses* along the corresponding basis vectors. the off-diagonal elements represent the *shear stresses* that propagate through the continuum. \nthe columns of $\\sigma$ are the *traction vectors* of the cauchy stress tensor. \neach element of $\\sigma$ has units of pascal $nm^{-2}$ and in order for it to be physical, symmetry is enforced as $\\sigma=\\sigma^t$.\n\nfor any solids that have forces propagation through them, there exist a basis for the cauchy stress tensor such that only the diagonal element remain and no shear stresses are experienced. \nnormal and shear stresses are therefore a matter of perspective since they depend on the choosen basis, which is arbitrary. \nthis \"normal\" basis is the eigenbasis of the cauchy stress tensor.\n\n## stress deviator and invariants\nit is convenient to introduce the *stress deviator* which is defined as the cauchy stress tensor but removing the normal stresses or equivalently the pressure\n$$\ns=\\sigma-p\\mathbf{i}\\hspace{0.3cm} \\text{where}\\hspace{0.3cm} p=\\frac{1}{3}tr(\\sigma)\n$$\n$$\n\\begin{pmatrix}\ns_{11} & s_{12} & s_{13}\\\\\ns_{21} & s_{22} & s_{23}\\\\\ns_{31} & s_{32} & s_{33}\\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\sigma_{11} - p & \\sigma_{12} & \\sigma_{13}\\\\\n\\sigma_{21} & \\sigma_{22}- p & \\sigma_{23}\\\\\n\\sigma_{31} & \\sigma_{32} & \\sigma_{33}- p\\\\\n\\end{pmatrix}\n$$\nby removing the pressure, the stress deviator allows us to define a new reference pressure. imagine building a house, modeling how the forces propagate through the building and now having to find suitable materials to carry those forces. those materials will come with a detailed stress test, but that test has most likely been performed in normal atmospheric conditions and the material was most likely forged in the same. it is also the information that is relevant for the building, as you are not interested in its structural strength in vacuum but at the pressure where it will be build.\n\nstresses relating to a similar system is therefore usually communicated in terms of the stress deviator with some reference pressure. \nthe cauchy stress tensor ($i$) and the stress deviator ($j$) have 3 invariants that are constant under rotation to any other basis.\n\n\n$i_1=\\sigma_1 +\\sigma_2+\\sigma_3$\n\n$i_2=\\sigma_1\\sigma_2+\\sigma_2\\sigma_3+\\sigma_3\\sigma_1$\n\n$i_3=\\sigma_1\\sigma_2\\sigma_3$\n\n$j_1=s_{kk}=0 $\n\n$j_2=\\frac{1}{2}tr(s^2)= \\frac{1}{2}\\left( tr(\\sigma^2)-\\frac{1}{3}tr(\\sigma)^2\\right)$\n\n$j_3=\\det(s_{ij}) = \\frac{1}{3}\\left( tr(\\sigma^3)-tr(\\sigma^2)tr(\\sigma)+\\frac{2}{9}tr(\\sigma)^3\\right)$\n\nespecially the $j_2$ invariant is relevant, as is it linked to the *von mises yield criterion*. for materials where the ratio of \n$$\n\\frac{\\sigma_{shear,yielding}}{\\sigma_{tensile,yielding}}=\\frac{1}{\\sqrt{3}}\\approx 0.577\n$$\nthe von mises yield criterion can be used to model the failure point of a material when permanent deformation occurs, independent of choice of basis. this is given as\n$$\np_{deformation}=\\sqrt{3j_2}\n$$\n\n## cauchy strain tensor\nsimilarily to the forces, displacement in position can also be modeled by a tensor, called the *cauchy strain tensor*. \nconsider a vector field describing motion in a continuum\n$$\n\\mathbf{v}(x,y,z)=\\begin{pmatrix} v_x(x,y,z)\\\\ v_y(x,y,z)\\\\ v_z(x,y,z) \\end{pmatrix}\n$$\nthe cauchy strain tensor is then given as\n$$\n\\epsilon_{3d}=\n\\begin{pmatrix}\n\\frac{\\partial v_x }{\\partial x} & \\frac{1}{2}\\left( \\frac{\\partial v_x }{\\partial y}+\\frac{\\partial v_y }{\\partial x} \\right) & \\frac{1}{2}\\left( \\frac{\\partial v_x }{\\partial z}+\\frac{\\partial v_z }{\\partial x} \\right)\\\\\n\\frac{1}{2}\\left( \\frac{\\partial v_x }{\\partial y}+\\frac{\\partial v_y }{\\partial x} \\right) & \\frac{\\partial v_y }{\\partial y} & \\frac{1}{2}\\left( \\frac{\\partial v_y }{\\partial z}+\\frac{\\partial v_z }{\\partial y} \\right)\\\\\n\\frac{1}{2}\\left( \\frac{\\partial v_x }{\\partial z}+\\frac{\\partial v_z }{\\partial x} \\right) & \\frac{1}{2}\\left( \\frac{\\partial v_y }{\\partial z}+\\frac{\\partial v_z }{\\partial y} \\right) & \\frac{\\partial v_z }{\\partial z}\\\\\n\\end{pmatrix}\n$$\nand for 2 and 1 dimensions\n$$\n\\epsilon_{2d}=\n\\begin{pmatrix}\n\\frac{\\partial v_x }{\\partial x} & \\frac{1}{2}\\left( \\frac{\\partial v_x }{\\partial y}+\\frac{\\partial v_y }{\\partial x} \\right)\\\\\n\\frac{1}{2}\\left( \\frac{\\partial v_x }{\\partial y}+\\frac{\\partial v_y }{\\partial x} \\right) & \\frac{\\partial v_y }{\\partial y}\\\\\n\\end{pmatrix},\\hspace{3mm}\n\\epsilon_{1d}=\n\\frac{\\partial v_x }{\\partial x}\n$$\nthe cauchy strain tensor describes deformation in a continua. the eigenbasis of the cauchy strain tensor has eigenvectors pointing in the direction of displ"
    },
    {
      "topicId": "continuum-mechanics",
      "topicTitle": "Continuum Mechanics",
      "routeSlug": "continuum-mechanics",
      "lessonSlug": "weakstokes",
      "lessonTitle": "Weak Stokes Formulation",
      "x": 0.9753677845001221,
      "y": 0.611626386642456,
      "searchText": "weak stokes formulation\n# weak stokes formulation\n\n\n\n## fem weak stokes\n\n\n## cauchy momentum balance\nfor \n\n"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models",
      "routeSlug": "dynamical-models",
      "lessonSlug": "bacterial-growth",
      "lessonTitle": "Bacterial Growth Physiology",
      "x": 0.4880288243293762,
      "y": 0.6924985647201538,
      "searchText": "bacterial growth physiology\n# bacterial growth physiology\n\n## phases of bacterial growth\n\n*e. coli* has been intensively used for research on bacterial growth. monod (1949) showed that there are several phases in bacterial growth, and we focus on the **exponential growth phase**. in the exponential phase, the bacteria reach a quasi-steady state of growth.\n\n## definition of steady-state growth\n\n1. intrinsic parameters of the cell remain constant.\n2. extrinsic parameters increase exponentially with precisely the same doubling time.\n3. growth conditions remain constant.\n\n## bacterial growth law by jacques monod (1949)\n\nhe found growth rate $\\lambda$ depends on concentration of limiting nutrient in a michaelis-menten manner:\n\n$$\n\\lambda = \\lambda_\\mathrm{max} \\frac{s}{k_s + s}\n$$\n\n[[simulation michaelis-menten]]\n\n## frederick c. neidhardt (1999)\n\n> for me, encountering the bacterial growth curve was a transforming experience.\n\n## bacterial biomass is mainly protein\n\nwe now know bacterial growth is governed by a complex metabolic network. however, 55% of the total dry weight of bacteria is protein. we can approximate bacterial growth as mass of protein. the differential equation for this is:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t} m = \\lambda \\cdot m\n$$\n\nhere, $m$ is total protein mass and $\\lambda$ is the growth rate. if protein synthesis is rate limiting for growth:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t} m = k \\cdot n_r^a\n$$\n\nhere $k$ is the translation rate per ribosome and $n_r^a$ is the total number of actively translating ribosomes. thus we approximate protein production as depending only on the number of ribosomes.\n\nwe can roughly divide protein into three fractions:\n- metabolism/transport: $\\phi_\\mathrm{p} = m_\\mathrm{p}/m$\n- \"extended\" ribosomes (ribosomal protein): $\\phi_\\mathrm{r} = m_\\mathrm{r}/m$\n- other tasks: $\\phi_\\mathrm{q} = m_\\mathrm{q}/m$\n\nhere $\\phi_\\mathrm{x} = m_\\mathrm{x}/m$ is the fraction of protein molecules dedicated to a specific task. we immediately know that $\\phi_\\mathrm{p} + \\phi_\\mathrm{r} + \\phi_\\mathrm{q} = 1$.\n\n## efficient resource allocation\n\nnutrient influx by $\\phi_\\mathrm{p}$ should match nutrient usage by $\\phi_\\mathrm{r}$. but how does the bacterium know when to adjust the balance?\n\nthe molecule called **ppgpp** (guanosine pentaphosphate) is the molecular signal to stop making ribosomes. in the default state, bacteria make a lot of ribosomes because synthesis of the \"extended ribosome\" is regulated mainly by the promoters for the ribosomal rna genes.\n\n## measuring numbers of growth\n\nas an equation describing bacterial growth, we have:\n\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t} m = k \\cdot n_r^a\n$$\n"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models",
      "routeSlug": "dynamical-models",
      "lessonSlug": "differential-equations",
      "lessonTitle": "Differential Equations in a Nutshell",
      "x": 0.39634716510772705,
      "y": 0.7348094582557678,
      "searchText": "differential equations in a nutshell\n# differential equations in a nutshell\n\n[[simulation hill-function]]\n\n# week 2 description\n- nov 28: intuitively understanding differential equation for gene regulation \n(no worries, we do not need to solve difficult differential equation!!).\n\n# differential equation for creation\nconsider the situation that molecules (such as mrna) are created with the rate $k$ \n(molecules/unit time).\nwhat is the number of molecules after short time $\\delta t$?\ndefining $n(t)$ is number of molecules at time $t$, we see the number of molecules\nafter short time $\\delta t$ become\n$$\n    n(t+\\delta t) = n(t) + k \\delta t.\n$$\nhere $k \\delta t$ is number of molecules created in time period $\\delta t$.\nthus we just get the number of molecules after time $\\delta t$ by just summing\nup the number of molecules at time $t$ and number of molecules created in time \nperiod $\\delta t$.\n\nthis equation can mathematically equivalent to \n$$\n    \\frac{n(t+\\delta t) - n(t)}{\\delta t}\n    = \n    k.\n$$\nin the limit of infinitely small time period $\\delta t \\rightarrow 0$, left hand \nside of this equation would be described by differentiation.\n$$\n    \\frac{\\mathrm{d} n(t)}{\\mathrm{d} t}\n    = \n    k.\n$$\nthus this simple molecules creation process can be discribed by differential \nequation.\n\n[[simulation steady-state-regulation]]\n\nsolution become\n$$\n    n(t)\n    =\n    n(0) + kt.\n$$\ntherefore $n(t)$ increases linearly with time.\n\n# differential equation for degradation\nnext consider the another situation that molecules are degraded with rate $\\gamma$\n(1/unit time).\nnotice the unit of degradation rate is frequency.\nthus number of molecules degraded in time duration $\\delta t$ would be \n$$\n\\gamma n(t) \\delta t\n$$\nusing same way of previous section, we get\n$$\n    n(t+\\delta t) = n(t) - \\gamma n(t) \\delta t.\n$$\n$$\n    \\frac{n(t+\\delta t) - n(t)}{\\delta t}\n    = \n    -\\gamma n(t).\n$$\n$$\n    \\frac{\\mathrm{d} n(t)}{\\mathrm{d} t}\n    = \n    -\\gamma n(t).\n$$\nsolution become\n$$\n    n(t)\n    =\n    n(0) \\exp \\left(-\\gamma t\\right).\n$$\ntherefore $n(t)$ decays exponentially with time.\n\n# differential equation for creation and degradation\nfinally we can make differential equation for system with both creation and \ndegradation.\nby combining previous two section we have a equation for how number of molecules \nevolve with time.\n$$\n    \\frac{\\mathrm{d} n(t)}{\\mathrm{d} t}\n    = \n    k -\\gamma n(t).\n$$\nhere, as same in the previous two sections, $k$ (molecules/unit time) is \ncreation rate and $\\gamma$ (1/unit time) is degradation rate.\n\nif we let the system go for sufficiently long time, the system reach steady state\ni.e. number of molecules does not depend on time.\nwe can get number of molecules in the steady state by setting \n$\\frac{\\mathrm{d} n(t)}{\\mathrm{d} t} = 0$.\n$$\n    0\n    = \n    k -\\gamma n_\\mathrm{ss}.\n$$\nthus, \n$$\n    n_\\mathrm{ss}\n    = \n    \\frac{k}{\\gamma}.\n$$\n\n# differential equation for transcription and translation\nlet's consider more biological process which includes both transcription and \ntranslation.\nfor transcription, the differential equation becomes\n$$\n    \\frac{\\mathrm{d} n_\\mathrm{m}(t)}{\\mathrm{d} t}\n    = \n    k_\\mathrm{m} - \\gamma_\\mathrm{m} n_\\mathrm{m}(t).\n$$\nthat of translation becomes\n$$\n    \\frac{\\mathrm{d} n_\\mathrm{p}(t)}{\\mathrm{d} t}\n    = \n    k_\\mathrm{p}n_\\mathrm{m}(t) - \\gamma_\\mathrm{p} n_\\mathrm{p}(t).\n$$\nthe parameters are listed below.\n- $n_\\mathrm{m}(t)$ is number of mrna molecules at time $t$\n- $n_\\mathrm{p}(t)$ is number of protein molecules at time $t$\n- $k_\\mathrm{m}$ is rate of creation of mrna \n- $k_\\mathrm{p}$ is rate of creation of protein\n- $\\gamma_\\mathrm{m}$ is rate of degradation of mrna\n- $\\gamma_\\mathrm{p}$ is rate of degradation of protein\nnotice that creation term of protein depends on also number of mrna molecules \n$n_\\mathrm{m}$.\n\n# number of molecules vs concentration of molecules\nso far we consider the number of molecules but concentration (=number/volume) is \nmore convinient to treat both theoretically and experimentally.\nthe unit of concentration would be $\\mathrm{m}$ (mole).\nby introducing volume of the system $v$, \nconcentration of mrna would be\n- $c_\\mathrm{m}(t) = n_\\mathrm{m}(t)/v$\nconcentration of protein would be\n- $c_\\mathrm{p}(t) = n_\\mathrm{p}(t)/v$\nby keeping the same notation for other rate parameters, the differential equations\nbecome\n$$\n    \\frac{\\mathrm{d} c_\\mathrm{m}(t)}{\\mathrm{d} t}\n    = \n    k_\\mathrm{m} - \\gamma_\\mathrm{m} c_\\mathrm{m}(t).\n$$\n$$\n    \\frac{\\mathrm{d} c_\\mathrm{p}(t)}{\\mathrm{d} t}\n    = \n    k_\\mathrm{p}c_\\mathrm{m}(t) - \\gamma_\\mathrm{p} c_\\mathrm{p}(t).\n$$\n\n# transcriptional regulation: repression\n#### self-repressing gene\nconsider self-repressing gene i.e. the number of protein control the rate of \ncreation of mrna. differential equation of such system become\n$$\n    \\frac{\\mathrm{d} c_\\mathrm{m}(t)}{\\mathrm{d} t}\n    = \n    \\alpha_\\mathrm{m}\\left(c_\\mathrm{p}(t)\\right) \n    - \n    \\gamma_\\mathrm{m} c_\\mathrm{m}(t).\n$$\n$$\n    \\frac{\\mathrm{d} c_\\mathrm{p}(t)}{\\mathrm{d} t}\n    = \n    k_\\mathrm{p}c_\\mathrm{m}(t) - \\gamma_\\mathrm{p} c_\\mathrm{p}(t).\n$$\nto show the dependence of creation rate of mrna $\\alpha$, \ni wrote it as a function of $c_\\mathrm{p}(t)$.\n$\\alpha$ should monotonically decreases as the number of protein increases.\n\nhow can we decide the form of $\\alpha$?\n\n#### hill function\nconsider the binding process of protein (transcription factor, tf) to promotor, \nthe binding process should depend on concentration of tf, but unbinding process\nis independent from concentration of tf.\nthus we can build equation for time evolution of probability.\n$$\n\\begin{aligned}\n    \\frac{\\mathrm{d} p_\\mathrm{free}}{\\mathrm{d} t}\n    =& \n    - v_\\mathrm{bind} c_\\mathrm{p}(t) p_\\mathrm{free}\n    + k_\\mathrm{unbind} p_\\mathrm{occupied}\n    \\\\=& \n    - v_\\mathrm{bind} c_\\mathrm{p}(t) p_\\mathrm{free}\n    + k_\\mathrm{unbind} (1-p_\\mathrm{free})\n\\end{aligned}\n$$\nthe parameters are listed below.\n- $p_\\mathrm{free}$ is the p"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models",
      "routeSlug": "dynamical-models",
      "lessonSlug": "feedback-loops",
      "lessonTitle": "Feedback Loops in Biological Systems",
      "x": 0.3984913229942322,
      "y": 0.6739663481712341,
      "searchText": "feedback loops in biological systems\n# feedback loops in biological systems\n\n## why feedback matters\n\nfeedback loops are the fundamental building blocks of regulatory circuits in biology. a gene product that influences its own production creates a **feedback loop**, and the sign of that influence, positive or negative, determines the qualitative behavior of the circuit.\n\n- **negative feedback**: the gene product represses its own transcription. this promotes homeostasis, speeds response, and reduces noise.\n- **positive feedback**: the gene product activates its own transcription. this generates bistability, memory, and irreversible switching.\n\n## negative autoregulation\n\nconsider a transcription factor $x$ that represses its own promoter. the ode model is:\n\n$$\n\\frac{dx}{dt} = \\frac{\\beta}{1 + (x/k)^n} - \\gamma x,\n$$\n\nwhere $\\beta$ is the maximal production rate, $k$ is the repression threshold, $n$ is the hill coefficient, and $\\gamma$ is the degradation rate.\n\nkey properties of negative autoregulation:\n\n- **faster response time**: the system reaches steady state more quickly than an unregulated gene because high initial production is followed by self-limiting repression.\n- **reduced noise**: fluctuations above the mean are suppressed by increased repression, and vice versa.\n- **robustness**: the steady-state level $x^*$ is less sensitive to parameter variations than for constitutive expression.\n\nthe steady state satisfies $\\beta / (1 + (x^*/k)^n) = \\gamma x^*$, which can be solved graphically as the intersection of the production and degradation curves.\n\n## positive feedback and bistability\n\nwhen a transcription factor activates its own production, the model becomes:\n\n$$\n\\frac{dx}{dt} = \\frac{\\beta (x/k)^n}{1 + (x/k)^n} + \\beta_0 - \\gamma x,\n$$\n\nwhere $\\beta_0$ is a basal (leak) production rate.\n\nfor sufficiently cooperative activation ($n \\geq 2$) and appropriate parameter values, the production curve intersects the degradation line at **three fixed points**: two stable (low and high expression) and one unstable. this is **bistability**.\n\n- the system can exist in either the low or high state.\n- transitions between states require a sufficiently large perturbation or a change in parameters.\n- bistability provides **cellular memory**: once a cell commits to a state, it remains there even after the inducing signal is removed.\n\n## the genetic toggle switch\n\ngardner, cantor, and collins (2000) constructed a synthetic bistable circuit from two mutually repressing genes:\n\n$$\n\\frac{du}{dt} = \\frac{\\alpha_1}{1 + v^n} - u, \\qquad \\frac{dv}{dt} = \\frac{\\alpha_2}{1 + u^n} - v.\n$$\n\nthis **toggle switch** has two stable steady states (high-$u$/low-$v$ and low-$u$/high-$v$) separated by an unstable saddle point. the system can be flipped between states by transient pulses of inducer.\n\n[[simulation steady-state-regulation]]\n\n## oscillations: the repressilator\n\nelowitz and leibler (2000) built a synthetic oscillator from three genes in a ring of repression: $a$ represses $b$, $b$ represses $c$, $c$ represses $a$.\n\n$$\n\\frac{dm_i}{dt} = \\frac{\\alpha}{1 + p_j^n} + \\alpha_0 - m_i, \\qquad \\frac{dp_i}{dt} = \\beta(m_i - p_i),\n$$\n\nwhere $j$ is the upstream repressor of gene $i$.\n\nsustained oscillations arise when:\n\n- the hill coefficient $n$ is large enough (strong cooperativity).\n- protein and mrna lifetimes are well matched.\n- the repression is strong ($\\alpha \\gg \\alpha_0$).\n\nthe repressilator demonstrates that negative feedback loops arranged in odd-numbered rings can generate oscillations, a principle that also explains circadian clocks and the cell cycle.\n\n[[simulation lotka-volterra]]\n\n## graphical fixed-point analysis\n\na powerful technique for analyzing one-dimensional feedback circuits:\n\n1. plot the **production rate** $f(x)$ as a function of $x$.\n2. plot the **degradation rate** $\\gamma x$ as a straight line.\n3. intersections are **fixed points**.\n4. stability is determined by the slopes: if $f'(x^*) < \\gamma$ the fixed point is stable; if $f'(x^*) > \\gamma$ it is unstable.\n\nfor multistable systems, this graphical method reveals the number and location of stable states, the thresholds for switching, and the sensitivity to parameter changes.\n\n## biological examples\n\n- **competence in *b. subtilis***: positive feedback on *comk* creates a bistable switch; a small fraction of cells stochastically enter the competent state.\n- **lambda phage lysis-lysogeny decision**: mutual repression between ci and cro creates a toggle switch determining the fate of the infected cell.\n- **p53-mdm2 oscillations**: negative feedback between the tumor suppressor p53 and its inhibitor mdm2 generates oscillatory pulses in response to dna damage.\n"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models",
      "routeSlug": "dynamical-models",
      "lessonSlug": "gene-expression-noise",
      "lessonTitle": "Quantifying Noise in Gene Expression",
      "x": 0.4422932267189026,
      "y": 0.72920823097229,
      "searchText": "quantifying noise in gene expression\n# quantifying noise in gene expression\n\n## cellular identity and the central dogma\n\nin multicellular organisms, all cells carry the same dna yet display enormous diversity. the answer lies in **gene expression**: depending on cell type, different genes are transcribed and translated into proteins.\n\nthe **central dogma** describes the flow of genetic information:\n\n$$\n\\text{dna} \\xrightarrow{\\text{transcription}} \\text{mrna} \\xrightarrow{\\text{translation}} \\text{protein}\n$$\n\ntwo key molecular machines drive this process:\n\n- **rna polymerase**: transcribes dna into mrna.\n- **ribosome**: translates mrna into protein.\n\n## transcriptional regulation\n\ngene expression is controlled at the promoter, a region of dna upstream of the gene:\n\n- **strong promoter**: attracts rna polymerase efficiently; the gene is on by default unless a repressor binds.\n- **weak promoter**: attracts rna polymerase poorly; the gene is off by default unless an activator recruits polymerase.\n- classic example: the *lac* promoter in *e. coli*, which is repressed by laci and activated by cap.\n\n## measuring gene expression\n\nto measure expression, a **reporter protein** such as gfp is fused to the target gene. fluorescence intensity then reports protein abundance.\n\n- **bulk measurement**: total fluorescence from billions of cells in a tube gives the population average.\n- **single-cell measurement**: flow cytometry or microscopy reveals the full distribution, showing that gene expression is inherently noisy.\n\n## why is gene expression noisy?\n\nlow copy numbers of key molecules, particularly transcription factors and gene copies, make reactions stochastic. chemical reactions inside the cell are driven by **diffusion** (confirmed by frap and single-molecule tracking), so each molecular encounter is a random event.\n\nnoise in gene expression has biological consequences:\n\n- **bistability** in *comk* expression drives competence in *b. subtilis*.\n- **persister cells** in bacterial populations survive antibiotic treatment through stochastic switching.\n\n## defining total noise\n\nthe **coefficient of variation** (cv) quantifies noise as the ratio of standard deviation to mean:\n\n$$\n\\eta(t) = \\frac{\\sqrt{\\langle (n(t) - \\langle n(t) \\rangle)^2 \\rangle}}{\\langle n(t) \\rangle}\n$$\n\nwhere $n_j(t)$ is the protein copy number in cell $j$, the population mean is\n\n$$\n\\langle n(t) \\rangle = \\frac{1}{n} \\sum_{j=1}^{n} n_j(t),\n$$\n\nand the variance is\n\n$$\n\\text{var}[n(t)] = \\frac{1}{n} \\sum_{j=1}^{n} \\bigl(n_j(t) - \\langle n(t) \\rangle\\bigr)^2.\n$$\n\n## decomposing noise: intrinsic and extrinsic\n\nfollowing the landmark experiment of elowitz et al. (2002), total noise can be decomposed by expressing two distinguishable reporters (e.g., cfp and yfp) from identical promoters in the same cell.\n\n**extrinsic noise** captures correlated fluctuations (shared upstream factors):\n\n$$\n\\eta_{\\mathrm{ext}}^2 = \\frac{\\langle n^{(1)} n^{(2)} \\rangle - \\langle n^{(1)} \\rangle \\langle n^{(2)} \\rangle}{\\langle n^{(1)} \\rangle \\langle n^{(2)} \\rangle}.\n$$\n\n**intrinsic noise** captures uncorrelated fluctuations (independent birth-death events):\n\n$$\n\\eta_{\\mathrm{int}}^2 = \\frac{\\langle (n^{(1)} - n^{(2)})^2 \\rangle}{2\\,\\langle n^{(1)} \\rangle \\langle n^{(2)} \\rangle}.\n$$\n\nthe total noise decomposes exactly:\n\n$$\n\\eta_{\\mathrm{total}}^2 = \\eta_{\\mathrm{int}}^2 + \\eta_{\\mathrm{ext}}^2.\n$$\n\nwhen both reporters are identically distributed ($n^{(1)} \\stackrel{d}{=} n^{(2)}$), this reduces to the standard cv squared.\n\n[[simulation gene-expression-noise]]\n\n## the fano factor\n\nan alternative noise measure is the **fano factor**:\n\n$$\nf = \\frac{\\text{var}[n]}{\\langle n \\rangle}.\n$$\n\n- for a poisson process, $f = 1$.\n- $f > 1$ indicates super-poissonian (bursty) noise, common in gene expression due to transcriptional bursting.\n- $f < 1$ indicates sub-poissonian noise, which can arise from negative autoregulation.\n\n## stochastic simulation\n\nthe **gillespie algorithm** (stochastic simulation algorithm) provides exact trajectories of the chemical master equation. at each step:\n\n1. compute all reaction propensities $a_i$.\n2. draw the time to next reaction from an exponential distribution with rate $a_0 = \\sum_i a_i$.\n3. choose which reaction fires with probability $a_i / a_0$.\n4. update molecule counts and repeat.\n\nthis algorithm is the computational workhorse for studying noise in gene expression at the single-cell level.\n"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models",
      "routeSlug": "dynamical-models",
      "lessonSlug": "gene-regulatory-networks",
      "lessonTitle": "Gene Regulatory Networks",
      "x": 0.40278133749961853,
      "y": 0.6962684392929077,
      "searchText": "gene regulatory networks\n# gene regulatory networks\n\n## types of regulation\n\nthere are two types of regulation:\n- **positive regulation**: gene a activates/increases gene b, symbolized by $a \\rightarrow b$\n- **negative regulation**: gene a represses/decreases gene b, symbolized by $a \\dashv b$\n\nby combining these simple types of regulation, genes are controlled. often, gene regulatory networks are more complicated than what appears to be necessary at first sight.\n\n## statistics of regulatory functions\n\nas the genome size increases, the percentage of gene regulatory motifs increases.\n\n## real networks and how we understand gene regulation\n\neven the fruit fly has an enormously complex network. what can we learn from these networks?\n\nwe focus on subparts, i.e., **motifs** of networks, and investigate how \"core\" key dynamics behave. this is a reductionist approach: we can say something about particular examples but cannot always make general statements.\n\n## types of network motifs\n\nseveral types of motifs have been identified:\n- **positive feedback**: $a \\leftrightarrow b$\n- **negative feedback**: $a \\rightarrow b \\dashv a$\n- **feed-forward loops**: $a \\rightarrow b \\rightarrow c$, $a \\rightarrow c$\n- **single input modules**: $a \\rightarrow b$, $a \\rightarrow c$, $a \\rightarrow d$\n\n## identifying positive and negative feedback\n\nfind a closed loop and multiply the interaction types as integers: positive regulation ($\\rightarrow$) as $+1$, and negative regulation ($\\dashv$) as $-1$. for example,\n\n$$\na \\rightarrow b \\rightarrow c \\dashv a\n$$\n\ngives $(+1)(+1)(-1) = -1$, so this is a **negative feedback loop**.\n\n## biological examples of positive/negative regulation\n\n- phage lambda repressor (ci)\n- bistability in *comk* expression\n- ppgpp signaling by the ribosome\n- cell-to-cell communication\n\n## biological examples of feed-forward loops\n\n- **and logic**: *ara genes* need two activators, crp and arac. the network is $\\mathrm{crp} \\rightarrow \\mathrm{arac} \\rightarrow ara$, $\\mathrm{crp} \\rightarrow ara$.\n- **or logic**: flagella of bacteria.\n\n## biological examples of single input modules\n\n- flagellar genes\n\n## simplification of dynamical equations\n\nbiologically, transcription and translation are two independent processes, so we need to build equations for each. however, from a mathematical viewpoint, it is convenient to approximate the transcription process as part of the translation process. we can write an equation for protein concentration time evolution:\n\n$$\n\\frac{\\mathrm{d}p}{\\mathrm{d}t} = \\frac{\\alpha_\\mathrm{p} \\alpha_\\mathrm{m} (p/k)^h}{\\gamma_\\mathrm{h} (1+(p/k)^h)} - \\gamma_\\mathrm{p} p\n$$\n\n## obtaining steady-state concentration from a graph\n\nto see the parameter-free typical behavior of this equation, we substitute $1$ for most parameters. the equation becomes:\n\n$$\n\\frac{\\mathrm{d}p}{\\mathrm{d}t} = \\frac{p^h}{1+p^h} - \\gamma_\\mathrm{p}p\n$$\n\nby plotting $y = p^h/(1+p^h)$ and $y = \\gamma_\\mathrm{p}p$ on the same plane, we can visually inspect the steady-state concentration of $p$.\n\n## negative regulation\n\nthe same analysis applies to negative regulation:\n\n$$\n\\frac{\\mathrm{d}p}{\\mathrm{d}t} = \\frac{1}{1+p^h} - \\gamma_\\mathrm{p}p\n$$\n\n[[simulation hill-function]]\n"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models",
      "routeSlug": "dynamical-models",
      "lessonSlug": "home",
      "lessonTitle": "Dynamical Models in Molecular Biology",
      "x": 0.5892553329467773,
      "y": 0.5680453181266785,
      "searchText": "dynamical models in molecular biology\n# dynamical models in molecular biology\n\n## course overview\n\nthis course applies the tools of **physics and mathematics** to understand how living systems regulate themselves at the molecular level.\nunlike classical biochemistry, which catalogs pathways and components, we build quantitative, predictive models of gene expression, regulation, and growth.\n\n- biology provides the systems: genes, proteins, regulatory circuits, and growing cells.\n- physics provides the framework: differential equations, stochastic processes, and steady-state analysis.\n- mathematics provides the rigor: exact solutions, stability analysis, and parameter estimation.\n\nwe focus on simple systems, often bacterial, but seek general rules that apply broadly across biology.\n\n## why this topic matters\n\n- gene expression is inherently **stochastic**, and noise shapes cell-fate decisions.\n- **feedback loops** in regulatory networks produce switches, oscillations, and memory.\n- **signal transduction** allows cells to sense and adapt to their environment with remarkable specificity and sensitivity.\n- quantitative **growth laws** connect molecular processes to whole-cell physiology.\n- **mutations** are both the raw material of evolution and a fundamental experimental tool.\n\n## key mathematical ideas\n\n- ordinary differential equations for production and degradation kinetics.\n- the hill function as a universal model for cooperative binding.\n- stochastic simulation (gillespie algorithm) for single-cell noise.\n- fixed-point analysis and bifurcation diagrams for feedback circuits.\n- resource allocation models for bacterial growth.\n\n## prerequisites\n\n- basic calculus (derivatives and integrals).\n- introductory probability and statistics.\n- familiarity with basic molecular biology (dna, rna, protein).\n- no advanced mathematics is required; differential equations are introduced from first principles.\n\n## recommended reading\n\n- phillips et al., *physical biology of the cell*.\n- alon, *an introduction to systems biology*.\n- weekly scientific articles from the quantitative biology literature.\n\n## learning trajectory\n\nthis module is organized from molecular-level processes to systems-level behavior:\n\n- gene expression noise: stochastic transcription and translation.\n- differential equations: modeling production, degradation, and regulation.\n- feedback loops: bistability, oscillations, and the repressilator.\n- gene regulatory networks: motifs, operons, and network architecture.\n- signal transduction: chemotaxis, adaptation, and mapk cascades.\n- mutational analysis: screens, selections, and experimental design.\n- bacterial growth: growth laws, proteome allocation, and resource trade-offs.\n"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models",
      "routeSlug": "dynamical-models",
      "lessonSlug": "mutational-analysis",
      "lessonTitle": "Probability for Mutational Analysis",
      "x": 0.4784526228904724,
      "y": 0.7679193019866943,
      "searchText": "probability for mutational analysis\n# probability for mutational analysis\n\n# week 3 description\n- dec 5: fundamentals of mutations and probability for mutational analysis\n\n# what causes mutations?\nthere are two type of mutations.\n- spontaneous (chemical mistakes in dna replication, $\\sim 5000$ times a day in a human cell)\n    - depurination (adenine or guanine base cleaving)\n    - deamination (cytosine become uracil)\n- induced (chemical change by uv light and radiation, $\\sim 100$ times a day in a human cell)\n\n# fidelity in dna replication and gene expression\naccuracy (mistake per bases) of each gene expression process:\ndna replication ($1/10^9$) > transcription ($1/10^6$) > translation ($1/10^4$)\n\n# proofreading in dna replication\nbase pairing is largely determined by hydrogene bond.\nhowever free energy difference of correct base pair and wrong one is only \n4-13 kj/mol which is not enough to observe error rate $10^{-9}$.\nwhat kind of additional process is necessary to achive this fidelity?\n## edting by dna polymerase\ndna polymerase can not only do polemerizing but also editing.\nif newly added base is wrong, they remove it.\n## cellular enzyme (strand-directed mismatch repair)\nmany cellular enzyme are dedicated to dna repair. \nsome enzyme removes errors by recruiting dna polymerase.\n\n# recombination\nduring meiosis crossing-over happens and it contribute genetic diversity.\n\n# mutants\ndue to their small size and fast growth rate, we can easily grow a billion bacteria\novernight in 1ml medium.\n## genetic selection\nwe can only grow mutants. \nfor example, we can only grow bacteria with t14 receptors.\n\n# distribution for mutation\nconsider the case we observe the cell division and count the number of mutated cell.\n\n# binomial distribution\n$$\n    p_n(k)\n    =\n    \\frac{n!}{(n-k)!k!} p^k (1-p)^{(n-k)}\n$$\n\n# poisson distribution\nwhen we take a limit of $n\\rightarrow\\infty$ with $m=np=\\mathrm{const.}$, we get \npoisson distribution.\n$$\n    p_m(k)\n    =\n    \\frac{m^k}{k!} \\exp(-m)\n$$\n\n# binomial vs poisson\nif we use large $n$ in binomial distribution, it approaches the poisson \ndistribution (with $np=m=\\mathrm{const.}$).\n"
    },
    {
      "topicId": "dynamical-models",
      "topicTitle": "Dynamical Models",
      "routeSlug": "dynamical-models",
      "lessonSlug": "signal-transduction",
      "lessonTitle": "Signal Transduction",
      "x": 0.4473150670528412,
      "y": 0.639265775680542,
      "searchText": "signal transduction\n# signal transduction\n\n## introduction\n\na signal is some sort of molecule (e.g. food, quorum-sensing molecules, hormones, ions, or gases) or physical stimulation (e.g. pressure, temperature, or light). the signal binds to a specific receptor, triggering a cascade of events inside the cell. this is the beginning of **signal transduction**.\n\n## signal transduction involves many steps\n\nthanks to intermediate steps, cells can perform:\n- signal amplification\n- signal spreading between cells\n- signal integration\n- noise filtering\n- signal memory\n- adaptation\n\nthese capabilities are enabled by protein-protein interactions. very often, the transduction steps are a series of **phosphorylation** events.\n\n## bacterial chemotaxis: a well-studied example\n\nbacterial chemotaxis is well studied. bacteria detect gradients of attractant (like food) and move in the desired direction.\n\nthey can detect the smallest change of gradients, such as one molecule per cell volume per micron. they can also detect gradients against a high concentration background spanning five orders of magnitude.\n\nbacteria perform this while undergoing brownian motion. they swim straight for about 1 second, then reorient randomly by about 90 degrees. how do they move towards food? they use a **biased random walk**.\n\nthey have flagella to move. the flagellar motor is a molecular motor, and depending on which way it rotates, bacteria can **run** (counterclockwise) or **tumble** (clockwise). when they run, flagella converge into a single bundle and bacteria move forward. when they tumble, the flagella do not converge.\n\nthis change of rotational direction is governed by **chey** and **chea**. when chey is phosphorylated, chey-p binds the motor and makes it turn clockwise. if a signal (attractant) binds to the receptor, it lowers the kinase activity of chea, which leads to less tumbling.\n\n## how tumbling frequency depends on ligand concentration\n\nif tumbling frequency depends on the absolute concentration of attractant, it will saturate quickly. if tumbling frequency does not depend on concentration at all, bacteria cannot detect the gradient. how do they detect the gradient?\n\n## chemotaxis requires adaptation\n\ntumbling frequency changes when a change is detected, but if there is no change for a while, it goes back to the default tumbling frequency. with this **adaptation**, cells can be sensitive to small changes in concentration as well as respond to a wide range of concentrations.\n\n## modeling chemotaxis\n\nassumptions:\n- ligand binding immediately changes the fraction of active methylated receptor\n- michaelis-menten kinetics\n\nequation for methylation/demethylation:\n\n$$\n\\frac{\\mathrm{d} [e_m]}{\\mathrm{d} t} = k^r [\\mathrm{cher}] - \\frac{k^b b^{*}(l) e_m}{k_m^b + e_m}\n$$\n\n## signal transduction in space\n\nthe fruit fly shows spatial patterning during its development. this is accomplished by signal transduction, where morphogen gradients establish positional information across the embryo.\n\n## cell-to-cell communication\n\n**lateral inhibition** is a process where a cell inhibits the gene expression of its nearest neighbors. this is described by the **notch-delta model**, where notch receptors on one cell are activated by delta ligands on neighboring cells, leading to differentiation patterns.\n"
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems",
      "routeSlug": "inverse-problems",
      "lessonSlug": "intro",
      "lessonTitle": "Introduction to Inverse Problems",
      "x": 0.5579352974891663,
      "y": 0.18748360872268677,
      "searchText": "introduction to inverse problems\n# introduction to inverse problems\n\nan **inverse problem** starts from measurements and asks for the hidden parameters that produced them.\n\n$$\n\\mathbf{d} = g(\\mathbf{m})\n$$\n\n- $\\mathbf{d}$: observed data\n- $\\mathbf{m}$: unknown model parameters\n- $g$: forward model (physics + measurement process)\n\nin practice, we know $\\mathbf{d}$ and we can evaluate $g$, but computing $g^{-1}$ is usually impossible or unstable.\n\n---\n\n## why inverse problems are hard\n\nfollowing hadamard, an inverse problem can fail to be well-posed in three ways:\n\n1. **no exact solution** exists\n2. **multiple solutions** fit the data\n3. **instability**: small data noise causes large model changes\n\nthat is why regularization, priors, and uncertainty quantification are central to this field.\n\n---\n\n## canonical examples\n\n### medical and geophysical imaging\n\nwe infer hidden structure from indirect signals:\n\n- mri and spect infer tissue properties from measured responses\n- seismic tomography infers subsurface velocity/slowness from travel times\n\n[[figure mri-scan]]\n\n[[figure spect-scan]]\n\n[[figure seismic-tomography]]\n\n### waveform inversion\n\na simplified acoustic model is:\n\n$$\n\\frac{1}{\\kappa(x)}\\frac{\\partial^2 p}{\\partial t^2}(x,t) - \\nabla\\cdot\\left(\\frac{1}{\\rho(x)}\\nabla p(x,t)\\right)=s(x,t)\n$$\n\ngiven source and boundary conditions, we measure $p(x_n,t)$ at sensors and infer acceptable $\\kappa(x)$ and $\\rho(x)$.\n\n---\n\n## a quick instability example (hadamard)\n\nfor a 2d heat-flow setup, one obtains\n\n$$\nt(x,y)=\\frac{1}{n^2}\\sin(nx)\\sinh(nx).\n$$\n\n- at $y=0$, the boundary data can remain bounded\n- at $y>0$, $\\sup |t(x,y)|$ can blow up as $n\\to\\infty$\n\nso tiny perturbations at the boundary can produce huge changes in the interior solution: a textbook unstable inverse setting.\n\n---\n\n## bayesian viewpoint\n\nregularization can be interpreted probabilistically.\na common form is:\n\n$$\n\\sigma(\\mathbf{m}) = \\rho_m(\\mathbf{m})\\,l(\\mathbf{m}), \\qquad l(\\mathbf{m}) = \\rho_d(g(\\mathbf{m}))\n$$\n\nhere, prior knowledge $\\rho_m$ and data likelihood $l$ combine into a posterior over models.\nin high dimensions, we often sample this posterior with monte carlo methods.\n\n---\n\n## what comes next\n\n- [week 1](./week1): information, entropy, and uncertainty\n- [week 2](./week2): least squares and tikhonov regularization\n- [week 3](./week3): linear tomography pipeline\n- [week 4](./week4): nonlinear inversion and monte carlo\n"
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems",
      "routeSlug": "inverse-problems",
      "lessonSlug": "landingPage",
      "lessonTitle": "Inverse Problems",
      "x": 0.5644369125366211,
      "y": 0.16139721870422363,
      "searchText": "inverse problems\n# inverse problems\n\ninverse problems ask a simple question: **what hidden system produced the data we measured?**\nyou observe effects, then infer causes.\n\ntypical examples include medical imaging, seismic exploration, and climate model calibration.\nthe common challenge is that inverse problems are often **ill-posed**: solutions can be non-unique, unstable, or sensitive to noise.\n\n[[figure mri-scan]]\n\n[[figure spect-scan]]\n\n[[figure seismic-tomography]]\n\n---\n\n## learning path\n\nuse this path if you are new to the topic:\n\n1. **foundations**: [introduction](./intro)\n2. **information + uncertainty**: [week 1](./week1)\n3. **regularization and optimization**: [week 2](./week2)\n4. **linear tomography workflow**: [week 3](./week3)\n5. **nonlinear inversion and monte carlo**: [week 4](./week4)\n\ndeep dives:\n\n- [least squares and tikhonov](./tikonov)\n- [linear tomography notes](./linear_tomography)\n\n---\n\n## interactive simulations in this module\n\n- information theory: `entropy-demo`, `kl-divergence`\n- optimization: `steepest-descent`, `tikhonov-regularization`\n- linear inverse problems: `linear-tomography`\n- monte carlo inversion: `monte-carlo-integration`, `vertical-fault-mcmc`, `glacier-thickness-mcmc`, `sphere-in-cube-mc`\n\nthis module is designed for short theory bursts followed by interactive exploration.\n"
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems",
      "routeSlug": "inverse-problems",
      "lessonSlug": "linear_tomography",
      "lessonTitle": "Linear Tomography",
      "x": 0.6481576561927795,
      "y": 0.12860096991062164,
      "searchText": "linear tomography\n# linear tomography\n\nlinear tomography reconstructs hidden structure from line-integral measurements.\nin geophysics, that means inferring subsurface slowness or density anomalies from travel-time data.\n\n---\n\n## forward model\n\nfor a ray path $\\gamma$, the travel-time anomaly is\n\n$$\nt_\\gamma=\\int_\\gamma s(u)\\,du,\n$$\n\nwhere $s(u)$ is slowness anomaly.\nafter discretization on a grid:\n\n$$\n\\mathbf{d}=\\mathbf{gm}.\n$$\n\n- $\\mathbf{m}$: cell-wise model parameters (slowness/density anomaly)\n- $\\mathbf{d}$: measured travel-time anomalies\n- $\\mathbf{g}$: ray-path sensitivity matrix\n\n---\n\n## building the sensitivity matrix\n\neach row of $\\mathbf{g}$ corresponds to one ray.\neach column corresponds to one grid cell.\nentries represent ray length inside the cell (or a scaled approximation).\n\n```python\ndef make_g(n=13):\n    g_right = [np.eye(n, k=1 + i).flatten() for i in range(n - 2)]\n    g_left = [np.flip(np.eye(n, k=-(1 + i)), axis=0).flatten() for i in range(n - 2)]\n    z = np.zeros((1, n**2))\n    g = np.concatenate([z, g_left[::-1], z, z, g_right, z])\n    return g * (2**0.5) * 1000\n```\n\n---\n\n## inversion step\n\ntomographic systems are typically noisy and underdetermined.\nwe therefore solve a regularized inverse problem:\n\n$$\n\\hat{\\mathbf{m}}=(\\mathbf{g}^t\\mathbf{g}+\\epsilon^2\\mathbf{i})^{-1}\\mathbf{g}^t\\mathbf{d}_{\\text{obs}}.\n$$\n\nthe target is a model that:\n\n- fits the data within uncertainty\n- remains stable under noise\n- avoids unrealistic spatial oscillations\n\n[[simulation linear-tomography]]\n\n---\n\n## interpreting resolution\n\nif a region is crossed by many rays from multiple directions, resolution is good.\nif a region is weakly sampled, uncertainty increases and artifacts can appear.\n\na useful stress test is a delta-like true model:\n\n- well-covered cells reconstruct sharply\n- poorly covered cells smear along acquisition geometry\n\nthis links acquisition design directly to inverse quality.\n\n---\n\n## takeaway\n\nlinear tomography turns geometry plus physics into a matrix inverse problem.\nthe quality of reconstruction depends as much on ray coverage and regularization as on numerical solvers."
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems",
      "routeSlug": "inverse-problems",
      "lessonSlug": "Tikonov",
      "lessonTitle": "Tikhonov Regularization",
      "x": 0.5917636156082153,
      "y": 0.24020954966545105,
      "searchText": "tikhonov regularization\n# tikhonov regularization\n\nleast squares alone is often too optimistic for inverse problems.\nnoise and poor conditioning can make the solution unstable or physically unrealistic.\n\n---\n\n## from least squares to tikhonov\n\nfor a linear forward model\n\n$$\n\\mathbf{d}=\\mathbf{gm},\n$$\n\nplain least squares minimizes\n\n$$\ne(\\mathbf{m})=\\|\\mathbf{d}-\\mathbf{gm}\\|^2.\n$$\n\ntikhonov regularization adds a penalty on model complexity:\n\n$$\ne_\\epsilon(\\mathbf{m})=\\|\\mathbf{d}-\\mathbf{gm}\\|^2+\\epsilon^2\\|\\mathbf{m}\\|^2.\n$$\n\nthe regularized solution is\n\n$$\n\\hat{\\mathbf{m}}=(\\mathbf{g}^t\\mathbf{g}+\\epsilon^2\\mathbf{i})^{-1}\\mathbf{g}^t\\mathbf{d}.\n$$\n\n---\n\n## choosing the regularization strength\n\nthe parameter $\\epsilon$ controls the bias-variance trade-off:\n\n- small $\\epsilon$: data fit is strong, noise amplification risk is high\n- large $\\epsilon$: solution is smoother and more stable, but can underfit\n\nin practice, you sweep a range of $\\epsilon$ values and inspect stability, residuals, and physical plausibility.\n\n[[simulation tikhonov-regularization]]\n\n---\n\n## optimization view\n\nthe same objective can be optimized iteratively.\ngradient-based methods are useful for large models and nonlinear extensions.\n\n[[simulation steepest-descent]]\n\nfor the quadratic objective above, steepest descent converges to the same regularized minimizer when steps are chosen properly.\n\n---\n\n## why regularization is physically meaningful\n\nregularization encodes prior structure:\n\n- smoothness\n- bounded energy\n- sparse or low-complexity models\n\nthis mirrors how coarse-grid parameterizations are used in climate and earth-system models.\n\n[[figure climate-grid]]\n\na bayesian interpretation is also common: tikhonov is equivalent to a gaussian prior on model parameters.\n\n[[figure gaussian-process]]\n\n---\n\n## weighted formulation (data and model covariance)\n\nif data covariance is $\\mathbf{c}_d$ and model covariance is $\\mathbf{c}_m$, define whitening transforms:\n\n$$\n\\mathbf{v}^t\\mathbf{v}=\\mathbf{c}_d^{-1}, \\qquad \\mathbf{w}^t\\mathbf{w}=\\mathbf{c}_m^{-1}.\n$$\n\nthen solve in transformed variables:\n\n$$\n\\bar{\\mathbf{d}}=\\mathbf{vd}, \\qquad \\bar{\\mathbf{m}}=\\mathbf{wm}, \\qquad \\bar{\\mathbf{g}}=\\mathbf{vgw}^{-1}.\n$$\n\nthis makes uncertainty weighting explicit and improves interpretability.\n\n---\n\n## takeaway\n\nmost practical inverse problems are noisy and ill-conditioned.\ntikhonov regularization is the baseline tool for making inversion stable, interpretable, and computationally tractable.\n\n\n\n\n\n"
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems",
      "routeSlug": "inverse-problems",
      "lessonSlug": "week1",
      "lessonTitle": "Week 1 - Information, Entropy, and Uncertainty",
      "x": 0.511955976486206,
      "y": 0.20709240436553955,
      "searchText": "week 1 - information, entropy, and uncertainty\n# week 1 - information, entropy, and uncertainty\n\ninverse problems are not only about fitting curves.\nthey are about deciding which model parameters are actually supported by the data.\n\n---\n\n## information as uncertainty reduction\n\nif $x$ is a random variable with probabilities $p_i$, the **shannon entropy** is\n\n$$\nh(x)=-\\sum_i p_i\\log p_i.\n$$\n\nhigh entropy means high uncertainty.\nlow entropy means observations are informative and concentrated.\n\n[[figure claude-shannon]]\n\n[[simulation entropy-demo]]\n\n---\n\n## comparing candidate distributions\n\nwhen we compare two probability models $p$ and $q$, a standard choice is the **kullback-leibler divergence**:\n\n$$\nd_{\\mathrm{kl}}(p\\|q)=\\sum_i p(i)\\log\\frac{p(i)}{q(i)}.\n$$\n\ninterpretation:\n\n- $d_{\\mathrm{kl}}=0$ only when the distributions match\n- larger values indicate larger mismatch\n- it is asymmetric, so direction matters\n\n[[simulation kl-divergence]]\n\n---\n\n## why this matters for inversion\n\nin inversion, we often compare:\n\n- observed data distribution vs model-predicted distribution\n- prior parameter belief vs posterior parameter belief\n\nthese comparisons guide model selection and regularization strength.\n\na practical takeaway is simple: **fit quality is not enough**.\nyou also want a model that is informative, stable, and physically plausible.\n\n---\n\n## week 1 takeaway\n\ninformation-theoretic tools quantify whether your model explains data efficiently.\nin later weeks, we combine this idea with regularized optimization and uncertainty-aware inference.\n"
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems",
      "routeSlug": "inverse-problems",
      "lessonSlug": "week2",
      "lessonTitle": "Week 2 - Regularization and Stable Inference",
      "x": 0.5637973546981812,
      "y": 0.23889701068401337,
      "searchText": "week 2 - regularization and stable inference\n# week 2 - regularization and stable inference\n\nin week 1, we asked whether a model matches data.\nnow we ask a harder question: **is the inferred model stable and physically plausible?**\n\n---\n\n## linear inverse setup\n\nwe start from\n\n$$\n\\mathbf{d}=\\mathbf{gm}+\\boldsymbol{\\eta},\n$$\n\nwhere $\\boldsymbol{\\eta}$ is measurement noise.\nwhen $\\mathbf{g}$ is ill-conditioned or rank-deficient, direct inversion is unstable.\n\n---\n\n## tikhonov objective\n\nuse a regularized objective:\n\n$$\nj(\\mathbf{m})=\\|\\mathbf{d}-\\mathbf{gm}\\|^2+\\epsilon^2\\|\\mathbf{m}\\|^2.\n$$\n\nthis balances:\n\n- **data fit** (first term)\n- **model complexity control** (second term)\n\nclosed-form minimizer:\n\n$$\n\\hat{\\mathbf{m}}=(\\mathbf{g}^t\\mathbf{g}+\\epsilon^2\\mathbf{i})^{-1}\\mathbf{g}^t\\mathbf{d}.\n$$\n\n[[simulation tikhonov-regularization]]\n\n---\n\n## optimization view\n\nthe same objective can be solved iteratively, which is useful for larger or nonlinear systems.\n\n[[simulation steepest-descent]]\n\ninterpretation:\n\n- if the learning rate is too large, iterates oscillate or diverge\n- if too small, convergence is slow\n- regularization smooths the landscape and improves robustness\n\n---\n\n## practical guidance\n\nwhen selecting $\\epsilon$:\n\n1. sweep a log-scale range\n2. inspect residual vs model norm\n3. prefer the simplest model that still explains data uncertainty\n\nthis is often more important than chasing the minimum residual.\n\n---\n\n## week 2 takeaway\n\nregularization is not an optional tweak.\nit is the core mechanism that turns ill-posed inversion into a usable scientific workflow.\n"
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems",
      "routeSlug": "inverse-problems",
      "lessonSlug": "week3",
      "lessonTitle": "Week 3 - Linear Tomography Workflow",
      "x": 0.6243594288825989,
      "y": 0.12479891628026962,
      "searchText": "week 3 - linear tomography workflow\n# week 3 - linear tomography workflow\n\nthis week builds a complete linear tomography pipeline:\nforward modeling, synthetic data generation, regularized inversion, and resolution analysis.\n\n---\n\n## from rays to matrix form\n\ntravel-time anomalies along rays are line integrals of slowness.\nafter discretization on a grid:\n\n$$\n\\mathbf{d}=\\mathbf{gm}.\n$$\n\n- rows of $\\mathbf{g}$: rays/measurements\n- columns of $\\mathbf{g}$: model cells\n- $\\mathbf{m}$: unknown slowness anomalies\n\n---\n\n## synthetic experiment\n\na reliable workflow starts with synthetic truth:\n\n1. define a true anomaly model\n2. compute noiseless data $\\mathbf{gm}_{\\text{true}}$\n3. add controlled noise\n4. recover $\\hat{\\mathbf{m}}$ and compare\n\nthis reveals where the setup is resolvable before touching real data.\n\n[[simulation linear-tomography]]\n\n---\n\n## resolution and coverage\n\ntomographic quality is driven by acquisition geometry:\n\n- dense, cross-cutting rays -> higher local resolution\n- sparse one-directional rays -> elongated uncertainty\n\nthis is why survey design and inversion are inseparable.\n\n---\n\n## link to deep dive\n\nfor derivations and implementation details, see:\n\n- [linear tomography notes](./linear_tomography)\n- [least squares and tikhonov](./tikonov)\n\n---\n\n## week 3 takeaway\n\nlinear tomography is a matrix inverse problem constrained by physics and geometry.\ngood reconstructions come from the combination of coverage, noise modeling, and regularization.\n"
    },
    {
      "topicId": "inverse-problems",
      "topicTitle": "Inverse Problems",
      "routeSlug": "inverse-problems",
      "lessonSlug": "week4",
      "lessonTitle": "Week 4 - Nonlinear Inversion and Monte Carlo",
      "x": 0.5201766490936279,
      "y": 0.15704156458377838,
      "searchText": "week 4 - nonlinear inversion and monte carlo\n# week 4 - nonlinear inversion and monte carlo\n\nnonlinear inverse problems rarely admit closed-form solutions.\ninstead, we estimate parameters with stochastic sampling and posterior exploration.\n\n---\n\n## why monte carlo\n\nsuppose your posterior over parameters is $p(\\mathbf{x}\\mid \\mathbf{d})$.\ndirect integration is often intractable in high dimensions, so we sample.\n\nfor basic rejection sampling:\n\n$$\np_{\\text{accept}}=\\frac{p(\\mathbf{x}_{\\text{cand}})}{m},\n\\qquad m\\ge \\max_{\\mathbf{x}} p(\\mathbf{x}).\n$$\n\nwith proposal density $q$:\n\n$$\np_{\\text{accept}}=\\frac{p(\\mathbf{x}_{\\text{cand}})}{m q(\\mathbf{x}_{\\text{cand}})}.\n$$\n\n[[simulation monte-carlo-integration]]\n\n---\n\n## markov chain monte carlo (mcmc)\n\nmcmc avoids independent sampling from a hard posterior.\nit builds a chain that spends more time in high-probability regions.\n\na common metropolis-style acceptance rule is:\n\n$$\np_{\\text{accept}}=\\min\\left(1,\\frac{p(\\mathbf{x}_{\\text{new}})}{p(\\mathbf{x}_{\\text{old}})}\\right).\n$$\n\npractical diagnostics to monitor:\n\n- burn-in length\n- acceptance rate\n- chain mixing\n- autocorrelation\n\n---\n\n## example: vertical fault inversion\n\ngeometry and synthetic setup:\n\n[[figure vertical-fault-diagram]]\n\nposterior exploration:\n\n[[simulation vertical-fault-mcmc]]\n\nkey insight: multiple parameter combinations can produce similar data, so posterior shape matters more than a single point estimate.\n\n---\n\n## example: glacier thickness inversion\n\nforward geometry:\n\n[[figure glacier-valley-diagram]]\n\nsampling-based inversion:\n\n[[simulation glacier-thickness-mcmc]]\n\nthis case highlights the trade-off between fit quality and physically plausible smooth thickness profiles.\n\n---\n\n## monte carlo geometry intuition\n\nbefore full inversion, it helps to build geometric intuition with volume estimation:\n\n[[simulation sphere-in-cube-mc]]\n\nas sample count grows, monte carlo error decays roughly as $o(n^{-1/2})$.\n\n---\n\n## week 4 takeaway\n\nfor nonlinear inverse problems, uncertainty is part of the answer.\nmonte carlo methods turn inversion from \"find one best model\" into \"characterize a credible family of models.\"\n\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "assignments-projects",
      "lessonTitle": "Assignments and Project Ideas",
      "x": 0.11027190834283829,
      "y": 0.3717740476131439,
      "searchText": "assignments and project ideas\n# assignments and project ideas\n\n## empirical assignment track\n\nimplement and compare learning curves and regret for:\n\n- hedge in expert advice.\n- ucb1 and exp3 in multi-armed bandits.\n- sarsa and q-learning in a gridworld or cliff-walking environment.\n- dqn on a compact control benchmark.\n\nsuggested outputs:\n\n- cumulative reward curves.\n- cumulative regret curves.\n- sensitivity to learning rate and exploration schedule.\n\n## theoretical assignment track\n\nderive and present key arguments:\n\n- regret bound sketch for hedge.\n- concentration-based arm selection argument for ucb.\n- bellman contraction proof and fixed-point uniqueness.\n- on-policy vs off-policy update implications.\n\n## course project\n\nchoose one applied setting and report reproducible experiments:\n\n- online advertising or recommendation simulator.\n- inventory/control mdp.\n- custom game or robotics-inspired simulator.\n- gymnasium-style benchmark environment.\n\nminimum project deliverables:\n\n1. problem definition and assumptions.\n2. baselines and chosen algorithm(s).\n3. experimental protocol.\n4. regret or return analysis.\n5. failure modes and next improvements.\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "average-reward-online-rl",
      "lessonTitle": "Online RL in Average-Reward and Discounted Settings",
      "x": 0.07274629175662994,
      "y": 0.30855947732925415,
      "searchText": "online rl in average-reward and discounted settings\n# online rl in average-reward and discounted settings\n\ndiscounted rl optimizes\n\n$$\n\\mathbb{e}\\left[\\sum_{t=0}^{\\infty}\\gamma^t r_t\\right].\n$$\n\naverage-reward rl targets long-run gain\n\n$$\ng^\\pi(s)=\\lim_{t\\to\\infty}\\frac{1}{t}\\mathbb{e}\\left[\\sum_{t=1}^{t}r_t \\mid s_1=s\\right].\n$$\n\n## gain and bias\n\n- **gain** captures steady-state average reward.\n- **bias** captures transient advantage before steady state.\n\nthis decomposition is central in continuing tasks without episodic reset.\n\n## representative algorithmic ideas\n\n- relative value iteration.\n- differential td / differential q-learning.\n- r-learning style methods.\n- optimism under uncertainty in model-based online rl.\n\n## regret in rl\n\nfor online rl, regret compares cumulative reward to the optimal policy in the same environment class.\nmodern methods include optimistic and posterior-sampling approaches (for example, ucrl- and psrl-style methods).\n\n[[simulation average-reward-vs-discounted]]\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "bandits-ucb-exp3",
      "lessonTitle": "Stochastic and Adversarial Bandits: UCB1 and EXP3",
      "x": 0.08763959258794785,
      "y": 0.4328443706035614,
      "searchText": "stochastic and adversarial bandits: ucb1 and exp3\n# stochastic and adversarial bandits: ucb1 and exp3\n\nassume $k$ arms and horizon $t$.\n\n## ucb1 (stochastic bandits)\n\nfor each arm $a$, let $\\widehat{\\mu}_a(t)$ be empirical mean and $n_a(t)$ pull count.\nucb1 chooses\n\n$$\na_t \\in \\arg\\max_a \\left[\\widehat{\\mu}_a(t) + \\sqrt{\\frac{2\\log t}{n_a(t)}}\\right].\n$$\n\ninterpretation: optimism under uncertainty.\n\n- gap-dependent regret: $o\\!\\left(\\sum_{a:\\delta_a>0}\\frac{\\log t}{\\delta_a}\\right)$.\n- gap-free regret: $o(\\sqrt{kt\\log t})$.\n\n## exp3 (adversarial bandits)\n\nexp3 adapts exponential weights to partial feedback.\n\n- maintain weights $w_t(i)$.\n- build exploration-smoothed sampling distribution $p_t$.\n- observe only chosen loss/reward.\n- use importance-weighted estimate to update all weights.\n\ntypical regret rate:\n\n$$\nr_t = o(\\sqrt{kt\\log k}).\n$$\n\nlower bounds are $\\omega(\\sqrt{kt})$ in adversarial bandits, so this is near-optimal up to log factors.\n\n[[simulation multi-armed-bandit]]\n[[simulation bandit-regret-comparison]]\n[[simulation bernoulli-trials]]\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "contextual-bandits-exp4",
      "lessonTitle": "Contextual Bandits and EXP4",
      "x": 0.06845445185899734,
      "y": 0.44788119196891785,
      "searchText": "contextual bandits and exp4\n# contextual bandits and exp4\n\nin contextual bandits, each round starts with context $x_t$.\nthe learner chooses action $a_t$ using $x_t$ and receives only bandit feedback for that action.\n\n## why contextual bandits\n\n- personalization in ads and recommendations.\n- medical dosing with patient covariates.\n- adaptive interfaces and ranking.\n\n## exp4 idea\n\nexp4 aggregates a set of experts (policies), where each expert maps context to an action distribution.\n\nat round $t$:\n\n1. each expert proposes a distribution over actions for context $x_t$.\n2. the learner forms a mixture distribution over experts.\n3. sample an action from the induced action distribution.\n4. build an importance-weighted loss estimate.\n5. update expert weights exponentially.\n\nthis achieves regret that scales roughly with $\\sqrt{t\\log |\\mathcal{e}|}$ (up to constants and feedback terms), where $\\mathcal{e}$ is the expert class.\n\n[[simulation contextual-bandit-exp4]]\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "deep-rl-dqn",
      "lessonTitle": "Function Approximation and Deep Q-Learning",
      "x": 0.12749464809894562,
      "y": 0.20122763514518738,
      "searchText": "function approximation and deep q-learning\n# function approximation and deep q-learning\n\ntabular methods do not scale to high-dimensional or continuous state spaces.\nfunction approximation replaces lookup tables with parameterized models.\n\n## from linear approximation to neural networks\n\n- linear value approximation is simple but limited.\n- deep neural networks enable large-scale representation learning.\n\n## dqn essentials\n\n- replay buffer to decorrelate samples.\n- target network for stable bootstrapping targets.\n- gradient clipping and robust losses.\n- double-q style targets to reduce overestimation.\n\n## stability challenge: the deadly triad\n\ninstability appears when combining:\n\n1. function approximation.\n2. bootstrapping.\n3. off-policy training.\n\ndqn mitigates, but does not eliminate, these risks.\n\n## beyond dqn (brief)\n\n- policy gradients.\n- actor-critic methods.\n- continuous-control variants.\n\n[[simulation dqn-stability]]\n[[simulation activation-functions]]\n[[simulation cartpole-learning-curves]]\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "feedback-and-settings",
      "lessonTitle": "Forms of Feedback and Problem Settings",
      "x": 0.0407230444252491,
      "y": 0.40146636962890625,
      "searchText": "forms of feedback and problem settings\n# forms of feedback and problem settings\n\nthe available feedback determines both algorithm design and regret guarantees.\n\n## full-information feedback\n\nat round $t$, the learner observes the whole loss vector:\n\n$$\n(\\ell_t(1), \\ell_t(2), \\ldots, \\ell_t(k)).\n$$\n\ntypical setting: prediction with expert advice.\n\n## bandit (partial) feedback\n\nonly the chosen action's loss is observed:\n\n$$\n\\ell_t(a_t).\n$$\n\nthis requires explicit exploration and usually introduces an extra $\\sqrt{k}$ factor in regret rates.\n\n## contextual feedback\n\na context vector $x_t$ arrives before action selection.\nthe learner chooses $a_t$ using $(x_t, \\text{history})$ and only receives feedback for the chosen action.\n\n## additional realism\n\n- delayed feedback.\n- noisy feedback.\n- drifting or non-stationary environments.\n- adversarially chosen outcomes.\n\nthese variants alter concentration arguments, estimator variance, and final regret bounds.\n\nbandit estimation quality and exploration budget are central themes in the next lessons.\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "ftl-and-hedge",
      "lessonTitle": "Follow the Leader and Hedge",
      "x": 0.0,
      "y": 0.36338478326797485,
      "searchText": "follow the leader and hedge\n# follow the leader and hedge\n\n## follow the leader (ftl)\n\nftl picks the action minimizing cumulative past loss:\n\n$$\na_t \\in \\arg\\min_{a \\in \\mathcal{a}} \\sum_{s=1}^{t-1}\\ell_s(a).\n$$\n\nstrengths:\n\n- simple and parameter-free.\n- works well for strongly convex or stable losses.\n\nweakness:\n\n- can oscillate badly in adversarial sequences, causing linear regret.\n\n[[simulation ftl-instability]]\n\n## hedge / exponential weights\n\nsetting: $n$ experts, full-information losses $\\ell_t(i)\\in[0,1]$.\n\ninitialize weights $w_1(i)=1$ and choose\n\n$$\np_t(i)=\\frac{w_t(i)}{\\sum_j w_t(j)}.\n$$\n\nupdate after observing losses:\n\n$$\nw_{t+1}(i)=w_t(i)\\exp(-\\eta \\ell_t(i)).\n$$\n\nwith $\\eta \\asymp \\sqrt{\\log n / t}$, regret scales as\n\n$$\nr_t = o(\\sqrt{t\\log n}).\n$$\n\nproof idea: potential $\\phi_t=\\sum_i w_t(i)$, multiplicative update bounds, and second-order control.\n\n[[simulation hedge-weights-regret]]\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "home",
      "lessonTitle": "Online and Reinforcement Learning",
      "x": 0.11318337917327881,
      "y": 0.31660401821136475,
      "searchText": "online and reinforcement learning\n# online and reinforcement learning\n\n## course overview\n\nonline learning and reinforcement learning study **sequential decision making**.\nunlike classical offline machine learning, data are not i.i.d. and the learner can change future data through its actions.\n\n- offline ml: fixed dataset, i.i.d. assumptions, generalization error.\n- online/rl: repeated interaction, potentially non-stationary or adversarial feedback, continual adaptation.\n\ncore interaction loop:\n\n1. observe state or context.\n2. choose an action.\n3. receive feedback (reward/loss, full or partial).\n4. update the decision rule.\n\n[[figure mdp-agent-environment-loop]]\n\n## why this topic matters\n\n- adversarial games and planning (for example, chess-like settings).\n- repeated investment and portfolio decisions.\n- spam filtering and security screening under adaptive opponents.\n- online advertising and recommendation systems.\n- routing and control in networks and robotics.\n- sequential medical decision support.\n\n## key mathematical ideas\n\n- regret minimization and no-regret learning.\n- online convex optimization and mirror-style updates.\n- bandit feedback and exploration-exploitation trade-offs.\n- markov decision processes and bellman operators.\n\n## prerequisites\n\n- probability and random variables.\n- linear algebra.\n- basic optimization and machine learning.\n- differential and integral calculus.\n\n## recommended reading\n\n- sutton and barto, *reinforcement learning: an introduction* (2nd edition).\n- cesa-bianchi and lugosi, *prediction, learning, and games*.\n- lattimore and szepesvari, *bandit algorithms*.\n- hazan, *introduction to online convex optimization*.\n\n## learning trajectory\n\nthis module is organized from online prediction and bandits to full rl:\n\n- regret and feedback models.\n- expert advice and adversarial online learning.\n- stochastic and adversarial bandits.\n- mdp foundations and dynamic programming.\n- monte carlo and temporal-difference methods.\n- deep rl and average-reward online rl.\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "mdp-and-dp",
      "lessonTitle": "MDPs and Dynamic Programming",
      "x": 0.12303799390792847,
      "y": 0.2671840488910675,
      "searchText": "mdps and dynamic programming\n# mdps and dynamic programming\n\n## markov decision processes\n\nan mdp is a tuple\n\n$$\n\\langle \\mathcal{s}, \\mathcal{a}, p, r, \\gamma \\rangle\n$$\n\nwith states, actions, transition kernel, reward function, and discount factor.\n\npolicies can be deterministic or stochastic. value functions:\n\n$$\nv^\\pi(s)=\\mathbb{e}^\\pi\\left[\\sum_{t=0}^{\\infty}\\gamma^t r_t \\mid s_0=s\\right],\\quad\nq^\\pi(s,a)=\\mathbb{e}^\\pi\\left[\\sum_{t=0}^{\\infty}\\gamma^t r_t \\mid s_0=s,a_0=a\\right].\n$$\n\n## bellman equations\n\n- policy evaluation:\n  $v^\\pi = r^\\pi + \\gamma p^\\pi v^\\pi$.\n- optimality:\n  $v^*(s)=\\max_a\\left[r(s,a)+\\gamma\\sum_{s'}p(s'|s,a)v^*(s')\\right]$.\n\nfor discounted finite mdps, bellman operators are contractions, giving unique fixed points.\n\n## dynamic programming algorithms\n\n- policy evaluation: iterative bellman backup.\n- policy iteration: evaluate policy then greedy improve.\n- value iteration: repeatedly apply bellman optimality operator.\n\nthese are planning methods (model known), not model-free learning.\n\n[[simulation gridworld-mdp]]\n[[simulation dp-convergence]]\n[[simulation mdp-simulation]]\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "monte-carlo-rl",
      "lessonTitle": "Monte Carlo Methods for RL",
      "x": 0.053012050688266754,
      "y": 0.2752454876899719,
      "searchText": "monte carlo methods for rl\n# monte carlo methods for rl\n\nmonte carlo (mc) methods estimate values from **complete episodes**.\nno transition model is required.\n\n## core idea\n\nfor return\n\n$$\ng_t = \\sum_{k=0}^{t-t-1} \\gamma^k r_{t+k+1},\n$$\n\nestimate values by sample averages:\n\n$$\nv^\\pi(s)\\approx \\frac{1}{n(s)}\\sum_{t:\\,s_t=s} g_t.\n$$\n\n## variants\n\n- first-visit mc.\n- every-visit mc.\n- on-policy mc control.\n- off-policy mc with importance sampling.\n\n## trade-offs\n\n- low bias for return targets.\n- high variance, especially with long horizons.\n- naturally episodic and simple to implement.\n\n[[simulation monte-carlo-convergence]]\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "regret",
      "lessonTitle": "The Notion of Regret",
      "x": 0.04707813635468483,
      "y": 0.3563782274723053,
      "searchText": "the notion of regret\n# the notion of regret\n\nregret is the primary performance metric in online learning.\nit compares the learner's cumulative loss to a benchmark policy, often the best fixed action in hindsight.\n\nfor losses, external regret over horizon $t$ is\n\n$$\nr_t = \\sum_{t=1}^{t} \\ell_t(a_t) - \\min_{a \\in \\mathcal{a}} \\sum_{t=1}^{t} \\ell_t(a).\n$$\n\nsublinear regret, $r_t = o(t)$, implies average regret $r_t/t \\to 0$.\n\n## why regret replaces generalization error\n\n- no i.i.d. requirement.\n- works under adversarial sequences.\n- naturally handles sequential adaptation.\n- provides minimax comparisons and lower bounds.\n\n## variants\n\n- **expected regret**: $\\mathbb{e}[r_t]$.\n- **high-probability regret**: bounds that hold with probability at least $1-\\delta$.\n- **pseudo-regret** (stochastic settings): compares against the best expected arm/policy.\n- **external regret** vs **internal/swap regret**.\n\n## adversarial vs stochastic interpretation\n\n- stochastic bandits: losses/rewards sampled from fixed distributions.\n- adversarial online learning: losses can be arbitrary or adaptive.\n- minimax lower bounds differ by feedback model:\n  - full information: typically $\\omega(\\sqrt{t \\log n})$ scale.\n  - bandit feedback: typically $\\omega(\\sqrt{kt})$ scale.\n\n## practical examples\n\n- portfolio learning compared with the best stock in hindsight.\n- expert aggregation compared with the best expert sequence baseline.\n\n[[simulation regret-growth-comparison]]\n"
    },
    {
      "topicId": "online-reinforcement-learning",
      "topicTitle": "Online Reinforcement Learning",
      "routeSlug": "online-reinforcement",
      "lessonSlug": "td-sarsa-qlearning",
      "lessonTitle": "Temporal-Difference Learning, SARSA, and Q-Learning",
      "x": 0.08891921490430832,
      "y": 0.2208370715379715,
      "searchText": "temporal-difference learning, sarsa, and q-learning\n# temporal-difference learning, sarsa, and q-learning\n\ntd methods bootstrap from current estimates instead of waiting for episode termination.\n\n## td(0) state-value update\n\n$$\nv(s_t)\\leftarrow v(s_t)+\\alpha\\left[r_{t+1}+\\gamma v(s_{t+1})-v(s_t)\\right].\n$$\n\nthe bracketed term is the td error.\n\n## sarsa (on-policy control)\n\n$$\nq(s_t,a_t)\\leftarrow q(s_t,a_t)+\\alpha\\left[r_{t+1}+\\gamma q(s_{t+1},a_{t+1})-q(s_t,a_t)\\right].\n$$\n\nsarsa learns the value of the behavior policy (often epsilon-greedy).\n\n## q-learning (off-policy control)\n\n$$\nq(s_t,a_t)\\leftarrow q(s_t,a_t)+\\alpha\\left[r_{t+1}+\\gamma \\max_{a'}q(s_{t+1},a')-q(s_t,a_t)\\right].\n$$\n\nwith sufficient exploration and suitable step sizes in tabular settings, q-learning converges to $q^*$.\n\n## exploration\n\n- epsilon-greedy.\n- softmax/boltzmann exploration.\n- optimism and ucb-like bonuses.\n\n[[simulation sarsa-vs-qlearning]]\n[[simulation concentration-bounds]]\n[[simulation stochastic-approximation]]\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "atom-field-interaction",
      "lessonTitle": "Atom-Field Interaction",
      "x": 0.8788571953773499,
      "y": 0.8370842337608337,
      "searchText": "atom-field interaction\n# atom-field interaction\n__topic 12 keywords__\n- perturbation theory \n- rabi oscillations\n- jaynes-cummings model\n\n# readings\nch. 4.3-5 \n\n# 4.3 interaction of an atom with a quantized field\n#### dipole approximation\nimagine a situation with electromagnetic field act on one atom.\n\nto begin, hamiltonian of an electron bound to an atom in vacuum is\n$$\n    \\hat{h}_\\mathrm{atom}\n    =\n    \\frac{\\hat{p}^2}{2m}\n    +\n    v(\\vec{r})\n$$\nhere, $v(\\vec{r})$ is coulomb potential.\n\nin presence of external fields, the hamiltonian become,\n$$\n    \\hat{h}\n    =\n    \\frac{1}{2m}\n    \\left(\n    \\hat{p}^2\n    +\n    e \\vec{a}(\\vec{r}, t)\n    \\right)^2\n    +\n    v(\\vec{r})\n$$\n\nwe can further simplify the equation.\nthe spatial dependency of electromagnetic field is $e^{i \\vec{k} \\cdot \\vec{r}}$.\nby assuming typical light wavelength as $\\lambda \\sim 500 \\mathrm{nm}$, \nand $\\vec{r}$ is few angstroms, \nthe magnitude of $\\left| \\vec{k} \\cdot \\vec{r} \\right|$ is smaller than one.\n$$\n    \\left| \\vec{k} \\cdot \\vec{r} \\right|\n    \\ll\n    1\n$$\nthus, we can ignore the spatial dependency of electromagnetic field.\n$$\n    \\hat{h}\n    =\n    \\hat{h}_\\mathrm{atom}\n    -\n    \\hat{\\vec{d}} \\cdot \\hat{\\vec{e}} (t)\n$$\nthis is **dipole approximation**.\n\n#### 2-level emitter in cavity (perturbation theory)\nimagine a 2-level system in cavity. \nwe apply single optical mode.\nelectric field on atom is \n$$\n    \\hat{\\vec{e}}\n    =\n    \\vec{\\mathcal{e}}\n    \\left( \n        \\hat{a} + \\hat{a}^\\dag\n    \\right)\n$$\nwe are going to solve schr\u00f6dinger equation.\n$$\n    i\\hbar\n    \\frac{\\partial}{\\partial t}\n    \\ket{\\psi(t)}\n    =\n    \\hat{h}\n    \\ket{\\psi(t)}\n$$\nwe use *ansatz* solution. \n$$\n\\begin{aligned}\n    \\ket{\\psi(t)}\n    &=\n    c_i(t) \n    \\cdot\n    \\ket{a} \n    \\ket{n}\n    \\cdot\n    e^{-i e_a t/\\hbar}\n    e^{-i n \\omega t}\n    +\n    c_f(t) \n    \\cdot\n    \\ket{b} \n    \\ket{n-1}\n    \\cdot\n    e^{-i e_b t/\\hbar}\n    e^{-i (n-1) \\omega t}\n    \\\\&=\n    c_i(t) \n    \\cdot\n    \\ket{i} \n    \\cdot\n    e^{-i e_a t/\\hbar}\n    e^{-i n \\omega t}\n    +\n    c_f(t) \n    \\cdot\n    \\ket{f} \n    \\cdot\n    e^{-i e_b t/\\hbar}\n    e^{-i (n-1) \\omega t}\n\\end{aligned}\n$$\nhere, \n$c_i(t)$ is complex coefficient, \n$\\ket{i}$ is initial state with $a$ state and $n$ photon, \n$e^{-i e_a t/\\hbar}$ is time evolution of atom, \nand $e^{-i n \\omega t}$ is time evolution of photon.\n\n\n# 4.4 the rabi model\n\n# 4.5 fully quantum-mechanical model; the jaynes-cummings model\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "cavity-qed",
      "lessonTitle": "Cavity QED",
      "x": 0.9141861796379089,
      "y": 0.8935409188270569,
      "searchText": "cavity qed\n# cavity qed\n\n## cavity quantum electrodynamics\n\n**cavity qed** studies the interaction between atoms and photons confined in a high-quality resonator. by trapping the electromagnetic field in a small volume, the atom-photon coupling strength $g$ can be made large relative to the dissipation rates, enabling the observation of fundamentally quantum phenomena.\n\nthe three key rates are:\n- $g$: atom-cavity coupling strength.\n- $\\kappa$: cavity photon loss rate (inverse of cavity lifetime).\n- $\\gamma$: atomic spontaneous emission rate into non-cavity modes.\n\nthe **strong coupling regime** $g \\gg \\kappa, \\gamma$ allows coherent exchange of excitations between atom and field before either decays.\n\n## the purcell effect\n\nwhen an atom is placed in a resonant cavity, its spontaneous emission rate is modified. the **purcell factor** gives the enhancement:\n\n$$\nf_p = \\frac{\\gamma_{\\text{cav}}}{\\gamma_{\\text{free}}} = \\frac{3}{4\\pi^2}\\left(\\frac{\\lambda}{n}\\right)^3 \\frac{q}{v},\n$$\n\nwhere $q$ is the cavity quality factor and $v$ is the mode volume. high-$q$, small-$v$ cavities dramatically enhance emission into the cavity mode.\n\nin the weak coupling regime ($g < \\kappa$), the atom still decays irreversibly but at the enhanced purcell rate $\\gamma_{\\text{cav}} = 4g^2/\\kappa$. in the strong coupling regime, the decay is replaced by reversible rabi oscillations described by the jaynes-cummings model.\n\nconversely, when the cavity is far detuned from the atomic transition, the density of states is suppressed and spontaneous emission is **inhibited**. this was first demonstrated by kleppner (1981) using rydberg atoms between conducting plates.\n\n## experimental platforms\n\n**microwave cavity qed** uses rydberg atoms (with transition frequencies in the ghz range) passing through superconducting microwave cavities. pioneered by haroche and colleagues, these experiments achieve:\n- photon lifetimes of $\\sim 0.1$ seconds in superconducting cavities.\n- strong coupling with $g/2\\pi \\sim 50$ khz.\n- single-atom, single-photon resolution.\n\n**optical cavity qed** uses alkali atoms trapped in high-finesse fabry-perot cavities. pioneered by kimble and colleagues, these experiments work at optical frequencies with:\n- small mode volumes ($\\sim \\lambda^3$).\n- strong coupling with $g/2\\pi \\sim 10{-}100$ mhz.\n- direct single-photon detection.\n\n**circuit qed** replaces atoms with superconducting qubits and cavities with microwave transmission line resonators. the coupling strength is orders of magnitude larger than in natural atoms:\n- $g/2\\pi \\sim 100$ mhz (easily in strong coupling).\n- highly controllable fabrication.\n- the dominant platform for quantum computing (ibm, google).\n\n## cat-state generation\n\na **schrodinger cat state** is a superposition of two macroscopically distinct coherent states:\n\n$$\n|\\text{cat}_\\pm\\rangle = \\mathcal{n}_\\pm(|\\alpha\\rangle \\pm |-\\alpha\\rangle),\n$$\n\nwhere $\\mathcal{n}_\\pm$ is a normalization constant. the even cat $|+\\rangle$ contains only even photon numbers, while the odd cat $|-\\rangle$ contains only odd photon numbers.\n\nin cavity qed, cat states are generated using the **dispersive interaction**. an atom in a superposition $(|e\\rangle + |g\\rangle)/\\sqrt{2}$ interacting dispersively with a coherent state $|\\alpha\\rangle$ creates an entangled state:\n\n$$\n\\frac{1}{\\sqrt{2}}(|e\\rangle|\\alpha e^{i\\chi t}\\rangle + |g\\rangle|\\alpha e^{-i\\chi t}\\rangle).\n$$\n\nat $\\chi t = \\pi/2$, this becomes $\\frac{1}{\\sqrt{2}}(|e\\rangle|i\\alpha\\rangle + |g\\rangle|-i\\alpha\\rangle)$. a subsequent $\\pi/2$ pulse and measurement on the atom projects the cavity into a cat state.\n\nthese experiments were performed by haroche's group and provide direct evidence of quantum superpositions at the mesoscopic scale. the decoherence of cat states (monitored by wigner function tomography) demonstrates the quantum-to-classical transition.\n\n[[simulation wigner-cat-state]]\n\n## decoherence and quantum jumps\n\nreal cavities lose photons at rate $\\kappa$, and atoms decay at rate $\\gamma$. the system dynamics are described by a **master equation**:\n\n$$\n\\frac{d\\hat{\\rho}}{dt} = -\\frac{i}{\\hbar}[\\hat{h}, \\hat{\\rho}] + \\kappa\\mathcal{d}[\\hat{a}]\\hat{\\rho} + \\gamma\\mathcal{d}[\\hat{\\sigma}_-]\\hat{\\rho},\n$$\n\nwhere $\\mathcal{d}[\\hat{o}]\\hat{\\rho} = \\hat{o}\\hat{\\rho}\\hat{o}^\\dagger - \\frac{1}{2}\\{\\hat{o}^\\dagger\\hat{o}, \\hat{\\rho}\\}$ is the lindblad dissipator.\n\nfor cat states, decoherence occurs at a rate $\\gamma_{\\text{decoherence}} = 2\\kappa|\\alpha|^2$, proportional to the \"size\" of the superposition. larger cats decohere faster, consistent with the difficulty of observing quantum effects at macroscopic scales.\n\n**quantum jump** monitoring (measuring the environment) reveals individual photon loss events in real time. between jumps, the system evolves under a non-hermitian effective hamiltonian, and each jump projects the state. this was first observed by nagourney, sauter, and dehmelt (1986) in ion traps.\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "coherence-functions",
      "lessonTitle": "Coherence Functions",
      "x": 0.7778085470199585,
      "y": 0.9540395140647888,
      "searchText": "coherence functions\n# coherence functions\n\n## classical coherence\n\n**coherence** describes the ability of light to produce interference. classically, it is quantified by **correlation functions** of the electric field. the first-order correlation function is\n\n$$\ng^{(1)}(\\mathbf{r}_1, t_1; \\mathbf{r}_2, t_2) = \\langle e^*(\\mathbf{r}_1, t_1) e(\\mathbf{r}_2, t_2) \\rangle.\n$$\n\nthe normalized version is the **degree of first-order coherence**:\n\n$$\ng^{(1)}(\\tau) = \\frac{\\langle e^*(t) e(t+\\tau) \\rangle}{\\langle |e(t)|^2 \\rangle}.\n$$\n\nfor a perfectly monochromatic source, $|g^{(1)}(\\tau)| = 1$ for all $\\tau$. for a thermal source with spectral width $\\delta\\nu$, the coherence decays on a timescale $\\tau_c \\sim 1/\\delta\\nu$, called the **coherence time**.\n\n**temporal coherence** measures how well the field correlates with itself at different times at the same point. **spatial coherence** measures correlations between different spatial points at the same time. the **wiener-khintchine theorem** relates $g^{(1)}(\\tau)$ to the power spectral density through a fourier transform.\n\n## quantum coherence functions\n\nin quantum optics, the electric field becomes an operator, and correlation functions involve **normal ordering** (creation operators to the left, annihilation operators to the right). the quantum first-order correlation function is\n\n$$\ng^{(1)}(\\mathbf{r}_1, t_1; \\mathbf{r}_2, t_2) = \\langle \\hat{e}^{(-)}(\\mathbf{r}_1, t_1) \\hat{e}^{(+)}(\\mathbf{r}_2, t_2) \\rangle,\n$$\n\nwhere $\\hat{e}^{(+)}$ and $\\hat{e}^{(-)}$ are the positive and negative frequency parts of the field operator.\n\nfor different quantum states, $g^{(1)}$ behaves differently:\n- **coherent state** $|\\alpha\\rangle$: $|g^{(1)}(\\tau)| = 1$ (perfect first-order coherence, just like a classical field).\n- **number state** $|n\\rangle$: $|g^{(1)}(\\tau)| = 1$ (also perfectly coherent in first order).\n- **thermal state**: $|g^{(1)}(\\tau)|$ decays with $\\tau$, reflecting the broad spectral content.\n\nfirst-order coherence alone cannot distinguish quantum from classical light. the differences emerge at higher orders.\n\n## young's interference with quantum fields\n\nyoung's double-slit experiment illustrates first-order coherence. two pinholes at positions $\\mathbf{r}_1$ and $\\mathbf{r}_2$ sample the field, and the intensity at the observation screen is\n\n$$\ni(\\mathbf{r}) \\propto g^{(1)}(\\mathbf{r}_1, \\mathbf{r}_1) + g^{(1)}(\\mathbf{r}_2, \\mathbf{r}_2) + 2\\operatorname{re}\\left[g^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2) e^{i\\phi}\\right],\n$$\n\nwhere $\\phi$ is the phase difference due to path lengths. the **visibility** of the interference fringes is\n\n$$\n\\mathcal{v} = \\frac{i_{\\max} - i_{\\min}}{i_{\\max} + i_{\\min}} = |g^{(1)}(\\mathbf{r}_1, \\mathbf{r}_2)|.\n$$\n\nremarkably, single photons also produce interference fringes when detected one at a time over many trials. each photon interferes with itself, building up the pattern statistically. this was demonstrated by taylor (1909) and later with more controlled single-photon sources.\n\n## photodetection theory\n\nthe quantum theory of **photodetection** connects correlation functions to measurable quantities. the probability of detecting a photon at position $\\mathbf{r}$ and time $t$ is proportional to\n\n$$\np_1 \\propto \\langle \\hat{e}^{(-)}(\\mathbf{r}, t) \\hat{e}^{(+)}(\\mathbf{r}, t) \\rangle = g^{(1)}(\\mathbf{r}, t; \\mathbf{r}, t).\n$$\n\nthe joint probability of detecting photons at two space-time points involves $g^{(2)}$, the second-order correlation function. normal ordering ensures that these expressions give physically meaningful (non-negative) detection probabilities, consistent with the photoelectric effect.\n\n[[simulation wigner-coherent]]\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "coherent-states",
      "lessonTitle": "Coherent States",
      "x": 0.7663951516151428,
      "y": 0.8524071574211121,
      "searchText": "coherent states\n# coherent states\n__topic 3 keywords__\n- coherent states\n- displacement operator\n- generation of coherent states\n\n# readings\nch. 3.1-5\n\n# 3.1 eigenstates of the annihilation operator and minimum uncertainty states\n#### definition of coherent state\ncoherent states are defined as eigenstate of annihilation operator.\n$$\n    \\boxed{\n        \\hat{a}\n        \\ket{\\alpha}\n        =\n        \\alpha\n        \\ket{\\alpha}\n    }\n$$\n$$\n    \\boxed{\n        \\hat{a}^\\dag\n        \\bra{\\alpha}\n        =\n        \\alpha^*\n        \\bra{\\alpha}\n    }\n$$\nas you know that $\\hat{a}$ is non-hermitian so the eigenvalue **$\\alpha$ is complex \nnumber**.\nby the way $\\hat{n}=\\hat{a}^\\dag\\hat{a}$ is hermitian.\n\n#### expanding coherent state with number state\nlet's expand coherent state with number state.\nfirst, we multiply identity $\\sum_{n=0}^\\infty \\ket{n}\\bra{n}$ to alpha.\nby this operation, we can project coherent state to number state.\n$$\n\\begin{aligned}\n    \\ket{\\alpha}\n    &=\n    \\sum_{n=0}^\\infty \n    \\ket{n}\n    \\braket{n|\\alpha}\n    \\\\&=\n    \\sum_{n=0}^\\infty \n    c_n\n    \\ket{n}\n\\end{aligned}\n$$\nwe replaced the $\\braket{n|\\alpha}=c_n$.\n\napply operator to $\\ket{\\alpha}$ resuts to\n$$\n\\begin{aligned}\n    \\hat{a}\n    \\ket{\\alpha}\n    &=\n    \\alpha\n    \\ket{\\alpha}\n    \\\\&=\n    \\sum_{n=0}^\\infty \n    \\alpha\n    c_n\n    \\ket{n}\n\\end{aligned}\n$$\nyou know, this is just a definition.\nmultiplying $\\hat{a}$ from left results\n$$\n\\begin{aligned}\n    \\hat{a}\n    \\sum_{n=0}^\\infty \n    c_n\n    \\ket{n}\n    &=\n    \\sum_{n=1}^\\infty \n    \\sqrt{n}\n    c_n\n    \\ket{n-1}\n    \\\\&=\n    \\sum_{n=0}^\\infty \n    \\sqrt{n+1}\n    c_{n+1}\n    \\ket{n}\n\\end{aligned}\n$$\ncoefficient of number state is equal.\n$$\n    \\sqrt{n+1}\n    c_{n+1}\n    =\n    \\alpha\n    c_n\n$$\nthus, we can decide the $c_n$ recursively.\n$$\n\\begin{aligned}\n    c_n\n    &=\n    \\frac\n    {\\alpha}\n    {\\sqrt{n}}\n    c_{n-1}\n    \\\\&=\n    \\frac\n    {\\alpha^2}\n    {\\sqrt{n(n-1)}}\n    c_{n-2}\n    \\\\&= \n    \\cdots\n    \\\\&=\n    \\frac\n    {\\alpha^n}\n    {\\sqrt{n!}}\n    c_{0}\n\\end{aligned}\n$$\nwe almost complete expanding coherent state with number state.\n$$\n    \\ket{\\alpha}\n    =\n    c_0\n    \\sum_{n=0}^\\infty \n    \\frac\n    {\\alpha^n}\n    {\\sqrt{n!}}\n    \\ket{n}\n$$\nwe still need to decide $c_0$. we can do this from normalization condition.\n$$\n\\begin{aligned}\n    1\n    &=\n    \\braket{\\alpha|\\alpha}\n    \\\\&=\n    \\left| c_0 \\right|^2\n    \\sum_{n, n^\\prime}\n    \\frac\n    {\\left| \\alpha \\right|^{2n}}\n    {n!}\n    \\braket{n|n^\\prime}\n    \\left| c_0 \\right|^2\n    \\\\&=\n    \\sum_{n=0}^\\infty \n    \\frac\n    {\\left| \\alpha \\right|^{2n}}\n    {n!}\n    \\\\&=\n    \\left| c_0 \\right|^2\n    e^\n    {\\left| \\alpha \\right|^{2}}\n\\end{aligned}\n$$\nthus,\n$$\n    \\left| c_0 \\right|^2\n    =\n    e^\n    {- \\left| \\alpha \\right|^{2}}\n$$\n$$\n    c_0\n    =\n    e^\n    {- \\left| \\alpha \\right|^{2}/2}\n$$\nfinally coherent coherent state of number state basis is\n$$\n\\boxed{\n    \\ket{\\alpha}\n    =\n    e^\n    {- \\left| \\alpha \\right|^{2}/2}\n    \\sum_{n=0}^\\infty\n    \\frac\n    {\\alpha^n}\n    {\\sqrt{n!}}\n    \\ket{n}\n}\n$$\n\n#### electric field from coherent state viewpoint\nlet's consider the expectation value of electric field operator.\n$$\n    \\hat{e}_x\n    =\n    i \\mathcal{e}_0\n    \\left[\n        \\hat{a} \n        e^{i \n        \\left( \\vec{k}\\cdot\\vec{r} - \\omega t\\right)\n        }\n        -\n        \\text{hermitian conjugate}\n    \\right]\n$$\ncoherent state average of electric field is \n$$\n    \\braket{\\alpha | \\hat{e}_x | \\alpha}\n    =\n    i \\mathcal{e}_0 \\alpha \n    e^{i \n    \\left( \\vec{k}\\cdot\\vec{r} - \\omega t\\right)\n    }\n    +\n    \\text{complex conjugate}\n$$\ncoherent state average of square of electric field is \n$$\n\\begin{aligned}\n    \\braket{\\alpha | \\hat{e}_x^2 | \\alpha}\n    &=\n    - \\mathcal{e}_0^2\n    \\braket{\\alpha | \n    \\left(\n        \\hat{a} \n        e^{i \n        \\left( \\vec{k}\\cdot\\vec{r} - \\omega t \\right)\n        }\n        -\n        \\hat{a}^\\dag\n        e^{-i \n        \\left( \\vec{k}\\cdot\\vec{r} - \\omega t\\right)\n        }\n    \\right)^2\n    | \\alpha}\n    \\\\&=\n    - \\mathcal{e}_0^2\n    \\braket{\\alpha | \n    \\left(\n        \\hat{a}^2\n        e^{2i \n        \\left( \\vec{k}\\cdot\\vec{r} - \\omega t\\right)\n        }\n        +\n        {\\hat{a}^\\dag }^2\n        e^{-2i \n        \\left( \\vec{k}\\cdot\\vec{r} - \\omega t\\right)\n        }\n        -\\hat{a}\\hat{a}^\\dag - \\hat{a}^\\dag\\hat{a}\n    \\right)\n    | \\alpha}\n    \\\\&=\n    - \\mathcal{e}_0^2\n    \\braket{\\alpha | \n    \\left(\n        \\hat{a}^2\n        e^{2i \n        \\left( \\vec{k}\\cdot\\vec{r} - \\omega t\\right)\n        }\n        +\n        {\\hat{a}^\\dag }^2\n        e^{-2i \n        \\left( \\vec{k}\\cdot\\vec{r} - \\omega t\\right)\n        }\n        - (1 + \\hat{a}^\\dag\\hat{a})\n        - \\hat{a}^\\dag\\hat{a}\n    \\right)\n    | \\alpha}\n\\end{aligned}\n$$\ndetail of calculation is left for readers ;). \nby writing $\\alpha = |\\alpha|e^{i\\theta}$, we can have sine wave which is **very classical**.\n\nfrom these, the variance become \n$$\n    \\left<\n        \\left( \\delta e_x \\right)^2\n    \\right>_\\alpha\n    =\n    \\mathcal{e}_0\n    =\n    \\frac{\\hbar \\omega}{2 \\epsilon_0 v}\n$$\nwhich **does not depend on $\\alpha$!** \nand notice this is **identical to those for a vacuum state!!** (see section 2.2)\n\n#### quadrature operators from coherent state viewpoint\nwe can show that fluctuation of quadrature operator also does not \ndepend on $\\alpha$.\n$$\n    \\hat{x}_1\n    =\n    \\frac{\\hat{a} + \\hat{a}^\\dag}{2}\n$$\n$$\n    \\hat{x}_2\n    =\n    \\frac{\\hat{a} - \\hat{a}^\\dag}{2i}\n$$\n$$\n\\begin{aligned}\n    \\left<\n        \\left(\n            \\delta \\hat{x}_1\n        \\right)^2\n    \\right>_\\alpha\n    &=\n    \\braket{\\alpha|\n            \\hat{x}_1^2\n    |\\alpha}\n    -\n    \\braket{\\alpha|\n            \\hat{x}_1\n            |\\alpha}^2\n    \\\\&=\n    \\braket{\\alpha|\n    \\left(\n        \\frac{\\hat{a} + \\hat{a}^\\dag}{2}\n    \\right)^2\n    |\\alpha}\n    -\n    \\braket{\\alpha|\n        \\frac{\\hat{a} + \\hat{a}^\\dag}{2}\n    |\\alpha}^2\n    \\\\&=\n    \\frac{1}{4}\n    \\braket{\\alpha|\n    \\left(\n        \\hat{a}^2 \n        + {\\hat{a}^\\dag}^2\n      "
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "displaced-squeezed-states",
      "lessonTitle": "Displaced Squeezed States",
      "x": 0.9389733672142029,
      "y": 1.0,
      "searchText": "displaced squeezed states\n# displaced squeezed states\n\n## displaced squeezed vacuum\n\na **displaced squeezed state** is obtained by first squeezing the vacuum and then displacing it in phase space:\n\n$$\n|\\alpha, \\xi\\rangle = \\hat{d}(\\alpha) \\hat{s}(\\xi) |0\\rangle,\n$$\n\nwhere $\\hat{d}(\\alpha) = \\exp(\\alpha \\hat{a}^\\dagger - \\alpha^* \\hat{a})$ is the displacement operator and $\\hat{s}(\\xi) = \\exp[\\frac{1}{2}(\\xi^* \\hat{a}^2 - \\xi \\hat{a}^{\\dagger 2})]$ is the squeezing operator with $\\xi = re^{i\\theta}$.\n\nthe ordering matters: $\\hat{d}(\\alpha)\\hat{s}(\\xi) \\neq \\hat{s}(\\xi)\\hat{d}(\\alpha)$ in general. the state $|\\alpha, \\xi\\rangle$ is a **minimum uncertainty state** centered at $\\alpha$ in phase space with an elliptical noise distribution whose orientation and eccentricity are determined by $\\xi$.\n\nthe mean values and variances are\n\n$$\n\\langle \\hat{x}_\\phi \\rangle = |\\alpha|\\cos(\\phi - \\phi_\\alpha), \\qquad (\\delta x_\\phi)^2 = \\frac{1}{4}(e^{-2r}\\cos^2\\psi + e^{2r}\\sin^2\\psi),\n$$\n\nwhere $\\psi = \\phi - \\theta/2$ and $\\phi_\\alpha = \\arg(\\alpha)$.\n\n## amplitude and phase squeezed light\n\nthe relative orientation of the squeezing ellipse and the coherent amplitude determines the type of squeezing:\n\n**amplitude squeezed light** has reduced intensity fluctuations. the squeezing axis is aligned with the coherent amplitude, so the radial (amplitude) quadrature has sub-vacuum noise:\n\n$$\n(\\delta n)^2 < \\langle n \\rangle \\quad \\text{(sub-poissonian)}.\n$$\n\nthis is useful for precision intensity measurements and direct detection experiments.\n\n**phase squeezed light** has reduced phase fluctuations. the squeezing axis is perpendicular to the coherent amplitude, compressing the tangential (phase) quadrature:\n\n$$\n\\delta\\phi < \\frac{1}{2\\sqrt{\\langle n \\rangle}} \\quad \\text{(below shot noise)}.\n$$\n\nthis is advantageous for interferometric measurements where phase sensitivity is the limiting factor.\n\nthe wigner function of a displaced squeezed state is a gaussian centered at $\\alpha$ with principal axes tilted by $\\theta/2$:\n\n$$\nw(x, p) = \\frac{1}{\\pi} \\exp\\left[-e^{2r}(x' - x_0')^2 - e^{-2r}(p' - p_0')^2\\right],\n$$\n\nwhere $(x', p')$ are coordinates rotated by the squeezing angle.\n\n[[simulation wigner-squeezed]]\n\n## two-mode squeezing\n\n**two-mode squeezing** correlates two distinct field modes and is the key resource for continuous-variable entanglement. the two-mode squeezing operator is\n\n$$\n\\hat{s}_2(\\xi) = \\exp(\\xi^* \\hat{a}\\hat{b} - \\xi \\hat{a}^\\dagger \\hat{b}^\\dagger),\n$$\n\nwhich creates photon pairs: one in mode $a$ and one in mode $b$. the two-mode squeezed vacuum (tmsv) state is\n\n$$\n|\\text{tmsv}\\rangle = \\frac{1}{\\cosh r} \\sum_{n=0}^{\\infty} (-e^{i\\theta}\\tanh r)^n |n\\rangle_a |n\\rangle_b.\n$$\n\nthe modes are perfectly correlated in photon number ($n_a = n_b$ in every term) but individually each mode is a thermal state with $\\langle n \\rangle = \\sinh^2 r$.\n\n## continuous-variable entanglement\n\nthe tmsv state exhibits **epr-type correlations** in the continuous variables. the sum and difference quadratures are\n\n$$\n\\delta(x_a - x_b)^2 = \\frac{1}{2}e^{-2r}, \\qquad \\delta(p_a + p_b)^2 = \\frac{1}{2}e^{-2r}.\n$$\n\nboth vanish in the limit $r \\to \\infty$, corresponding to the original epr state with perfect correlations. the entanglement is verified by the **duan criterion**: the state is entangled if\n\n$$\n\\delta(x_a - x_b)^2 + \\delta(p_a + p_b)^2 < 1.\n$$\n\nfor a tmsv state, this sum equals $e^{-2r} < 1$ for any $r > 0$, confirming entanglement.\n\n## applications\n\ndisplaced squeezed states and two-mode squeezing are central to:\n\n- **quantum teleportation**: the tmsv provides the shared entangled resource for continuous-variable teleportation of coherent states.\n- **quantum dense coding**: entangled beams allow transmission of classical information at rates exceeding the classical channel capacity.\n- **quantum illumination**: entangled signal-idler pairs improve target detection in noisy environments.\n- **cluster state generation**: large entangled states for measurement-based quantum computation can be deterministically produced using squeezed light and linear optics.\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "higher-order-coherence",
      "lessonTitle": "Higher-Order Coherence",
      "x": 0.7500756978988647,
      "y": 0.9592083692550659,
      "searchText": "higher-order coherence\n# higher-order coherence\n\n## second-order correlation function\n\nthe **second-order correlation function** measures intensity-intensity correlations and reveals the photon statistics of a light source. it is defined as\n\n$$\ng^{(2)}(\\tau) = \\frac{\\langle \\hat{a}^\\dagger \\hat{a}^\\dagger \\hat{a} \\hat{a} \\rangle}{\\langle \\hat{a}^\\dagger \\hat{a} \\rangle^2} = \\frac{\\langle : \\hat{n}(\\hat{n}-1) : \\rangle}{\\langle \\hat{n} \\rangle^2},\n$$\n\nwhere the colons denote normal ordering. at zero delay, $g^{(2)}(0)$ characterizes the photon number fluctuations:\n\n- **coherent light** (poissonian statistics): $g^{(2)}(0) = 1$.\n- **thermal light** (super-poissonian): $g^{(2)}(0) = 2$.\n- **number state** $|n\\rangle$ (sub-poissonian): $g^{(2)}(0) = 1 - 1/n < 1$.\n- **single photon** $|1\\rangle$: $g^{(2)}(0) = 0$.\n\nthe condition $g^{(2)}(0) < 1$ is a signature of **non-classical light** with no classical analogue. classically, the cauchy-schwarz inequality requires $g^{(2)}(0) \\geq 1$.\n\n## the hanbury brown-twiss experiment\n\nin 1956, hanbury brown and twiss measured intensity correlations of starlight using two detectors. they observed **photon bunching**: photons from a thermal source tend to arrive in pairs, giving $g^{(2)}(0) > g^{(2)}(\\tau)$ for $\\tau > 0$.\n\nthe experimental setup splits the light beam with a beam splitter and sends it to two detectors. a correlator measures the coincidence rate as a function of the time delay $\\tau$ between detections. for thermal light:\n\n$$\ng^{(2)}(\\tau) = 1 + |g^{(1)}(\\tau)|^2.\n$$\n\nat $\\tau = 0$, this gives $g^{(2)}(0) = 2$, meaning photons are twice as likely to arrive together as independently. as $\\tau$ increases beyond the coherence time, $g^{(2)}(\\tau) \\to 1$.\n\nthe hbt result was initially controversial because it seemed to imply that photons \"attract\" each other. the resolution is that bunching arises from the bosonic nature of photons and the statistical properties of thermal states, not from photon-photon interactions.\n\n## photon bunching and antibunching\n\n**photon bunching** ($g^{(2)}(0) > 1$) occurs for thermal and chaotic light sources. it is a classical phenomenon explainable by wave interference of many random emitters.\n\n**photon antibunching** ($g^{(2)}(0) < 1$) has no classical explanation and requires a quantum description. it means photons tend to arrive one at a time, with a suppressed probability of simultaneous detection. antibunching was first observed by kimble, dagenais, and mandel (1977) in the fluorescence of a single atom.\n\nthe key distinction is:\n- bunching: $g^{(2)}(\\tau) < g^{(2)}(0)$ (correlations decrease with delay).\n- antibunching: $g^{(2)}(\\tau) > g^{(2)}(0)$ (correlations increase from a minimum at $\\tau = 0$).\n\n## sub-poissonian statistics\n\nclosely related to antibunching is the concept of **sub-poissonian** photon statistics, where the variance of the photon number is below the poissonian value:\n\n$$\n\\langle (\\delta n)^2 \\rangle < \\langle n \\rangle.\n$$\n\nthe **mandel q parameter** quantifies the deviation:\n\n$$\nq = \\frac{\\langle (\\delta n)^2 \\rangle - \\langle n \\rangle}{\\langle n \\rangle} = \\langle n \\rangle (g^{(2)}(0) - 1).\n$$\n\n$q = 0$ for coherent light, $q > 0$ for super-poissonian (classical) light, and $q < 0$ for sub-poissonian (non-classical) light. number states have $q = -1$, the minimum possible.\n\n## higher-order correlations\n\nthe hierarchy extends to arbitrary order. the $n$-th order correlation function is\n\n$$\ng^{(n)}(\\tau_1, \\ldots, \\tau_{n-1}) = \\frac{\\langle (\\hat{a}^\\dagger)^n \\hat{a}^n \\rangle}{\\langle \\hat{a}^\\dagger \\hat{a} \\rangle^n}.\n$$\n\nfor thermal light, $g^{(n)}(0) = n!$, while for coherent light, $g^{(n)}(0) = 1$ for all $n$. these higher-order functions provide increasingly stringent tests of non-classicality and are relevant for multi-photon experiments and quantum information protocols.\n\n[[simulation wigner-number-state]]\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "home",
      "lessonTitle": "Quantum Optics",
      "x": 0.8320335149765015,
      "y": 0.9169026613235474,
      "searchText": "quantum optics\n# quantum optics\n\n## course overview\n\nquantum optics studies the **quantum mechanical aspects of the interaction between light and matter**. unlike classical optics, where electromagnetic fields are treated as continuous waves, quantum optics reveals the discrete photon nature of light and the fundamentally quantum phenomena that arise from field quantization.\n\n- classical optics: continuous electromagnetic waves, intensity, interference.\n- quantum optics: photon concept, field quantization, vacuum fluctuations, non-classical correlations.\n\ncore conceptual framework:\n\n1. quantize the electromagnetic field to obtain photon number (fock) states.\n2. construct coherent states that bridge quantum and classical descriptions.\n3. measure field correlations through photo-detection to reveal quantum coherence.\n4. analyze input/output devices (beam splitters, interferometers) quantum mechanically.\n5. study atom-field interactions, spontaneous emission, and cavity qed.\n6. explore non-classical states: squeezed light, entangled photons, cat states.\n\n## why this topic matters\n\n- quantum communication and quantum key distribution.\n- precision metrology and gravitational wave detection (squeezed light at ligo).\n- quantum computing with photonic platforms and cavity qed.\n- fundamental tests of quantum mechanics (bell inequalities, entanglement).\n- single-photon sources and detectors for quantum networks.\n- laser physics and coherence theory.\n\n## key mathematical ideas\n\n- harmonic oscillator algebra: creation and annihilation operators.\n- coherent states as displaced vacuum and minimum-uncertainty states.\n- quasi-probability distributions: wigner, p, and q functions in phase space.\n- field correlation functions and quantum coherence hierarchy.\n- jaynes-cummings model and dressed states for atom-field coupling.\n- squeezing operators and uncertainty engineering.\n\n## prerequisites\n\n- quantum mechanics (dirac notation, operators, commutators).\n- electrodynamics (maxwell's equations, electromagnetic waves).\n- linear algebra (eigenvalues, hilbert spaces).\n- basic probability and statistics.\n\n## recommended reading\n\n- gerry and knight, *introductory quantum optics*, cambridge university press.\n- walls and milburn, *quantum optics*, springer.\n- scully and zubairy, *quantum optics*, cambridge university press.\n\n## learning trajectory\n\nthis module is organized from field quantization through non-classical light:\n\n- quantization of single-mode and multimode electromagnetic fields.\n- coherent states and their phase-space representation.\n- quasi-probability distributions (p, q, wigner functions).\n- coherence functions and photo-detection theory.\n- beam splitters, interferometry, and input/output relations.\n- squeezed states and displaced squeezed states.\n- atom-field interaction, rabi oscillations, and the jaynes-cummings model.\n- cavity qed and single-photon experiments.\n- quantum measurements and non-classical light.\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "interferometry",
      "lessonTitle": "Interferometry",
      "x": 0.8552972078323364,
      "y": 0.9753077030181885,
      "searchText": "interferometry\n# interferometry\n\n## input-output relations\n\noptical networks of beam splitters and phase shifters are described by **input-output relations** that map input mode operators to output mode operators. for a network with $m$ modes, the transformation is\n\n$$\n\\hat{a}_{\\text{out}, i} = \\sum_{j=1}^{m} u_{ij} \\hat{a}_{\\text{in}, j},\n$$\n\nwhere $u$ is a unitary matrix. any unitary transformation on $m$ modes can be decomposed into a sequence of beam splitters and phase shifters (reck decomposition). this universality makes linear optics a powerful platform for quantum information processing.\n\n## homodyne detection\n\n**homodyne detection** measures a single quadrature of the electromagnetic field by interfering the signal with a strong local oscillator (lo) at the same frequency. the signal mode $\\hat{a}$ and the lo mode $\\hat{b} \\approx |\\beta|e^{i\\theta}$ are combined on a 50:50 beam splitter, and the photocurrents from two detectors are subtracted:\n\n$$\n\\hat{i}_- \\propto \\hat{a} e^{-i\\theta} + \\hat{a}^\\dagger e^{i\\theta} = \\hat{x}_\\theta,\n$$\n\nwhere $\\hat{x}_\\theta$ is the quadrature operator at phase angle $\\theta$. by varying the lo phase $\\theta$, any quadrature can be measured. this enables full reconstruction of the quantum state via **quantum state tomography**.\n\nfor a coherent state $|\\alpha\\rangle$, homodyne detection yields gaussian noise centered at $2|\\alpha|\\cos(\\theta - \\phi_\\alpha)$ with vacuum-level variance. for squeezed states, the variance is below vacuum for one quadrature.\n\n## heterodyne detection\n\n**heterodyne detection** simultaneously measures both quadratures ($\\hat{x}$ and $\\hat{p}$) by using a local oscillator detuned from the signal frequency. this is equivalent to a joint measurement of non-commuting observables and necessarily adds half a quantum of noise to each quadrature (from the heisenberg uncertainty principle):\n\n$$\n\\delta x \\cdot \\delta p \\geq \\frac{1}{2}.\n$$\n\nheterodyne detection projects onto coherent states and is equivalent to measuring the husimi q-function of the field.\n\n## mach-zehnder interferometer\n\nthe **mach-zehnder interferometer** (mzi) is the workhorse of optical interferometry. two beam splitters enclose two paths with a relative phase shift $\\phi$. the full unitary transformation for a balanced mzi is\n\n$$\nu_{\\text{mzi}} = u_{\\text{bs}} \\cdot u_\\phi \\cdot u_{\\text{bs}} = \\begin{pmatrix} \\cos(\\phi/2) & i\\sin(\\phi/2) \\\\ i\\sin(\\phi/2) & \\cos(\\phi/2) \\end{pmatrix},\n$$\n\nup to global phases. the output intensities oscillate sinusoidally with $\\phi$, allowing precise phase measurements.\n\n## quantum-enhanced interferometry\n\nclassical interferometry with coherent light achieves a phase sensitivity at the **shot-noise limit**:\n\n$$\n\\delta\\phi_{\\text{snl}} = \\frac{1}{\\sqrt{\\bar{n}}},\n$$\n\nwhere $\\bar{n}$ is the mean photon number. this limit arises from the poissonian photon statistics of coherent states.\n\nquantum states can beat this limit. the ultimate bound set by quantum mechanics is the **heisenberg limit**:\n\n$$\n\\delta\\phi_{\\text{hl}} = \\frac{1}{\\bar{n}}.\n$$\n\nstrategies to approach the heisenberg limit include:\n- **squeezed vacuum** injected into the unused port of the mzi reduces the noise in the measured quadrature. this was implemented in ligo to improve gravitational wave sensitivity.\n- **noon states** $|n,0\\rangle + |0,n\\rangle$ achieve heisenberg-limited sensitivity but are fragile and difficult to prepare for large $n$.\n- **twin-fock states** $|n,n\\rangle$ provide robustness against losses compared to noon states.\n\n## sagnac interferometer\n\nthe **sagnac interferometer** uses a common path traversed in opposite directions. rotation of the interferometer introduces a phase shift proportional to the enclosed area and angular velocity (sagnac effect):\n\n$$\n\\delta\\phi = \\frac{8\\pi a \\omega}{c\\lambda},\n$$\n\nwhere $a$ is the enclosed area and $\\omega$ is the rotation rate. fiber-optic gyroscopes and ring laser gyroscopes exploit this principle for navigation and geophysics.\n\n[[simulation wigner-squeezed]]\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "jaynes-cummings",
      "lessonTitle": "Jaynes-Cummings Model",
      "x": 0.8838842511177063,
      "y": 0.8704519867897034,
      "searchText": "jaynes-cummings model\n# jaynes-cummings model\n\n## the model\n\nthe **jaynes-cummings model** describes the simplest quantum interaction between a single two-level atom and a single mode of the electromagnetic field. the hamiltonian is\n\n$$\n\\hat{h} = \\hbar\\omega_c \\hat{a}^\\dagger \\hat{a} + \\frac{\\hbar\\omega_a}{2}\\hat{\\sigma}_z + \\hbar g(\\hat{a}^\\dagger \\hat{\\sigma}_- + \\hat{a}\\hat{\\sigma}_+),\n$$\n\nwhere $\\omega_c$ is the cavity frequency, $\\omega_a$ is the atomic transition frequency, $g$ is the coupling strength, and $\\hat{\\sigma}_\\pm$ are the atomic raising/lowering operators.\n\nthe interaction term $\\hat{a}^\\dagger \\hat{\\sigma}_-$ describes the atom emitting a photon (going from excited to ground) while creating a cavity photon, and $\\hat{a}\\hat{\\sigma}_+$ describes absorption. this is the **rotating wave approximation** (rwa), valid when $g \\ll \\omega_c, \\omega_a$.\n\n## energy levels and dressed states\n\nthe total excitation number $\\hat{n} = \\hat{a}^\\dagger\\hat{a} + \\hat{\\sigma}_+\\hat{\\sigma}_-$ is conserved, so the hilbert space splits into independent two-dimensional subspaces spanned by $\\{|n, e\\rangle, |n+1, g\\rangle\\}$ for each $n$.\n\nwithin each subspace, diagonalizing gives the **dressed states**:\n\n$$\n|+, n\\rangle = \\cos\\theta_n |n, e\\rangle + \\sin\\theta_n |n+1, g\\rangle,\n$$\n$$\n|-, n\\rangle = -\\sin\\theta_n |n, e\\rangle + \\cos\\theta_n |n+1, g\\rangle,\n$$\n\nwhere $\\tan(2\\theta_n) = 2g\\sqrt{n+1}/\\delta$ and $\\delta = \\omega_a - \\omega_c$ is the detuning. the dressed-state energies are\n\n$$\ne_{\\pm, n} = \\hbar\\omega_c(n + \\tfrac{1}{2}) \\pm \\frac{\\hbar}{2}\\sqrt{\\delta^2 + 4g^2(n+1)}.\n$$\n\nthe splitting $\\hbar\\omega_n = \\hbar\\sqrt{\\delta^2 + 4g^2(n+1)}$ between the dressed states is the **vacuum rabi splitting** when $n = 0$.\n\n## rabi oscillations\n\nif the atom starts in the excited state with $n$ photons, $|\\psi(0)\\rangle = |n, e\\rangle$, the state evolves as\n\n$$\n|\\psi(t)\\rangle = \\cos(\\omega_n t/2)|n, e\\rangle - i\\sin(\\omega_n t/2)|n+1, g\\rangle,\n$$\n\nat resonance ($\\delta = 0$), where $\\omega_n = 2g\\sqrt{n+1}$ is the **$n$-photon rabi frequency**. the atomic inversion oscillates:\n\n$$\n\\langle \\hat{\\sigma}_z(t) \\rangle = \\cos(\\omega_n t).\n$$\n\nthe $\\sqrt{n+1}$ dependence is a purely quantum effect. for a coherent state input $|\\alpha\\rangle$ with $\\bar{n} = |\\alpha|^2$ photons, different fock components oscillate at different frequencies $\\omega_n$, leading to **collapse and revival** of the rabi oscillations. the initial oscillations collapse on a timescale $t_c \\sim 1/(g\\sqrt{\\bar{n}})$ due to dephasing, then revive at $t_r \\sim 2\\pi\\sqrt{\\bar{n}}/g$ when the phases realign.\n\n## dispersive regime\n\nwhen the detuning is large ($|\\delta| \\gg g\\sqrt{n+1}$), the atom and field exchange only virtual excitations. perturbation theory gives an effective hamiltonian\n\n$$\n\\hat{h}_{\\text{disp}} \\approx \\hbar(\\omega_c + \\chi\\hat{\\sigma}_z)\\hat{a}^\\dagger\\hat{a} + \\frac{\\hbar(\\omega_a + \\chi)}{2}\\hat{\\sigma}_z,\n$$\n\nwhere $\\chi = g^2/\\delta$ is the **dispersive shift**. the cavity frequency shifts by $\\pm\\chi$ depending on the atomic state, and the atomic frequency shifts by $\\chi$ per photon (**ac stark shift** or **light shift**).\n\nthis regime enables **quantum non-demolition** (qnd) measurement of photon number: measuring the atomic phase shift reveals $n$ without absorbing photons. it is the foundation of circuit qed readout in superconducting qubits.\n\n## spontaneous emission\n\nin free space, a two-level atom coupled to a continuum of modes decays irreversibly at the **wightman-weisskopf** rate\n\n$$\n\\gamma = \\frac{\\omega_a^3 d^2}{3\\pi\\epsilon_0\\hbar c^3},\n$$\n\nwhere $d$ is the transition dipole moment. the excited-state population decays exponentially: $p_e(t) = e^{-\\gamma t}$.\n\nin a cavity, spontaneous emission is modified by the density of states. when the cavity is resonant, the enhanced rate is $\\gamma_{\\text{cav}} = 4g^2/\\kappa$ (where $\\kappa$ is the cavity decay rate), leading to the **purcell effect** discussed in the cavity qed topic.\n\n[[simulation wigner-cat-state]]\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "multimode-fields",
      "lessonTitle": "Multimode Fields",
      "x": 0.7822786569595337,
      "y": 0.8198568224906921,
      "searchText": "multimode fields\n# multimode fields\n__topic 2 keywords__\n- multi-mode fields\n- thermal states-density of states\n- planck formula\n- density operators\n- lamb shift\n- casimir forces\n\n[[simulation wigner-coherent]]\n\n# readings\nch. 2.4-6, app. a.\n\n# 2.4 multimode fields\nin the textbook, they use the vector potential. \nwe can do same things in different way.\nconsider the hamiltonian of multi-mode wave.\n$$\n\\begin{aligned}\n    \\hat{h}\n    &=\n    \\sum_{\\vec{k}, s}\n    \\hbar \\omega_k\n    \\left(\n        \\hat{a}^\\dag_{\\vec{k},s}\n        \\hat{a}_{\\vec{k},s}\n        +\n        \\frac{1}{2}\n    \\right)\n    \\\\&=\n    \\sum_j\n    \\hbar \\omega_j\n    \\left(\n        \\hat{n}_j\n        +\n        \\frac{1}{2}\n    \\right)\n\\end{aligned}\n$$\nhere, paramters are follows.\n- $\\omega_k=kc$ is frequency\n- $\\vec{k}$ is the wave vetor\n- $s$ is the polarization index\n\nby using index $j$ we can simply write the eigenstate of this hamiltonian.\nthe eigenstate would be product of number states.\n$$\n    \\ket{\\left\\{n_j\\right\\}}\n    =\n    \\ket{n_1, n_2, \\cdots, n_j, \\cdots}\n$$\nthis state means how many photon in each mode.\n\nwe can also think the annihilation operator of multi-mode state.\n$$\n    \\hat{a}_i\n    \\ket{\\left\\{n_j\\right\\}}\n    =\n    \\sqrt{n_i}\n    \\ket{n_1, n_2, \\cdots, n_i-1, \\cdots}\n$$\n\n# 2.5 thermal fields\n#### thermal light\nso far we consider the zero-temperature box.\nwe can think interaction between photon and thermal wall.\nin thermal equilibrium, the density matrix is\n$$\n    \\hat{\\rho}_\\mathrm{th}\n    =\n    \\frac\n    {e^{ -\\hat{h} / k_\\mathrm{b}t}}\n    {\\operatorname{tr}~e^{- \\hat{h} / k_\\mathrm{b}t}}\n$$\nremember that operator on napier number is symbolic representation of maclaurin \nseries.\n$$\n    e^{ -\\hat{h} / k_\\mathrm{b}t}\n    =\n    1 \n    - \n    \\frac{\\hat{h}}{k_\\mathrm{b}t}\n    +\n    \\frac{1}{2}\n    \\left(\n        \\frac{\\hat{h}}{k_\\mathrm{b}t}\n    \\right)^2\n    \\cdots\n$$\nprobability of occupying $\\ket{n}$ is\n$$\n    p_n \n    =\n    \\braket{\n        n|\n        \\hat{\\rho}_\\mathrm{th}\n        |n\n    }\n$$\nexpectation number of photon is \n$$\n    \\boxed{\n    \\left< n \\right>\n    =\n    \\sum_n\n    n p_n\n    =\n    \\frac\n    {1}\n    {e^{\\hbar \\omega / k_\\mathrm{b}t}  - 1 }\n    }\n$$\nlet's check the order of this number.\nenergy of visible light is \n$$\n    \\hbar \\omega\n    \\sim\n    1\n    \\mathrm{ev}\n$$\nenergy of room temperature is\n$$\n    k_\\mathrm{b}t\n    \\sim\n    \\frac{1}{40}\n    \\mathrm{ev}\n$$\nby putting these number into equation, we see\n$$\n    \\left< \\hat{n} \\right>\n    \\sim\n    0\n$$\nso photon does not care temperature. this is different from quantum computer.\n**temperature does not play a role in quantum optics.**\n\nthermal fluctuation is\n$$\n\\begin{aligned}\n    \\left< \\left( \\delta n \\right)^2 \\right>\n    &=\n    \\left< \\hat{n}^2 \\right>\n    -\n    \\left< \\hat{n} \\right>^2\n    \\\\&=\n    \\bar{n}\n    +\n    \\bar{n}^2\n\\end{aligned}\n$$\nthis is super-poisonian distribution. variance is larger than that of poisonian.\n#### planck's radiation law\nconsider the light in the box with each length $l$ in thermal equilibrium.\nfrom boundary condition,\n$$\n    e^{i k_i x_i}\n    =\n    e^{i k_i (x_i+l)}\n$$\n$$\n    k_i \n    =\n    \\frac{2\\pi}{l} \n    m_i\n$$\nthe number of state is \n$$\n\\begin{aligned}\n    \\delta m\n    &=\n    \\delta m_x\n    \\delta m_y\n    \\delta m_z\n    \\\\&=\n    2\n    \\frac{v}{2\\pi}\n    \\delta k_x\n    \\delta k_y\n    \\delta k_z\n\\end{aligned}\n$$\nhere multiplication of 2 is number of polarization.\n\nwe can think this in spherical coordinate.\n$$\n\\begin{aligned}\n    \\mathrm{d}m\n    &=\n    \\frac{v}{4\\pi^3}\n    \\mathrm{d}^3 k\n    \\\\&=\n    \\frac{v}{4\\pi^3}\n    k^2\n    \\mathrm{d} k\n    \\mathrm{d} \\omega\n    \\\\&=\n    \\frac{v}{4\\pi^3}\n    \\frac{\\omega^2}{c^3}\n    \\mathrm{d} \\omega\n    \\mathrm{d} \\omega\n\\end{aligned}\n$$\ndensity of state is \n$$\n    \\rho(\\omega)\n    =\n    \\frac{\\omega^2}{\\pi^2 c^3}\n$$\ndimension of density of state is \n$\\frac{\\text{\\# of state}}{\\text{frequency} \\cdot \\text{volume}}$\n\nenergy density become\n$$\n\\begin{aligned}\n    \\bar{u}\n    &=\n    \\hbar \\omega \\bar{n} \\rho (\\omega)\n    \\\\&=\n    \\frac\n    {\\hbar\\omega}\n    {e^{\\hbar\\omega/k_\\mathrm{b}t} - 1}\n    \\frac\n    {\\omega^2}\n    {\\pi^2 c^3}\n\\end{aligned}\n$$\n\n# 2.6 vacuum fluctuations and the zero-point energy\nvacuum energy and fluctuations actually give rise to observable effects such as:\n- spontaneous emission\n- lamb shift \n- casimir effect\n#### lamb shift\nthe lamb shift is a discrepancy between experiment and the dirac relativistic\ntheory of the hydrogen atom.\n- the theory predicts that the $2^2s_{1/2}$ and $2^2p_{1/2}$ levels should be degenerate.\n- optical experiment suggest that these states were not degenerate.\n\nthis discrepancy explained by bethe. here we use the welton's intuitive \ninterpretation.\n\nfirst the potential energy of electron of hydrogen atom is\n$$\n    v(r)\n    =\n    -\n    \\frac{e^2}{r}\n    +\n    v_\\mathrm{vac}\n$$\nwe added the small term $v_\\mathrm{vac}$ to include vacuum energy.\nsmall displacement of potential energy is \n$$\n    \\delta v \n    =\n    \\delta \\vec{r}\n    \\cdot\n    \\vec{\\nabla} v\n    +\n    \\sum_{i=1}^3\n    \\frac{1}{2}\n    \\left(\n        \\delta x_i\n    \\right)^2\n    \\frac\n    {\\partial^2 v}\n    {\\partial x_i^2}\n$$\nwe assume that fluctuation is uniform in all direction in sufficiently long time. \nso we set \n$$ \n    \\left< \\delta \\vec{r} \\right> = 0 \n$$\nalso, we assume that the displacement is same in all direction. \n$$\n    \\left< \n        \\left( \n            \\delta x_i \n        \\right)^2 \n    \\right> \n    = \n    \\frac{1}{3} \n    \\left< \n        \\left( \n            \\delta r\n        \\right)^2 \n    \\right>\n$$\nso the time-average potential energy displacement is \n$$\n\\begin{aligned}\n    \\left<\n        \\delta v\n    \\right>\n    &=\n    \\sum_{i=1}^3\n    \\frac{1}{2}\n    \\left<\n        \\left(\n            \\delta x_i\n        \\right)^2\n    \\right>\n    \\frac\n    {\\partial^2 v}\n    {\\partial x_i^2}\n    \\\\&=\n    \\sum_{i=1}^3\n    \\frac{1}{2}\n    \\frac{1}{3}\n    \\left<\n        \\left( \n            \\delta r\n        \\right)^2 \n    \\right>\n    \\frac\n    {\\partial^2 v}\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "papers",
      "lessonTitle": "Recommended Papers",
      "x": 0.958398163318634,
      "y": 0.8970470428466797,
      "searchText": "recommended papers\n# recommended papers\n\n## key experimental papers\n\n- **deleglise et al. (2008)** [nature](https://doi.org/10.1038/nature07288) - reconstruction of non-classical cavity field states with snapshots of their decoherence. demonstrates wigner function tomography of fock states and cat states in a microwave cavity, observing decoherence in real time.\n\n- **kirchmair et al. (2013)** [nature](https://doi.org/10.1038/nature11902) - observation of quantum state collapse and revival due to the single-photon kerr effect. shows the dispersive regime of circuit qed producing cat-state dynamics.\n\n- **vlastakis et al. (2013)** [science](https://doi.org/10.1126/science.1243289) - deterministically encoding quantum information using large cat states in a superconducting cavity. demonstrates cat-code quantum error correction.\n\n- **weinbub et al. (2018)** [applied physics reviews](https://doi.org/10.1063/1.5046663) - comprehensive review of computational approaches to wigner function methods in quantum mechanics and quantum transport.\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "phase-space-pictures",
      "lessonTitle": "Phase-Space Pictures",
      "x": 0.7330970764160156,
      "y": 0.8590565323829651,
      "searchText": "phase-space pictures\n# phase-space pictures\n__topic 4 keywords__\n- quasi-probability distributions\n- characteristic functions\n- phase-space picture\n\n# readings\nch. 3.6-8\n\n# 3.6 phase-space pictures of coherent states\n#### coherent state on a complex plane\nrecall quadrature operators are \n$$\n    \\hat{x_1}\n    =\n    \\frac{1}{2}\n    \\left(\n        \\hat{a} + \\hat{a}^\\dag\n    \\right)\n$$\n$$\n    \\hat{x_2}\n    =\n    \\frac{1}{2i}\n    \\left(\n        \\hat{a} - \\hat{a}^\\dag\n    \\right)\n$$\nas we learned in topic 3.1, coherent state averages of quadrature operators are\n$$\n\\begin{aligned}\n    \\braket{\\alpha|\n    \\hat{x_1}\n    |\\alpha}\n    &=\n    \\frac{1}{2}\n    \\braket{\\alpha|\n    \\left(\n        \\hat{a} + \\hat{a}^\\dag\n    \\right)\n    |\\alpha}\n    \\\\&=\n    \\frac{1}{2}\n    \\left(\n        \\alpha + \\alpha^*\n    \\right)\n    \\\\&=\n    \\mathrm{re}(\\alpha)\n\\end{aligned}\n$$\n$$\n\\begin{aligned}\n    \\braket{\\alpha|\n    \\hat{x_2}\n    |\\alpha}\n    &=\n    \\frac{1}{2i}\n    \\braket{\\alpha|\n    \\left(\n        \\hat{a} - \\hat{a}^\\dag\n    \\right)\n    |\\alpha}\n    \\\\&=\n    \\frac{1}{2i}\n    \\left(\n        \\alpha - \\alpha^*\n    \\right)\n    \\\\&=\n    \\mathrm{im}(\\alpha)\n\\end{aligned}\n$$\nthus the coherent state $\\ket{\\alpha}$ is centered at a $\\alpha$ on a complex $\\hat{x}_1$-$\\hat{x}_2$ plane.\n\nremember that in topic 3.1, we saw that that variance of quadrature operators are\n$$\n    \\left<\n        \\left(\n            \\delta \\hat{x}_1\n        \\right)^2\n    \\right>_\\alpha\n    =\n    \\left<\n        \\left(\n            \\delta \\hat{x}_2\n        \\right)^2\n    \\right>_\\alpha\n    =\n    \\frac{1}{4}\n$$\nthus the fluctuation of quadrature operators are both $\\frac{1}{2}$. \non a complex $\\hat{x}_1$-$\\hat{x}_2$ plane, coherent state $\\ket{\\alpha}$ is centered at a $\\alpha$ with fluctuation of radius $\\frac{1}{2}$.\n\nas we learned in topic 3.1, the average number of photon is $\\bar{n}=|\\alpha|^2$. \nthus the distance between coherent state and origin of complex plane is \nsquare root of number of photon.\n\nnotice when we consider $\\alpha = \\left|\\alpha\\right| e^{i\\theta}$, \nthe uncertainty of theta $\\delta \\theta$ become \nmaximum $2\\pi$ when $\\left|\\alpha\\right|=0$ and minimum $0$ when \n$\\left|\\alpha\\right| \\rightarrow \\infty$.\n\n#### number state on a complex plane\nhow about number state $\\ket{n}$?\nlet's calculate!\n$$\n\\begin{aligned}\n    \\braket{n|\n    \\hat{x_1}\n    |n}\n    &=\n    \\frac{1}{2}\n    \\braket{n|\n    \\left(\n        \\hat{a} + \\hat{a}^\\dag\n    \\right)\n    |n}\n    \\\\&=\n    \\frac{1}{2}\n    \\left(\n        0 + 0\n    \\right)\n    \\\\&=\n    0\n\\end{aligned}\n$$\n$$\n\\begin{aligned}\n    \\braket{n|\n    \\hat{x_2}\n    |n}\n    &=\n    \\frac{1}{2i}\n    \\braket{n|\n    \\left(\n        \\hat{a} - \\hat{a}^\\dag\n    \\right)\n    |n}\n    \\\\&=\n    \\frac{1}{2i}\n    \\left(\n        0 - 0\n    \\right)\n    \\\\&=\n    0\n\\end{aligned}\n$$\nhmm. number state is centered at origin.\n\nhow about fluctuation?\n$$\n\\begin{aligned}\n    \\left<\n        \\left(\n            \\delta \\hat{x}_1\n        \\right)^2\n    \\right>_n\n    &=\n    \\braket{n|\n            \\hat{x}_1^2\n    |n}\n    -\n    \\braket{n|\n            \\hat{x}_1\n            |n}^2\n    \\\\&=\n    \\braket{n|\n    \\left(\n        \\frac{\\hat{a} + \\hat{a}^\\dag}{2}\n    \\right)^2\n    |n}\n    -\n    0\n    \\\\&=\n    \\frac{1}{4}\n    \\braket{n|\n    \\left(\n        \\hat{a}^2 \n        + {\\hat{a}^\\dag}^2\n        + \\hat{a} \\hat{a}^\\dag\n        + \\hat{a}^\\dag \\hat{a}\n    \\right)\n    |n}\n    \\\\&=\n    \\frac{1}{4}\n    \\braket{n|\n    \\left(\n        \\hat{a}^2 \n        + {\\hat{a}^\\dag}^2\n        + 1\n        + \\hat{a}^\\dag \\hat{a}\n        + \\hat{a}^\\dag \\hat{a}\n    \\right)\n    |n}\n    \\\\&=\n    \\frac{1}{4}\n    \\left(\n        1\n        + \n        2n\n    \\right)\n    \\\\&=\n    \\frac{1}{2}\n    \\left(\n        \\frac{1}{2} + n\n    \\right)\n\\end{aligned}\n$$\n$$\n\\begin{aligned}\n    \\left<\n        \\left(\n            \\delta \\hat{x}_2\n        \\right)^2\n    \\right>_n\n    &=\n    \\braket{n|\n            \\hat{x}_2^2\n    |n}\n    -\n    \\braket{n|\n            \\hat{x}_2\n            |n}^2\n    \\\\&=\n    \\braket{n|\n    \\left(\n        \\frac{\\hat{a} - \\hat{a}^\\dag}{2i}\n    \\right)^2\n    |n}\n    -\n    0\n    \\\\&=\n    -\n    \\frac{1}{4}\n    \\braket{n|\n    \\left(\n        \\hat{a}^2 \n        + {\\hat{a}^\\dag}^2\n        - \\hat{a} \\hat{a}^\\dag\n        - \\hat{a}^\\dag \\hat{a}\n    \\right)\n    |n}\n    \\\\&=\n    -\n    \\frac{1}{4}\n    \\braket{n|\n    \\left(\n        \\hat{a}^2 \n        + {\\hat{a}^\\dag}^2\n        - 1\n        - \\hat{a}^\\dag \\hat{a}\n        - \\hat{a}^\\dag \\hat{a}\n    \\right)\n    |n}\n    \\\\&=\n    -\n    \\frac{1}{4}\n    \\left(\n        - 1\n        - 2n\n    \\right)\n    \\\\&=\n    \\frac{1}{2}\n    \\left(\n        \\frac{1}{2} + n\n    \\right)\n\\end{aligned}\n$$\nwhen there is no photon, the fluctuation is $\\frac{1}{2}$. \ntherefore, the number state $\\ket{n=0}$ is centered at origin \nand its uncertainty is circle with radius $\\frac{1}{2}$. \nthis agree with that of coherent state $\\ket{\\alpha=0}$.\n\nwhen there is photon, the radius of fluctuation \n$\\sqrt{\n    \\frac{1}{2}\n    \\left(\n        \\frac{1}{2} + n\n    \\right)\n}$ \nbecome larger than that of coherent state.\n\n# 3.7 density operators and phase-space probability distributions\n#### $p$ function\nas we learned in topic 3.5, the *completeness* of coherent state is\n$$\n    \\frac{1}{\\pi}\n    \\int \\mathrm{d}^2 \\alpha\n    \\ket{\\alpha}\n    \\bra{\\alpha}\n    =\n    1\n$$\ndensity operator can be represented by\n$$\n\\begin{aligned}\n    \\hat{\\rho}\n    &=\n    \\left(\n        \\frac{1}{\\pi}\n        \\int \\mathrm{d}^2 \\alpha^\\prime\n        \\ket{\\alpha^\\prime}\n        \\bra{\\alpha^\\prime}\n    \\right)\n    \\hat{\\rho}\n    \\left(\n        \\frac{1}{\\pi}\n        \\int \\mathrm{d}^2 \\alpha\n        \\ket{\\alpha}\n        \\bra{\\alpha}\n    \\right)\n    \\\\&=\n    \\int \\mathrm{d}^2 \\alpha\n    \\underbrace{\n        \\frac{1}{\\pi^2}\n        \\int \\mathrm{d}^2 \\alpha^\\prime\n        \\ket{\\alpha^\\prime}\n        \\bra{\\alpha^\\prime}\n        \\hat{\\rho}\n    }\n    \\ket{\\alpha}\n    \\bra{\\alpha}\n\\end{aligned}\n$$\nwe want to replace the under braced part with something useful.\nwe introduce the glauber-sudarshan $p$ function.\n$$\n    \\hat"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "quantization-single-mode",
      "lessonTitle": "Quantization of Single Mode Field",
      "x": 0.8301462531089783,
      "y": 0.834571361541748,
      "searchText": "quantization of single mode field\n# quantization of single mode field\n __topic 1 keywords__\n- maxwell equations\n- single mode fields\n- creation/annihilation operators\n- number state\n- field fluctuations\n\n# readings\nch. 2.1-3\n\n# why do we need to quantize?\n- so far, we learned that electron in high-energy state decays back to ground state with the emission of light.\n- however, according to the schr\u00f6dinger equation $$\\hat{h} \\ket{\\psi_m} = e_m \\ket{\\psi_m}$$, electron is stable in excited state i.e. *electron stays in high energy state*.\n- how do the decay? something goes wrong. why does spontaneous emission happen?\n- the answer is **fluctuations**. \n- the new question is *what kind of fluctuations do they have*?\n\n# can classical electromagnetic describe this fluctuations?\nin classical electromagnetic, energy of electron in electric field $e(t)$ is \n$$ e \\cdot e(t) $$\nthus, when there is no light, there is no fluctuation.\nhowever, it is known that even without light, there is a fluctuation i.e. quantum\nmechanical fluctuation.\nwe need to use quantum mechanics.\n\n# 2.1 quantization of single mode field\n#### motivation\nlet's start our quantization of electromagnetic waves.\nwhat are we gonna quantize? of course, as you know, it is **energy**.\n#### situation\nimagine a three-dimensional box and there are perfectly conducting walls at \n$z=0$ and $z=l$. \nwe consider **single mode field** i.e. we only take care one mode.\nboundary conditions are\n- $\\vec{e}(z=0)=0$\n- $\\vec{e}(z=l)=0$\n#### energy\nelectromagnetic energy is\n$$\n    h \n    = \n    \\frac{1}{2} \n    \\int \\mathrm{d} v\n    \\left[\n        \\epsilon_0 \\left| \\vec{e}(z, t) \\right|^2\n        + \n        \\frac{1}{\\mu_0} \\left| \\vec{b}(z, t) \\right|^2\n    \\right]^2\n$$\n#### electric field\nfrom boundary condition, we can determine the spatial part of electric field.\n$$\n    \\vec{e}(z, t)\n    =\n    a \\cdot q(t) \\cdot \\sin(kz) \\cdot \\vec{e_x}\n$$\nhere, parameters are described as follows.\n- $a$ is a constant and we can decide. \n- $q(t)$ is the time dependent part and we will see why we use $q$ as symbol.\n- $k=\\frac{2\\pi}{\\lambda}=\\frac{\\pi}{l}m$ is a wave vector and $m$ is integer ($m=0, \\pm1, \\pm2, \\cdots$).\n- $\\vec{e_x}$ is an unit vector of $x$-direction (we decide the electric field has component on $x$ direction).\nwe decide $a$ as follows.\n$$\n    a\n    =\n    \\sqrt{\\frac{2\\omega^2}{\\epsilon_0 v}}\n$$\nhere, $\\omega=kc$ is frequency.\n#### magnetic field\nso, we got electric field. how can we get magnetic field? yea, we use **maxwell equations**.\n$$\n    \\vec{\\nabla} \\times \\vec{b}\n    =\n    \\mu_0 \\epsilon_0 \\frac{\\partial \\vec{e}}{\\partial t}\n$$\nto calculate left-hand side term, we can use the table.\n$$\n    \\vec{\\nabla} \\times \\vec{b}\n    =\n    \\begin{vmatrix}\n        \\vec{e_x} & \\vec{e_y} & \\vec{e_z}\\\\\n        \\partial_x & \\partial_y & \\partial_z\\\\\n        b_x & b_y & b_z\\\\\n    \\end{vmatrix}\n$$\nphysicist can typically notice that\nwe need to take care only $y$ direction of magnetic field..\nyou know we set electric field on $x$ direction.\nthus, \n$$\n    \\vec{\\nabla} \\times \\vec{b}\n    =\n    -\\frac{\\partial b_y}{\\partial z} \\vec{e_x}\n$$\ngotcha. right-hand side is easy.\n$$\n    \\mu_0 \\epsilon_0 \\frac{\\partial \\vec{e}}{\\partial t}\n    =\n    a \\cdot \\dot{q}(t) \\cdot \\sin(kz) \\cdot \\vec{e_x}\n$$\nthen, maxwell equation become\n$$\n    -\\frac{\\partial b_y}{\\partial z} \\vec{e_x}\n    =\n    a \\cdot \\dot{q}(t) \\cdot \\sin(kz) \\cdot \\vec{e_x}\n$$\nthus, \n$$\n\\begin{aligned}\n    \\vec{b}(z, t)\n    &=\n    \\frac{mu_0 \\epsilon_0}{k} \\cdot \n    a \\cdot \\dot{q}(t) \\cdot \\cos(kz) \\cdot \\vec{e_y}\n    \\\\&=\n    \\frac{mu_0 \\epsilon_0}{k} \\cdot \n    a \\cdot p(t) \\cdot \\cos(kz) \\cdot \\vec{e_y}\n\\end{aligned}\n$$\nhere, we introduced $p(t)=\\dot{q}(t)$. again we gonna see why we use symbol $p$.\n#### finally, let's calculate energy!\nwe have electric field and magnetic field so we can calculate energy.\n\n[[simulation wigner-number-state]]\n\nhowever, as you can see the difficulty is $\\int \\mathrm{d} v$. \nhow do we process this?\nwe introduce new variable cross section $\\sigma$.\n$$\n    v \n    =\n    \\sigma \\cdot l\n$$\nenergy function become\n$$\n    h \n    = \n    \\frac{1}{2} \n    \\sigma\n    \\int_0^l \\mathrm{d} z\n    \\left[\n        \\epsilon_0 \\left| \\vec{e}(z, t) \\right|^2\n        + \n        \\frac{1}{\\mu_0} \\left| \\vec{b}(z, t) \\right|^2\n    \\right]^2\n$$\nby using the math trick\n$$\n\\begin{aligned}\n    \\int_0^l \\mathrm{d}z \\sin^2(kz) \n    &=\n    \\int_0^l \\mathrm{d}z \\sin^2\\left(\\frac{\\pi}{l}mz\\right) \n    \\\\&=\n    \\frac{l}{2}\n\\end{aligned}\n$$\nwe see the simple form of energy function.\n$$\n    h\n    =\n    \\frac{1}{2} \\omega^2 q^2(t)\n    +\n    \\frac{1}{2} p^2(t)\n$$\nas you notice this energy function is same as that of unit mass classical \nharmonic oscillator.\nand our way of symbolizing make sense.\n#### warning\ncan we say $q$ as position of photon and $p$ as momentum of photon? no, we can't.\nthis is just mathematical formulation and analogy to classical harmonic oscillator.\n#### quantization\nphew. it was a long journey to get energy function. \nlet's go back to quantum world.\nto quantize the energy function, we need to use operators.\nwe introduce three operators $\\hat{h}, \\hat{q}, \\hat{p}$.\n$$\n    \\hat{h}\n    =\n    \\frac{1}{2} \\omega^2 \\hat{q}^2(t)\n    +\n    \\frac{1}{2} \\hat{p}^2(t)\n$$\nto quantize we use commutation relation to operators $\\hat{q}$ and $\\hat{p}$.\n$$\n    \\left[\n        \\hat{q}, \\hat{p}\n    \\right]\n    =\n    i\\hbar\n$$\nnotice that $\\hat{q}$ and $\\hat{p}$ are hermitian i.e. observable.\n#### new operators\nin addition to these operators, we introduce other two non-hermitian operators.\nnamely, **annihilation operator** $\\hat{a}$ \nand **creation operator** $\\hat{a}^\\dag$ .\n$$\n    \\hat{a} \n    =\n    \\frac{1}{2\\hbar\\omega}\n    \\left(\n        \\omega \\hat{q} \n        + \n        i\\hat{p} \n    \\right)\n$$\n$$\n    \\hat{a}^\\dag \n    =\n    \\frac{1}{2\\hbar\\omega}\n    \\left(\n        \\omega \\hat{q} \n        - \n        i\\hat{p} \n    \\right)\n$$\nthese operators have cool commutation relation.\n$$\n    \\left[\n        \\hat{a}, \\ha"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "quantum-measurements",
      "lessonTitle": "Quantum Measurements",
      "x": 0.8737772703170776,
      "y": 0.9316663146018982,
      "searchText": "quantum measurements\n# quantum measurements\n\n## measurement in quantum mechanics\n\nin quantum optics, measurement plays a fundamental role: the act of detection irreversibly alters the quantum state of light. the measurement formalism connects the abstract quantum state to experimentally observable quantities like photon counts, quadrature values, and correlation functions.\n\na general quantum measurement is described by a set of **measurement operators** $\\{\\hat{m}_m\\}$ satisfying $\\sum_m \\hat{m}_m^\\dagger \\hat{m}_m = \\hat{i}$. the probability of outcome $m$ given state $\\hat{\\rho}$ is\n\n$$\np(m) = \\operatorname{tr}[\\hat{m}_m^\\dagger \\hat{m}_m \\hat{\\rho}],\n$$\n\nand the post-measurement state is $\\hat{\\rho}_m = \\hat{m}_m \\hat{\\rho} \\hat{m}_m^\\dagger / p(m)$.\n\n## projective vs. generalized measurements\n\n**projective (von neumann) measurements** use orthogonal projectors $\\hat{\\pi}_m = |m\\rangle\\langle m|$ satisfying $\\hat{\\pi}_m \\hat{\\pi}_n = \\delta_{mn}\\hat{\\pi}_m$. photon number detection is a projective measurement in the fock basis $\\{|n\\rangle\\}$.\n\n**generalized measurements** (povms) allow non-orthogonal outcomes and describe realistic detectors. a **positive operator-valued measure** consists of positive operators $\\hat{e}_m \\geq 0$ with $\\sum_m \\hat{e}_m = \\hat{i}$, without requiring orthogonality. heterodyne detection is a povm with elements $\\hat{e}_\\alpha = \\frac{1}{\\pi}|\\alpha\\rangle\\langle\\alpha|$ that projects onto coherent states.\n\n## photon counting\n\nideal **photon-number-resolving** (pnr) detectors measure the fock state projectors. for a state $\\hat{\\rho}$, the probability of detecting $n$ photons is $p(n) = \\langle n|\\hat{\\rho}|n\\rangle$.\n\nreal single-photon detectors (avalanche photodiodes, superconducting nanowire detectors) are typically **threshold detectors**: they distinguish \"no click\" from \"one or more clicks\" but cannot resolve the exact photon number. the povm elements are\n\n$$\n\\hat{e}_0 = |0\\rangle\\langle 0|, \\qquad \\hat{e}_{\\text{click}} = \\hat{i} - |0\\rangle\\langle 0|,\n$$\n\nwith detector efficiency $\\eta < 1$ modeled as a beam splitter loss before an ideal detector.\n\ntransition-edge sensors and superconducting nanowire arrays can resolve photon numbers up to $\\sim 10{-}20$, enabling direct measurement of photon statistics and wigner function negativity.\n\n## quantum state tomography\n\n**quantum state tomography** reconstructs the full density matrix $\\hat{\\rho}$ from a set of measurements on many identically prepared copies. for optical fields, this is achieved by:\n\n1. **homodyne tomography**: measure the quadrature $\\hat{x}_\\theta$ for many phase angles $\\theta$. the marginal distributions $p(x_\\theta)$ are projections of the wigner function. the state is reconstructed via the inverse radon transform (same mathematics as medical ct scanning).\n\n2. **maximum likelihood estimation**: numerically find the density matrix that maximizes the likelihood of the observed data, subject to the constraints that $\\hat{\\rho}$ is positive semidefinite with unit trace.\n\nthe wigner function provides a complete phase-space representation:\n\n$$\nw(x, p) = \\frac{1}{\\pi\\hbar}\\int_{-\\infty}^{\\infty} \\langle x + y|\\hat{\\rho}|x - y\\rangle e^{-2ipy/\\hbar} dy.\n$$\n\nnegative values of $w$ indicate non-classical states (e.g., fock states, cat states).\n\n[[simulation wigner-number-state]]\n\n## quantum non-demolition measurements\n\na **quantum non-demolition** (qnd) measurement extracts information about an observable without disturbing it. for photon number, the key requirement is $[\\hat{n}, \\hat{h}_{\\text{int}}] = 0$: the interaction used for measurement commutes with the measured observable.\n\nin cavity qed, the dispersive interaction shifts the atomic phase by an amount proportional to $n$ without absorbing photons. by sending probe atoms through the cavity and measuring their phase shift, one can determine $n$ repeatedly and observe quantum jumps as individual photons are lost.\n\nthis was demonstrated by haroche's group, who tracked the photon number in a microwave cavity decaying from $n = 7$ to $n = 0$ one photon at a time, directly observing the quantum trajectory of the field state.\n\n## back-action and the uncertainty principle\n\nevery measurement has **back-action**: gaining information about one observable increases uncertainty in conjugate observables. for homodyne detection of $\\hat{x}$, the back-action appears as increased noise in $\\hat{p}$.\n\nthe **standard quantum limit** (sql) for monitoring the position of a free mass is\n\n$$\n\\delta x_{\\text{sql}} = \\sqrt{\\frac{\\hbar t}{2m}},\n$$\n\narising from the trade-off between measurement imprecision and radiation-pressure back-action. beating the sql requires correlating the measurement and back-action noise, achievable with squeezed light or back-action evasion techniques.\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "single-photon-experiments",
      "lessonTitle": "Single Photon Experiments",
      "x": 0.8271322250366211,
      "y": 0.9888681173324585,
      "searchText": "single photon experiments\n# single photon experiments\n\n## the beam splitter\n\na **beam splitter** is the fundamental optical element for single-photon experiments. it partially reflects and partially transmits incoming light. quantum mechanically, a lossless beam splitter with reflectivity $r$ and transmissivity $t = 1 - r$ transforms the input mode operators as\n\n$$\n\\begin{pmatrix} \\hat{a}_{\\text{out}} \\\\ \\hat{b}_{\\text{out}} \\end{pmatrix}\n=\n\\begin{pmatrix} t & r \\\\ r' & t' \\end{pmatrix}\n\\begin{pmatrix} \\hat{a}_{\\text{in}} \\\\ \\hat{b}_{\\text{in}} \\end{pmatrix},\n$$\n\nwhere $|t|^2 + |r|^2 = 1$ and the matrix must be unitary to preserve the commutation relations $[\\hat{a}, \\hat{a}^\\dagger] = 1$. for a symmetric beam splitter: $t = t' = \\cos\\theta$ and $r = -r'^* = i\\sin\\theta$.\n\n## single photon at a beam splitter\n\nwhen a single photon $|1\\rangle_a |0\\rangle_b$ enters one port of a 50:50 beam splitter, the output state is\n\n$$\n|1\\rangle_a |0\\rangle_b \\xrightarrow{\\text{bs}} \\frac{1}{\\sqrt{2}}\\left(|1\\rangle_c |0\\rangle_d + i|0\\rangle_c |1\\rangle_d\\right).\n$$\n\nthe photon exits through one port or the other but is never split: a single detector click occurs in output $c$ or output $d$, never both simultaneously. this was demonstrated by grangier, roger, and aspect (1986), confirming the particle nature of single photons.\n\nthe joint detection probability at both outputs is $p_{cd} = 0$ for a true single photon, while for a classical wave it would be $p_{cd} > 0$. the **anticorrelation parameter** $\\alpha = p_{cd}/(p_c p_d)$ equals zero for a single photon, providing a clean test of the quantum nature of light.\n\n## coherent state at a beam splitter\n\nfor a coherent state input $|\\alpha\\rangle_a |0\\rangle_b$, the output is a product of coherent states:\n\n$$\n|\\alpha\\rangle_a |0\\rangle_b \\xrightarrow{\\text{bs}} |t\\alpha\\rangle_c |r\\alpha\\rangle_d.\n$$\n\nunlike the single-photon case, the outputs are uncorrelated and each port independently contains a coherent state. this factorization property is unique to coherent states and reflects their classical nature.\n\na 50:50 beam splitter splits a coherent state $|\\alpha\\rangle$ into two coherent states $|\\alpha/\\sqrt{2}\\rangle$, with the total mean photon number preserved: $|\\alpha/\\sqrt{2}|^2 + |\\alpha/\\sqrt{2}|^2 = |\\alpha|^2$.\n\n## two-photon interference: hong-ou-mandel effect\n\nwhen **two indistinguishable single photons** enter a 50:50 beam splitter from different ports, they always exit together through the same port:\n\n$$\n|1\\rangle_a |1\\rangle_b \\xrightarrow{\\text{bs}} \\frac{1}{\\sqrt{2}}\\left(|2\\rangle_c |0\\rangle_d - |0\\rangle_c |2\\rangle_d\\right).\n$$\n\nthe coincidence rate at the two outputs drops to zero, known as the **hong-ou-mandel (hom) dip**. this two-photon quantum interference effect has no classical analogue and was first demonstrated by hong, ou, and mandel (1987).\n\nthe dip visibility depends on the indistinguishability of the photons. if the photons differ in frequency, polarization, or arrival time, the dip becomes shallower. the hom effect is the basis for **bell-state measurements** and linear-optical quantum computing schemes.\n\n## mach-zehnder interferometer\n\na **mach-zehnder interferometer** consists of two beam splitters with a phase shift $\\phi$ in one arm. for a single-photon input, the detection probabilities at the two outputs are\n\n$$\np_c = \\cos^2(\\phi/2), \\qquad p_d = \\sin^2(\\phi/2).\n$$\n\nthis demonstrates single-photon interference: the photon interferes with itself as it traverses both paths simultaneously in superposition. the which-path information determines whether interference is observed, illustrating the complementarity principle.\n\nfor $n$-photon states or squeezed light inputs, the interferometer can achieve phase sensitivity beyond the **shot-noise limit** $\\delta\\phi \\sim 1/\\sqrt{n}$, approaching the **heisenberg limit** $\\delta\\phi \\sim 1/n$.\n\n[[simulation wigner-coherent]]\n"
    },
    {
      "topicId": "quantum-optics",
      "topicTitle": "Quantum Optics",
      "routeSlug": "quantum-optics",
      "lessonSlug": "squeezed-light",
      "lessonTitle": "Squeezed Light",
      "x": 0.9196775555610657,
      "y": 0.9848847985267639,
      "searchText": "squeezed light\n# squeezed light\n\n## quadrature operators\n\nthe electromagnetic field quadratures are defined as\n\n$$\n\\hat{x} = \\frac{1}{2}(\\hat{a} + \\hat{a}^\\dagger), \\qquad \\hat{p} = \\frac{1}{2i}(\\hat{a} - \\hat{a}^\\dagger),\n$$\n\nsatisfying $[\\hat{x}, \\hat{p}] = i/2$. the heisenberg uncertainty relation gives $\\delta x \\cdot \\delta p \\geq 1/4$. for vacuum and coherent states, the uncertainties are equal: $\\delta x = \\delta p = 1/2$ (minimum uncertainty states with symmetric noise).\n\n**squeezed states** redistribute the quantum noise between the two quadratures. one quadrature has reduced fluctuations below the vacuum level at the expense of increased fluctuations in the conjugate quadrature, while still satisfying the uncertainty relation.\n\n## the squeezing operator\n\nthe single-mode **squeezing operator** is\n\n$$\n\\hat{s}(\\xi) = \\exp\\left[\\frac{1}{2}(\\xi^* \\hat{a}^2 - \\xi \\hat{a}^{\\dagger 2})\\right],\n$$\n\nwhere $\\xi = r e^{i\\theta}$ is the complex squeezing parameter. the magnitude $r$ determines the degree of squeezing. the squeezed vacuum state is $|\\xi\\rangle = \\hat{s}(\\xi)|0\\rangle$.\n\nunder squeezing, the quadrature variances become\n\n$$\n(\\delta x_\\theta)^2 = \\frac{1}{4}e^{-2r}, \\qquad (\\delta x_{\\theta+\\pi/2})^2 = \\frac{1}{4}e^{+2r}.\n$$\n\nthe noise reduction is characterized in decibels: squeezing of $r$ corresponds to $-10\\log_{10}(e^{-2r}) \\approx 8.69 r$ db. current experiments achieve over 15 db of squeezing.\n\n## photon statistics of squeezed vacuum\n\nthe squeezed vacuum contains only **even photon numbers**:\n\n$$\n|\\xi\\rangle = \\frac{1}{\\sqrt{\\cosh r}} \\sum_{n=0}^{\\infty} \\frac{(-e^{i\\theta} \\tanh r)^n \\sqrt{(2n)!}}{2^n n!} |2n\\rangle.\n$$\n\nthe mean photon number is $\\langle n \\rangle = \\sinh^2 r$, and the photon number distribution is super-poissonian despite the sub-vacuum noise in one quadrature. the even-photon-number signature is a distinctive feature observable in photon-number-resolving measurements.\n\n[[simulation wigner-squeezed]]\n\n## generation by parametric down-conversion\n\nthe primary method for generating squeezed light is **optical parametric down-conversion** (pdc). a nonlinear crystal with $\\chi^{(2)}$ nonlinearity is pumped by a strong laser at frequency $\\omega_p$. the pump photons are converted into pairs of photons (signal and idler) satisfying energy and momentum conservation:\n\n$$\n\\omega_p = \\omega_s + \\omega_i, \\qquad \\mathbf{k}_p = \\mathbf{k}_s + \\mathbf{k}_i.\n$$\n\nwhen the signal and idler are in the same mode (**degenerate** pdc), the output is a squeezed vacuum state. the hamiltonian describing this process is\n\n$$\n\\hat{h}_{\\text{pdc}} = i\\hbar\\kappa(\\hat{a}^{\\dagger 2} - \\hat{a}^2),\n$$\n\nwhere $\\kappa$ is proportional to the pump amplitude and the nonlinear coefficient. this is exactly the squeezing hamiltonian.\n\nin an **optical parametric oscillator** (opo), the nonlinear crystal is placed inside a cavity. below threshold, the opo produces continuous-wave squeezed light with narrow bandwidth determined by the cavity linewidth. above threshold, it oscillates and produces a coherent output.\n\n## applications of squeezed light\n\nsqueezed light has practical applications in precision measurement:\n\n- **gravitational wave detection**: ligo and virgo inject squeezed vacuum into the interferometer's dark port, reducing shot noise and improving sensitivity. frequency-dependent squeezing (using filter cavities) optimizes noise reduction across the detection bandwidth.\n\n- **quantum key distribution**: squeezed states enable continuous-variable quantum cryptography protocols where security is guaranteed by the uncertainty principle.\n\n- **spectroscopy**: sub-shot-noise measurements improve the sensitivity of absorption and phase-shift spectroscopy.\n\n- **quantum computing**: squeezed states are resources for measurement-based quantum computation in the continuous-variable regime, where large cluster states can be deterministically generated.\n"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "bounding_errors",
      "lessonTitle": "Bounding Errors",
      "x": 0.6200764179229736,
      "y": 0.36798304319381714,
      "searchText": "bounding errors\n# bounding errors\n\n\n\n## header 1\n**sources of approximation** include modelling, \nempirical measurements, previous computations, truncation/discretization, rounding.\n \n**absolute error** and **relative error** are different in the obvious manner, i.e., abs. error \n= approx. value- true value, and rel. error = abs. error / true value.\n**data error and computational errror**, the hats indicate an approximation;\n\n$$\n\\begin{align*}\n\\text{total error} &= \\hat{f}(\\hat{x})-f(x)\\\\\n&= \\left(\\hat{f}(\\hat{x})-f(\\hat{x})\\right) &+&\\left(f(\\hat{x})-f(x)\\right)\\\\\n&= \\text{computational error} &+& \\text{propagated data error}\\\\\ne_\\text{tot} &= e_\\text{comp} &+& e_\\text{data}\n\\end{align*}\n$$\n\n## header 2\ncomputational error can be split int truncation error $e_{trunc}$ and rounding error e_{round}.\n\n**truncation error** contains:\n* simplifications of the physciial model (frictionless, etc)\n* finite basis sets\n* truncations of infinite series\n\n**rounding error** contains everything that comes from working on a finite computer\n* accumulated rounding error (from finite arithmetic)\n\n**forward vs. backward error**\n\nfoward error is the error in the output, backward error is the error in the input.\n\n\n## header 3\n**sensitivity and conditioning**\n\ncondition number: $cond(f) \\equiv \\frac{|\\frac{\\delta y}{y}|}{|\\frac{\\delta x}{x}|} = \\frac{|x\\delta y|}{|y\\delta x|}$\n\n**stability and accuracy**\n\n* fixed points have each bit correspond to a specific scale.\n* floating point (32 bit) has: 1 sign bit (0=postive, 1=negative), 8 exponent bits, and 23 mantissa bits. \n\noverflow and underflow; refers to the largest and smallest numbers that can be \ncontained in a floating point.\n\n\n## example\n\ncomputational error of first order finite difference: $$ f'(x) = \\frac{f(x+h) - f(x)}{h} \\def \\hat{f'}(x) $$\ntaylor expand:\n$$ f(x+h) = f(x) + h*f'(x) + \\frac{h^2}{2} f''(\\theta), \\qquad \\lvert \\theta - x \\rvert \\leq h $$\n$$ \\frac{f(x+h) - f(x)}{h} = f'(x) + \\frac{h}2 f''(\\theta) $$\n$$ \\hat{f'}(x) - f'(x) = \\frac{h}2 f''(\\theta) $$\n$$ m \\def \\sup{\\theta - x = h} \\lvert f''(\\theta) \\rvert $$\n$$ e_{trunc} = \\hat{f'}(x) - f'(x) \\leq \\frac{m}2 h \\quad \\sim o(h) $$\n\nwhat about rounding error? assume that for $f$, it's bounded by $\\epsilon$\n$$ e_{round} \\leq \\frac{2\\epsilon}h \\quad \\sim o\\left(\\frac1h\\right) $$ \n(comes from floating point somehow... use significant digits?)\n\nif you decrease $h$, you decrease truncation error but increase rounding error\n\n$$ e_{comp} = \\frac{m}2 h + \\frac{2\\epsilon}h $$\nwhat value of $h$ minimizes it? differentiate\n\n$$ 0 = \\frac{m}2 - \\frac{2\\epsilon}{h^2} $$\n$$ h^2 = \\frac{4\\epsilon}m $$\n$h$ can't be negative, so\n$$ h = \\frac{2 \\sqrt{\\epsilon}}{\\sqrt{m}} $$\n(note that $\\epsilon$ is a bound)\n\n**propagated data error**: the problem can either expand or contract the error from your data, and it's importat to understand what it does\n\nabsolute forward data error = $f(\\hat{x}) - f(x) \\equiv \\delta y$\n\nrelative forward data error = $ \\frac{\\delta y}{y} = \\frac{f(\\hat{x}) - f(x)}{f(x)}$\n\nwe also use a _condition number_: how much a change in the data affects a change in the result.\n$$ cond(f) = \\frac{\\lvert \\delta y/y \\rvert}{ \\lvert \\delta x/x \\rvert} = \\frac{\\lvert x \\delta y \\rvert}{ \\lvert y \\delta x \\rvert} $$\n\nit may be intutive that if you start with 4 digits of input, your ouput will be correct to 4 digits at max. this isn't the case: consider a function $f(x) = x^{\\frac{1}{10}}$, and let's analyze the errors.\n\n$$ e_{data} = f(\\hat{x}) - f(x) $$\n$$ (x+\\delta x)^\\frac{1}{10} - x^\\frac{1}{10} $$\nthe relative error will be\n$$ e^{rel}_{data} = \\frac{(x+\\delta x)^\\frac{1}{10} - x^\\frac{1}{10}}{x^\\frac{1}{10}} $$\nnow taylor expand\n$$ = \\frac{x^\\frac1{10} + \\delta x x^\\frac{-9}{10} - x^\\frac{1}{10}}{x^\\frac{1}{10}} + o(\\frac{\\delta x^2}{x^\\frac1{10}})$$\n$$ \\delta y / y = \\frac1{10} \\delta{x} /x + o(quadratic)$$\nyou can have an additional significant digit in the output: start with 3, end up with 4, etc\n\n**in general**:\n* $\\sqrt{x}$ has 1 more significant bit as compared to $x$\n* $x^\\frac1{10^n}$ has n more decimal significant digits\n* x^2 is 1 fewer bit significant\n* x^10^n has n fewer decimal sig digits \n\nbut information theory tells us that information cannot be gained out of nowhere: what's going on?\n\n**truncaiton error and rounding error** are the two parts of computational error. \ntruncation error stems from truncating infinite series, or replacing derivatives \nwith finite differences. rounding error is like the error from like floating point accuracy.\n\ntruncation error, $e_\\text{trunc}$ can stem from; \n* simplification of physical model\n* finite basis sets\n* truncations of infinite series\n* ...\n\n*example:* computational error of $1^\\text{st}$ order finite difference\n\n$$\n\\begin{align*}\nf'(x) \\approx \\frac{f(x+h)-f(x)}{h}\\equiv\\hat{f'(x)}\\\\\nf(x+h) = f(x)+hf'(x)+ \\frac{h^2}{2}f''(\\theta), |\\theta-x|\\leq h\\\\\n\\frac{f(x+h)-f(x)}{h} = f'(x) + \\frac{h}{2}f''(\\theta)\\\\\n\\hat{f'(x)} - f'(x) = \\frac{h}{2}f''(\\theta), \\text{let} \\equiv \\text{sup}_{|\\theta-x|\\leq h} (f''(\\theta))\\\\\ne_\\text{trunc} = \\hat{f'(x)}-f'(x)\\leq \\frac{m}{2}h\\sim o(h)\n\\end{align*}\n$$\n\nbut what about the rounding error? \n(assume r.e. for $f$ is $\\epsilon \\rightarrow e_\\text{ronud} \\leq \\frac{2\\epsilon}{h}\\sim 0(\\frac{1}{h})$\n\n$$\n\\begin{align*}\ne_\\text{comp} = \\frac{m}{2}h + \\frac{2\\epsilon}{h}\\\\\n0 = \\frac{d}{dh}e_\\text{comp} = \\frac{m}{2}-\\frac{2\\epsilon}{h^2}\\\\\n\\frac{m}{2} = \\frac{2\\epsilon}{h^2} \n\\leftrightarrow h^2 = \\frac{4\\epsilon}{m}\\leftrightarrow h_\\text{optimal} = 2\\sqrt{\\frac{\\epsilon}{m}}\n\\end{align*}\n$$"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "eigenSystems",
      "lessonTitle": "Eigenvalue Problems",
      "x": 0.715760350227356,
      "y": 0.31712788343429565,
      "searchText": "eigenvalue problems\n# eigenvalue problems\n\nany stable physical/chemical system can be described with an eigensystem. wavefunctions in quantum mechanics are a typical example.\n\n$$\nax = \\lambda x\n$$\n\nwhere $a$ is the operator (mapping $\\mathbb{c}^n \\rightarrow \\mathbb{c}^n$), $x$ an eigenvector, and $\\lambda$ an eigenvalue. the question is: **how do we obtain the eigenvalues and eigenvectors?**\n\n[[simulation eigen-transformation]]\n\n## why eigenvalues matter\n\neigenvalues appear throughout physics and engineering:\n\n- **quantum mechanics**: energy levels are eigenvalues of the hamiltonian\n- **vibrations**: natural frequencies of structures\n- **stability analysis**: system behavior near equilibrium points\n- **principal component analysis**: dimensionality reduction in data science\n- **google pagerank**: largest eigenvector of the web graph\n\n[[figure eigen-applications]]\n\n---\n\n## mathematical foundations\n\n### the characteristic polynomial\n\nfor any fixed $\\lambda$, we have a linear system:\n\n$$\n(a-\\lambda i)x = 0\n$$\n\nthis has **non-trivial** solutions ($x\\neq0$) if and only if:\n\n$$\n\\det(a-\\lambda i) = 0\n$$\n\n[[simulation characteristic-polynomial]]\n\n### eigenspaces and multiplicity\n\neigenvectors form subspaces called **eigenspaces**:\n\n$$\ne_\\lambda = \\{x\\in \\mathbb{c}^n \\mid ax=\\lambda x\\}\n$$\n\nthe characteristic polynomial $p(\\lambda) = \\det(a-\\lambda i)$ is of degree $n$, and by the **fundamental theorem of algebra**, has exactly $n$ complex roots (counting multiplicity).\n\n**two types of multiplicity:**\n\n1. **algebraic multiplicity**: how many times $\\lambda_i$ appears in the characteristic polynomial\n2. **geometric multiplicity**: dimension of the eigenspace $e_\\lambda$\n\n[[figure multiplicity-diagram]]\n\n**key inequality**: geometric multiplicity $\\leq$ algebraic multiplicity\n\n### defective vs non-defective matrices\n\n- **non-defective**: $\\sum_{\\lambda\\in sp(a)} \\dim(e_\\lambda) = n$ \u2014 we have a complete eigenbasis\n- **defective**: $\\sum_{\\lambda\\in sp(a)} \\dim(e_\\lambda) < n$ \u2014 not enough eigenvectors\n\n**non-defectiveness is guaranteed if:**\n- $a$ is **normal**: $a^h a = aa^h$\n- all eigenvalues are distinct\n- $a$ is **hermitian**: $a=a^h$ (best case \u2014 guarantees orthonormal eigenbasis)\n\nfor hermitian matrices: $a = u \\lambda u^h$\n\n[[simulation hermitian-demo]]\n\n---\n\n## the power method\n\nlet $a$ be non-defective with $a=t\\lambda t^{-1}$. order the eigenvalues by magnitude:\n\n$$\n|\\lambda_1| \\geq |\\lambda_2| \\geq \\dots \\geq |\\lambda_n|\n$$\n\n### derivation\n\nfor any $x \\in \\mathbb{c}^n$, expressed in the eigenbasis:\n\n$$\nx = \\tilde{x}_1 t_1 + \\tilde{x}_2 t_2 + \\dots + \\tilde{x}_n t_n\n$$\n\napplying $a$ repeatedly:\n\n$$\na^k x = \\tilde{x}_1 \\lambda_1^k t_1 + \\tilde{x}_2 \\lambda_2^k t_2 + \\dots + \\tilde{x}_n \\lambda_n^k t_n\n$$\n\n$$\n= \\lambda_1^k \\left(\\tilde{x}_1 t_1 + \\tilde{x}_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k t_2 + \\dots + \\tilde{x}_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^k t_n\\right)\n$$\n\nsince $|\\lambda_1|$ is largest, the ratios approach zero:\n\n$$\n\\lim_{k\\to\\infty}\\frac{a^k x}{\\|a^k x\\|} = t_1, \\quad \\text{if } \\tilde{x}_1 \\neq 0 \\text{ and } |\\lambda_2| < |\\lambda_1|\n$$\n\n[[simulation power-method-animation]]\n\n### power method algorithm\n\n```python\ndef power_iterate(a, x0, tol=1e-10, max_iter=1000):\n    \"\"\"\n    find the dominant eigenvalue and eigenvector.\n    \n    parameters:\n        a: square matrix\n        x0: initial guess vector\n        tol: convergence tolerance\n        max_iter: maximum iterations\n    \n    returns:\n        eigenvalue, eigenvector, iterations\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    \n    for i in range(max_iter):\n        y = a @ x\n        x_new = y / np.linalg.norm(y)\n        \n        # rayleigh quotient for eigenvalue estimate\n        eigenvalue = x_new @ a @ x_new\n        \n        if np.linalg.norm(x_new - x) < tol or np.linalg.norm(x_new + x) < tol:\n            return eigenvalue, x_new, i + 1\n        \n        x = x_new\n    \n    return eigenvalue, x, max_iter\n```\n\n### limitations\n\n- only finds the **dominant eigenvalue** (largest magnitude)\n- fails if the dominant eigenvalue is not unique\n- slow convergence when $|\\lambda_1| \\approx |\\lambda_2|$ (small spectral gap)\n\n[[figure convergence-comparison]]\n\n---\n\n## inverse iteration\n\nto find an eigenvalue **closest to a shift** $\\sigma$, apply the power method to $(a - \\sigma i)^{-1}$:\n\nthe eigenvalues of $(a - \\sigma i)^{-1}$ are $(\\lambda_i - \\sigma)^{-1}$, so the one closest to $\\sigma$ becomes dominant.\n\n```python\ndef inverse_iterate(a, sigma, x0, tol=1e-10, max_iter=1000):\n    \"\"\"\n    find eigenvalue closest to sigma.\n    \"\"\"\n    n = len(a)\n    x = x0 / np.linalg.norm(x0)\n    a_shifted = a - sigma * np.eye(n)\n    \n    for i in range(max_iter):\n        # solve (a - sigma*i) y = x\n        y = np.linalg.solve(a_shifted, x)\n        x_new = y / np.linalg.norm(y)\n        \n        eigenvalue = x_new @ a @ x_new\n        \n        if np.linalg.norm(x_new - x) < tol or np.linalg.norm(x_new + x) < tol:\n            return eigenvalue, x_new, i + 1\n        \n        x = x_new\n    \n    return eigenvalue, x, max_iter\n```\n\n[[simulation inverse-iteration]]\n\n---\n\n## rayleigh quotient iteration\n\nthe **rayleigh quotient** provides an eigenvalue estimate:\n\n$$\n\\lambda_r(x) = \\frac{x^t a x}{x^t x}\n$$\n\nrayleigh quotient iteration updates the shift at each step, achieving **cubic convergence** for hermitian matrices!\n\n```python\ndef rayleigh_quotient_iteration(a, x0, tol=1e-12, max_iter=100):\n    \"\"\"\n    fast cubic convergence for hermitian matrices.\n    \"\"\"\n    n = len(a)\n    x = x0 / np.linalg.norm(x0)\n    eigenvalue = x @ a @ x\n    \n    for i in range(max_iter):\n        a_shifted = a - eigenvalue * np.eye(n)\n        \n        try:\n            y = np.linalg.solve(a_shifted, x)\n        except np.linalg.linalgerror:\n            # singular matrix means we hit an eigenvalue\n            return eigenvalue, x, i\n        \n        x_new = y / np.linalg.norm(y)\n        eigenvalue_new = x_new @ a @ x_new\n        \n        if abs(eigenvalue_new - eigenvalue)"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "fft",
      "lessonTitle": "Fast Fourier Transform",
      "x": 0.6506667137145996,
      "y": 0.46004071831703186,
      "searchText": "fast fourier transform\n# fast fourier transform\n\n## the discrete fourier transform\n\nthe **discrete fourier transform** (dft) converts a sequence of $n$ samples in the time domain into a sequence of $n$ complex coefficients in the frequency domain:\n\n$$\nx_k = \\sum_{n=0}^{n-1} x_n \\, e^{-2\\pi i \\, kn/n}, \\qquad k = 0, 1, \\ldots, n-1.\n$$\n\nthe inverse transform recovers the original signal:\n\n$$\nx_n = \\frac{1}{n} \\sum_{k=0}^{n-1} x_k \\, e^{2\\pi i \\, kn/n}.\n$$\n\neach coefficient $x_k$ represents the amplitude and phase of a sinusoidal component at frequency $k/n$ cycles per sample. the **power spectrum** $|x_k|^2$ reveals the dominant frequencies in the signal.\n\n## the fft algorithm\n\ncomputing the dft directly requires $o(n^2)$ operations. the **fast fourier transform** (cooley-tukey, 1965) reduces this to $o(n \\log n)$ by exploiting the symmetry and periodicity of the complex exponentials.\n\nthe key idea for radix-2 fft (when $n$ is a power of 2):\n\n$$\nx_k = \\underbrace{\\sum_{m=0}^{n/2-1} x_{2m} \\, e^{-2\\pi i \\, k(2m)/n}}_{\\text{even-indexed dft}} + e^{-2\\pi i \\, k/n} \\underbrace{\\sum_{m=0}^{n/2-1} x_{2m+1} \\, e^{-2\\pi i \\, k(2m)/n}}_{\\text{odd-indexed dft}}.\n$$\n\nthis splits one $n$-point dft into two $n/2$-point dfts plus $o(n)$ multiplications. applying this recursively yields the $o(n \\log n)$ complexity.\n\n**practical impact**: for $n = 10^6$, the fft is roughly $50{,}000$ times faster than the direct dft.\n\n## applications in signal processing\n\nthe dft and fft are ubiquitous in scientific computing:\n\n- **spectral analysis**: identify periodic components in time series (e.g., tidal data, heart rhythms, seismic signals).\n- **filtering**: multiply the spectrum by a transfer function to remove noise or isolate frequency bands.\n- **interpolation and zero-padding**: increasing $n$ by appending zeros refines the frequency resolution.\n- **image processing**: the 2d dft decomposes images into spatial frequencies for compression (jpeg) and enhancement.\n\n## the convolution theorem\n\none of the most powerful properties of the dft is the **convolution theorem**:\n\n$$\n\\mathcal{f}\\{f * g\\} = \\mathcal{f}\\{f\\} \\cdot \\mathcal{f}\\{g\\},\n$$\n\nwhere $*$ denotes convolution and $\\cdot$ denotes pointwise multiplication. this means that convolution in the time domain becomes multiplication in the frequency domain.\n\n**practical consequence**: convolving two sequences of length $n$ via the fft costs $o(n \\log n)$, compared to $o(n^2)$ for direct convolution. this speedup is exploited in:\n\n- polynomial multiplication.\n- cross-correlation and matched filtering.\n- solving pdes with periodic boundary conditions (spectral methods).\n\n## aliasing and the nyquist frequency\n\nthe dft assumes the signal is periodic with period $n$. if the signal contains frequencies above the **nyquist frequency** $f_{\\text{nyq}} = f_s / 2$ (where $f_s$ is the sampling rate), those components are **aliased** into lower frequencies.\n\nthe **sampling theorem** (shannon-nyquist) states that a bandlimited signal can be perfectly reconstructed from its samples if and only if the sampling rate exceeds twice the highest frequency present.\n\n## windowing\n\nreal signals are finite in duration. truncation introduces spectral **leakage**, spreading energy from a true frequency into neighboring bins. **window functions** (hann, hamming, blackman) taper the signal at the edges to reduce leakage at the cost of slightly reduced frequency resolution.\n\n[[simulation reaction-diffusion]]\n"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "home",
      "lessonTitle": "Scientific Computing",
      "x": 0.6869516968727112,
      "y": 0.5147120952606201,
      "searchText": "scientific computing\n# scientific computing\n\n## course overview\n\nscientific computing develops the **numerical methods** needed to solve problems in biology, physics, nanoscience, and chemistry that have no closed-form solution. the emphasis is on deriving algorithms, programming them, and understanding their error behavior.\n\n- accuracy: how close is the numerical answer to the true solution?\n- efficiency: how does the computational cost scale with problem size?\n- robustness: does the method work reliably across a range of inputs?\n- stability: do small perturbations in input produce small perturbations in output?\n\n## why this topic matters\n\n- most differential equations arising in science cannot be solved analytically.\n- linear systems with thousands of unknowns appear in finite-element modeling, data fitting, and network analysis.\n- optimization underlies machine learning, inverse problems, and experimental design.\n- understanding numerical error is essential for trusting computational results.\n\n## key mathematical ideas\n\n- matrix factorizations (lu, qr, svd) and their role in solving linear systems.\n- iterative methods for nonlinear equations (newton-raphson, fixed-point iteration).\n- numerical integration of odes (euler, runge-kutta) and stability theory.\n- finite-difference discretization of pdes.\n- the discrete fourier transform and the fft algorithm.\n- condition numbers and the propagation of rounding errors.\n\n## prerequisites\n\n- programming in python with numpy.\n- linear algebra: matrix operations, eigenvalues, vector spaces.\n- calculus: derivatives, integrals, taylor series.\n\n## recommended reading\n\n- heath, *scientific computing: an introductory survey*.\n- trefethen and bau, *numerical linear algebra*.\n- press et al., *numerical recipes*.\n\n## learning trajectory\n\nthis module is organized from foundational linear algebra to advanced pde methods:\n\n- error analysis and floating-point arithmetic.\n- linear equations: gaussian elimination and lu factorization.\n- linear least squares and data fitting.\n- nonlinear equations and optimization.\n- eigenvalue problems: power method, qr algorithm.\n- initial value problems for odes: euler and runge-kutta methods.\n- partial differential equations: finite differences, heat and wave equations.\n- fast fourier transform: dft, fft, and signal processing.\n"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "initialValueProblems",
      "lessonTitle": "Initial Value Problems",
      "x": 0.7054721713066101,
      "y": 0.403448224067688,
      "searchText": "initial value problems\n# initial value problems\n\n## introduction\n\nan **initial value problem** (ivp) asks us to find $y(t)$ satisfying an ordinary differential equation $y' = f(t, y)$ with a given initial condition $y(t_0) = y_0$. most ode systems arising in physics and engineering cannot be solved analytically, so we rely on numerical methods that advance the solution step by step through discrete time increments.\n\nthe key challenges are **accuracy** (how close the numerical solution tracks the true one), **stability** (whether errors grow or decay), and **efficiency** (how much computation is needed for a given accuracy). these three concerns drive the design of all ivp solvers.\n\n## euler's method\n\nthe simplest approach discretizes the derivative directly. given a step size $h$, **forward euler** updates the solution as\n\n$$\ny_{n+1} = y_n + h f(t_n, y_n).\n$$\n\nthis is a first-order method: the local truncation error per step is $o(h^2)$, giving a global error of $o(h)$. while easy to implement, euler's method requires very small step sizes for acceptable accuracy and is unstable for stiff problems.\n\n**backward euler** replaces the right-hand side with the function evaluated at the new time:\n\n$$\ny_{n+1} = y_n + h f(t_{n+1}, y_{n+1}).\n$$\n\nthis is an **implicit** method since $y_{n+1}$ appears on both sides and generally requires solving a nonlinear equation at each step. the payoff is greatly improved stability for stiff systems.\n\n## runge-kutta methods\n\n**runge-kutta methods** achieve higher accuracy by evaluating $f$ at intermediate points within each step. the classical fourth-order method (rk4) computes\n\n$$\n\\begin{aligned}\nk_1 &= f(t_n, y_n), \\\\\nk_2 &= f(t_n + h/2, \\; y_n + h k_1/2), \\\\\nk_3 &= f(t_n + h/2, \\; y_n + h k_2/2), \\\\\nk_4 &= f(t_n + h, \\; y_n + h k_3),\n\\end{aligned}\n$$\n\nand then advances with\n\n$$\ny_{n+1} = y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4).\n$$\n\nrk4 has a local truncation error of $o(h^5)$ and a global error of $o(h^4)$, offering an excellent balance of accuracy and simplicity. it is the workhorse method for non-stiff problems.\n\na general $s$-stage runge-kutta method is defined by a **butcher tableau** specifying the coefficients $a_{ij}$, $b_i$, and $c_i$. the method is explicit if $a_{ij} = 0$ for $j \\geq i$ and implicit otherwise.\n\n## multistep methods\n\nrather than using multiple evaluations within a single step, **multistep methods** use information from several previous steps. an $s$-step **adams-bashforth** method (explicit) takes the form\n\n$$\ny_{n+1} = y_n + h \\sum_{j=0}^{s-1} \\beta_j f(t_{n-j}, y_{n-j}).\n$$\n\nthe two-step version ($s = 2$) is\n\n$$\ny_{n+1} = y_n + \\frac{h}{2}\\bigl(3f_n - f_{n-1}\\bigr).\n$$\n\n**adams-moulton** methods are the implicit counterparts and include $f_{n+1}$ on the right-hand side. in practice, a **predictor-corrector** scheme uses adams-bashforth to predict and adams-moulton to correct, combining the efficiency of explicit methods with the improved stability of implicit ones.\n\n## stability analysis\n\nto study stability, we apply numerical methods to the **test equation** $y' = \\lambda y$ where $\\lambda \\in \\mathbb{c}$. the **stability region** of a method is the set of values $h\\lambda$ for which the numerical solution does not grow without bound.\n\nfor forward euler, the stability region is the disk $|1 + h\\lambda| \\leq 1$ in the complex plane. for backward euler, the stability region is the complement of $|1 - h\\lambda| < 1$, which includes the entire left half-plane. a method is **a-stable** if its stability region contains the entire left half-plane $\\operatorname{re}(h\\lambda) \\leq 0$.\n\nexplicit methods have bounded stability regions, so step sizes must satisfy $|h\\lambda| < c$ for some constant $c$. for stiff problems (where eigenvalues of the jacobian span many orders of magnitude), this restriction makes explicit methods impractical.\n\n## stiffness\n\na problem is **stiff** when it contains both fast-decaying and slow-varying components. the fast components force explicit methods to use tiny step sizes even when the solution is smooth. classic examples include chemical reaction kinetics, circuit simulations, and discretized parabolic pdes.\n\nfor stiff problems, **implicit methods** (backward euler, implicit runge-kutta, bdf methods) are essential. the **backward differentiation formulas** (bdf) of order $s$ are\n\n$$\n\\sum_{k=0}^{s} \\alpha_k y_{n+1-k} = h \\beta_0 f(t_{n+1}, y_{n+1}).\n$$\n\nbdf methods up to order 5 are a-stable or nearly so and form the basis of production codes like lsoda and sundials.\n\n## adaptive step size control\n\nin practice, a fixed step size is wasteful: the solution may be smooth in some regions and rapidly varying in others. **adaptive methods** estimate the local error and adjust $h$ to maintain a user-specified tolerance.\n\na common approach uses an **embedded runge-kutta pair** where two methods of different orders share the same function evaluations. the **dormand-prince** method (used by matlab's `ode45` and scipy's `solve_ivp`) pairs a fourth-order and fifth-order method. the difference between the two solutions estimates the local error:\n\n$$\n\\text{err} \\approx |y_{n+1}^{(5)} - y_{n+1}^{(4)}|.\n$$\n\nif the error exceeds the tolerance, the step is rejected and retried with a smaller $h$. if the error is well below the tolerance, $h$ is increased. a standard step-size update rule is\n\n$$\nh_{\\text{new}} = h \\left(\\frac{\\text{tol}}{\\text{err}}\\right)^{1/(p+1)}\n$$\n\nwhere $p$ is the order of the lower-order method.\n\n## systems of odes and higher-order equations\n\nany higher-order ode can be rewritten as a first-order system. for example, newton's second law $m\\ddot{x} = f(x, \\dot{x}, t)$ becomes\n\n$$\n\\frac{d}{dt}\\begin{pmatrix} x \\\\ v \\end{pmatrix} = \\begin{pmatrix} v \\\\ f(x, v, t)/m \\end{pmatrix}.\n$$\n\nall the methods above apply to vector-valued systems $\\mathbf{y}' = \\mathbf{f}(t, \\mathbf{y})$ with no modifications other than replacing scalar operations with vector ones.\n\nfor hamiltonian systems (where energy conservat"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "linear_equations",
      "lessonTitle": "Linear Equations",
      "x": 0.7497873306274414,
      "y": 0.25595104694366455,
      "searchText": "linear equations\n# linear equations\n\n\n\n## why linear systems matter\nlinear systems are special: it's something we can solve really well, and it covers an enormous amount of problems. even when you've got a non-linear system, you can isolate the linearity and solve that, and treat the non-linearity in another way.\n\n## from abstract linear systems to matrices\n#### going from abstract linear systems to matrices\n\na **linear function** is anything that behaves in the way we call linear. they exist in vector spaces: a mapping $f: x \\rightarrow y$ (abstract, eg: wave functions) is linear if $f(ax + bx') = af(x) + bf(x')$. \n\nlinear functions and matrices are the same thing!\n* let's say you have a basis for $x$, eg: $\\{e_{1}, e_2, \\dots e_n\\}$, then any vector $x \\in x$ can be written uniquely as $x = a_1e_1 + \\dots + a_n e_n$\n* let $\\{f_{1}, f_2, \\dots f_n\\}$ form a basis for $y$, any vector $y \\in y$ can be written as $y = b_1f_1 + \\dots + b_m f_m$\n* $$f(e_j)=b_{1j}f_1 + \\dots + b_{mj}f_m$$\n\twe can write it because of linearity, but you'll notice that it's just matrix multiplication.\n* $$ f(x) = f(a_1e_1 + \\dots + a_ne_n) = a_1f(e_1) + \\dots + a_nf(e_n) $$\n\t$$ = \\sum_{j=1}^n a_j \\sum_{i=i}^m b_{ij} f_i $$ \n\t$$ = \\sum_{i=i}^m f_i \\left(\\sum_{j=1}^n a_j b_{ij} \\right) $$ \n\tthe thing on the right is nothing more than a matrix product. think of the total thing as:  representation of $f$ in $e,f$ basis $*$ (coordinates of $x$ in $e$ basis) = coordinates of $y$ in $f$ basis\n\nwe've shown how an abstract linear problem can be represented with matrices. \n\nwe're missing one thing: how do you find $b_{ij}$, the components of the matrix? \n$$b_{ij} = \\left< f_i \\vert f e_j \\right>$$\nfor example, $\\int f_i(\\alpha)(fe_j)(\\alpha) d\\alpha$, if $y$ is a space of functions $f(\\alpha)$\n\n**punch line:** the actions of $f: x\\rightarrow y$ are exactly the same as $f: \\mathbb{c}^m \\rightarrow \\mathbb{c}^n$.\n\n#### how to solve linear systems of equations\n\nfind all $x \\in x$ such that $f(x) = y$ (some known $y\\in y$)\n1. pick basis sets $\\{e_1, \\dots, e_n\\}$ for $x$, $\\{f_1, \\dots, f_m\\}$ for $y$\n2. write down matrix $f$ in $e,f$ basis and rhs $y$ in $f$ basis\n3. solve matrix equation $fx=y$, where $f$ and $y$ are known\n4. dot result $x$ with $e$ basis to get the result in the problem domain $x=x_1e_1+\\dots+x_ne_n$\n\n## existence of solutions\n#### can we solve $f(x)=y$?\nyes, when solutions exist!\n\ntoday, we'll use the case where $m=n$, i.e, matrix $\\underline{f}$ is square.\n\nif you apply $f$ to all the vectors in the source space, you get a subset (not proper) of $y$, which is called the _image_. $im(f) = \\{f(x) \\vert x \\in x\\}$.\n\nin the non-abstract space, it's called the _span_: $span(\\underline{f}) = \\{\\underline{f} \\,\\underline{x} \\vert \\underline{x} \\in \\mathbb{c}\\}$\n\nthree cases when $n=m$\n\n* **$f$ is non-singular**: (if one of them holds, all of them hold: they're equivalent)\n* $im(f) = y$ (dimension of source space $x$ = dimension of target space $y$)\n* $span(\\underline{f} = \\mathbb{c}^n)$\n* $rank(\\underline{f}) = n$\n* $det(\\underline{f}) \\neq 0$\n* $\\underline{f}\\,\\underline{x} = 0 \\leftrightarrow \\underline{x}=0$ (trivial kernel)\n* $\\underline{f}$ is invertible (deterministically find unique solution)\n* **$f$ is singular**:\n* $im(f) \\not\\subseteq y$\n* $span(\\underline{f} \\not\\subseteq \\mathbb{c}^n)$\n* $rank(\\underline{f}) < n$\n* $det(\\underline{f}) = 0$\n* there is a non-trivial subspace $ker(\\underline{f})$ such that $\\underline{f}(\\underline{x})=0$ for $\\underline{x}\\in ker(\\underline{f})$\n\nsingular $f$ splits into two sub-cases:\n1. $y \\not\\in im(f) \\implies$ there are no solutions\n2. $y \\in im(f) \\implies$ infinitely many solutions (because we can add something from the kernel and get another solution).\n\nthat was the mathematical part: now we're going to look at a case where we have exact solutions: when are the solutions stable, and when do small perturbations cause it to blow up?\n\n## condition number interactive demo\n\n<conditionnumberdemo />\n\n## sensitivity of a linear system of equations\n\nthe more orthogonal the matrix is, the lower the condition number. it's ~1 for orthogonal, but as they get closer to one another, i.e, they get closer to being linearly dependent on one another, condition number increases. the webpage has a calculation of the exact condition number.\n\n## interactive gaussian elimination and lu decomposition\n\n<gaussianelimdemo />\n\n<ludecompdemo />\n\n## how to build the algorithms from scratch\n\nconstruct algoithms that transforms $b=ax$ into $x$ using a modest number of operations that are linear, invertible, and simple to compute.\n\n**fundamental property:** if $m$ is invertible, then $max = mb$ has the same solutions as $ax=b$\n\nwhat we know:\n1. our algorithm must have the same effect as multiplying by the inverse (you don't want to actually calculate the inverse and multiply because it introduces a lot of computational error): $a \\rightarrowtail i; i \\rightarrowtail a; b \\rightarrowtail x$\n2. each step must be linenar, invertible\n3. we first want $a = lu$ (lower and upper triangular matrices)\n4. every step, we want to take an $n\\times n$ matrix, and reduce the leftmost column to be zero below the first element. then, we just recursively continue for an $(n-1)\\times(n-1)$ matrix\n5. row scaling (it's linear and invertible)\n6. row addition and subtraction is also linear and invertible\n\nwe can use 5. and 6. together: just scale the rows (if the leading term is nonzero) and subtract\n\n\"sorry anton, i ain't taking notes on gaussian elimination\"\n\n## lu_factorize\ndef lu_factorize(m):\n    \"\"\"\n    factorize m such that m = lu\n\n    parameters\n    ----------\n    m : square 2d array\n        the 1st param name `first`\n\n    returns\n    -------\n    l : a lower triangular matrix\n    u : an upper triangular matrix\n    \"\"\"\n    m, u = m.shape[0], m.copy()\n    l = np.eye(m.shape[0]) # make identity \n    for j in range(m-1):\n        for i in range(j+1,m):\n            scalar    = u[i, j] / u[j,j]\n            u[i]    "
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "linearLeastSquares",
      "lessonTitle": "Linear Least Squares",
      "x": 0.7252544164657593,
      "y": 0.269555002450943,
      "searchText": "linear least squares\n# linear least squares\n\n\n\n## the least squares problem\nwith given data and a desired function, determine the paramters of the function to minimize the distance to data points.\n\n\n## least square solution\n* **always exists:** solution to $ax=ilde{b}$ is the least square solution. \n$ilde{b}$ is the projection on the image space, and $b^\\perp$ \nthe projection on the orthogonal component\n* **unique if rank(a) = n:** if the rank is less than n, there are \ninfinitely many solutions: you can find one and add the kernel space \nto it to get them all\n* **normal equations**: \n$a^t_ir=0 \\rightarrow a^tr=0 mplies a^t(b-ax)=a^tb-a^tax=0$. \nthe fact that the residual is orthogonal to the image means that \nfor all the rows of $a$, the dot product with the residual has to be 0.\n* **$a^ta$ is a small square matrix**\n* the only problem is that this has a large condition number: cond$(a^ta)$ = cond$(a)^2$\n\n\nwe're almost at our goal, but not there yet. we've found an efficient solution (the normal equations) which are great for mathematical calculations, but we can't use them because a small error will ruin us because of the condition number.\n\n### how do we save our significant digits (hopefully without too much work?)\n\nnote that $im(a)^\\perp = ker(a^t) mplies \\mathbb{c}^m=im(a)plus ker(a^t)$.\n\n### recap\nwe decomposed the target space $\\mathbb{c}^m$. (see \"prison school\" manga for a fun analogy to decomposition.) \n\ncond($a^ta$) = cond($a^2$), but cond($q^ta$) = cond($a$).\n\nwe just need to construct the effect of multiplying our matrix by $q^t$. in general, you never want to calculate $q$ cause it can be really large (million x million).\n\n## building a least squares algorithm from scratch\n\nnote: norm $eft(\\,||x||\\,ight)$ always refers to the euclidean norm $eft(\\,||x||_2\\,ight)$ when we're talking about least squares.\n\n**goal:** construct the effect of $q^t$ such that $q^t a = b$, where $b$ is a matrix with the bottom part being 0 and the upper part being upper triangular.\n\n**building blocks:** we want to perform _unitary_ operations: i.e, do things that don't change the length of vectors: operations like rotation, reflection (not translations, because although it doesn't change lengths it changes the norm).\n* 2d: rotations and reflections\n* 3d: rotations, reflections and inversions (like reflection through a point)\n* higher dimensions: lots more (symmetries of n-spheres), permutations (everywhere)\n\n**what do we want to build?** similar to lu, we want to take a column and eliminate everything below the diagonal. construct a reflection operation $h$ (for householder), which is a reflection. the norm of the entire column must be the same though, and so the top element (the diagonal) must contain $||a||$ concentrated in it.\n\nfirst, we reflect vector (column) $a$ onto basis vector $e_1$. consider a mirror, which is the angle bisector in between $a$ and $e_1$. we could reflect it onto $e_1$ or even onto the negative side, $-e_1$. call the two mirrors $v^+$ and $v^-$\n\nthe operation needs to transform $\\vec{a} ightarrowtail \\alpha \\vec{e_1}$, where $\\alpha= \\pm ||a||$\n\n$$ha = a - 2 pva$$\n$$ h = i - 2pv \\qquad v=v^+ ext{ or } v^-$$\n\nhow to find $v^+, v^-$?\n\nprojection operator, $p_v a = \\frac{v^t a}{||v||^2} v= \\frac{v^t a}{v^t v} v = eft(\\frac{vv^t}{v^tv} aight)$\n$$mplies p_v = \\frac{vv^t}{v^tv}$$\n\n$$\\alpha e_1 = ha = a-2\\frac{v^ta}{v^tv}v$$\n$$\\underbrace{\\frac{2v^ta}{v^tv}} v =a-\\alpha e_1$$\nfirst part is just a scalar number, the rest are vectors. it gets normalized away if we choose $||v||=1$\n\nthus, $v \\propto a - \\alpha e_1$. just subtract $\\alpha$ from the first entry in the column\n\nnow we can plug that into the equation for $h$, and we're done.\n\n## code\ndef householderqr(a, b):\n\tm, n = a.shape\n\tr = a.astype(float)\n\tb_tilde = b.astype(float)\n\tfor k in range(n):\n\t\ta = r[k:m, k]\n\t\tif (np.dot(a[1:],a[1:]) == 0):\n\t\t\tcontinue\n\t\tv = reflection_vector(a)\n\t\treflect_columns(x, r[k:m, k:n])\n\t\treflect_columns(v, b_tilde[k:m])\n\treturn r, b_tilde\n\ndef reflect_columns(v, a):\n\ts = -2 * np.dot(v, a)\n\ta -= v[:, na] * s[na, :]\n\n## qr factorization via householder reflections\nthe last line rhs is the same as `np.outer(s,v)`\n\nthis then yields a much better least squares optimizer:\n\n\n## least_squares\ndef least_squares(a, b):\n    '''\n    solves ax = b, for x\n    '''\n    q, r = householder_qr_slow(a)\n    v = q.t @ b\n    size = np.shape(a)[1]\n    r_cropped = r[:size,:size]\n    v_cropped = v[:size]\n    x = backward_substitute(r_cropped, v_cropped)\n    \n    residual = max(abs(v[size-1:]))\n    return x, residual\n"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "nonlinearEquationsOptimization",
      "lessonTitle": "Nonlinear Equations and Optimization",
      "x": 0.6708601117134094,
      "y": 0.34099942445755005,
      "searchText": "nonlinear equations and optimization\n# nonlinear equations and optimization\n\n\n\n# root finding in one dimension\n## notation:\n\n* $f(x) = 0$: 1 dimensional stuff. $f:\\mathbb{r} \\to \\mathbb{r}$\n* $f(x) = 0$: higher dimensional stuff, $f$ is a matrix an $x$ a vector. $f:\\mathbb{r}^n\\to\\mathbb{r}^m$\n\ncomplex numbers are complicated, so we'll only work with reals.\n\n\n## introduction\n\nemergent macroscopic behaviour comes out of high dimensionality of linear systems. for example, you don't figure out the aerodynamics of a plane by using the schrodinger equation for every atom. you can make a simpler theory based on the emergent behaviour, which could be non-linear despite the underlying rules being linear. you could also just make up a non-linear problem, like in economics.\n\n**linear systems:** \ud83d\ude0a\n* we know exactly how many solutions exist (by looking at the matrix's rank)\n* we have methods to find exact solutions (if they exist) or approximate solutions (if they don't exist).\n* we can find the full solution space of the problem by adding the kernel\n* we can routinely solve for billions of dimensions: it's very efficient\n\n**non-linear systems:** \ud83d\udc80\n* no idea how many (if any) solutions. all we can hope for is rules of thumb, heuristics, and we can look for something that works as much as possible and fails rarely. we won't get great results in a finite number of steps, sometimes it gets closer and sometimes it doesn't.\n* no fail-proof solvers\n* no way of knowing if we've found all the solutions\n* even 1 dimensional solutions can take ages\n\n## how many solutions?\n\nglobally, *anything is possible*. $e^{-x}$ has no solutions, but $(e^{-x}-\\delta)$ (where $\\delta$ is a small number) does. $\\sin(x)$ has countably infinite solutions, while $\\text{erf}(x) -\\frac12$ has uncountably infinite solutions.\n\nlocally, we can sometimes work it out. in 1d, we can look at where $f(x)$ changes sign, and we can assume that there's a root in between (intermediate value theorem, assuming the function is continuous). in particular, there are $>1$ roots in the region, and there are an odd number of roots.\n\n## general algorithm construction scheme\n\nin general, you want to find an algorithm which does the following:\n1. find invariant that guarantees existence of a solution in the search space\n2. design operation that preserves 1. and shrinks search space\n\nit's a tried and true scheme for coming up with algorithms, euclid did it thousands of years ago, and we'll do it now. let's use this to build an equation solver on a bracket. (a *bracket* is an interval in which $f(x)$ changes sign).\n\n## bisection method\n1. our invariant: $a<b$ and $\\text{sign}(f(a)) \\neq \\text{sign}(f(b))$\n2. set $m = \\frac{a+b}{2}$ and evaluate $s_m = \\text{sign}(f(m))$\n3. if $s_m == s_a$: $a=m$\n4. if $s_m == s_b$: $b=m$\n5. if $s_m == 0$: we've found the root\n\nnote: you should not use $m = \\frac{a+b}{2}$ because of floating point error: use  $m = a + \\frac{b-a}{2}$\n\n```python\ndef bisection(f, a, b, tolerance):\n    n_steps = np.log2((b - a) / tolerance)\n    s_a, s_b = sign(f(a)), sign(f(b))\n    for i in range(nsteps):\n        m = a + (b - a) / 2\n        s_m = sign(m)\n        if s_m == s_a:\n            a = m\n        else:\n            b = m\n    return m\n```\n\n## conditionings\n\nthe conditioning for evaluating $f(x)$ is approximately $\\vert \\frac{x f'(x)}{f(x)} \\vert$ (taylor expansion) and the absolute error is $\\vert f'(x)\\vert$ when evaluating $f^{-1}$, the conditional number is $\\approx \\vert  \\frac{f(x)}{x f'(x)} \\vert$ aand the absolute error is $\\vert\\frac{1}{f'(x)} \\vert$\n\nas you get a high sensitivity in the inverse, you get a low sensitivity in the inversion and vice-versa. the function doesn't need to have an inverse in order to find the inverse in a local region.\n\nwe're trying to look for $f(x)=0$: when we're close to zero, we never use the relative accuracy but always the absolute one.\n\n## convergence\n\n$e_{k}$ (the error at the $k^{\\text{th}}$ step) $= x_k - x^*$\n\n$$e^k_{rel} = \\frac{e_k}{x^*}  = \\frac{x_k - x^*}{x^*}$$\n\nwe need to look at the number of significant bits, because it's exact unlike significant decimal digits.\n\n\t\"\"\")\n\tst.latex(r\"\"\"\n\\begin{align*}\n\\text{bits/step} &= -\\log_2(e^{k+1}_{rel}) - \\left(-\\log_2(e^k_{rel}) \\right)   \\\\\n& = \\log_2\\left(\\frac{\\frac{x_k - x^*}{x^*}}{\\frac{x_{k+1} - x^*}{x^*}} \\right) \\\\\n& = \\log_2\\left(\\frac{\\vert x_k - x^*\\vert}{\\vert x_{k+1} - x^*\\vert} \\right)   \\\\\n& = \\log_2\\left(\\frac{\\vert e_k\\vert}{\\vert e_{k+1}\\vert}\\right) \t\t\t\t\\\\\n& = -\\log_2\\left(\\frac{\\vert e_{k+1}\\vert}{\\vert e_k\\vert}\\right) \n\\end{align*}\n\"\"\")\n\tst.markdown(r\"\"\"\nif $\\lim_{k\\to 0} \\frac{\\vert e_{k+1}\\vert}{\\vert e_k\\vert^r} = c$, and $0 \\leq c \\lt 1$, method converges with rate r=1 $\\implies$ linear, r=2 $\\implies$ quadratic, etc\n\n## fixed point solvers\n\na systeamtic approach that works (also in n-dimensions). it uses the fixed point theorem: here we'll use _banache's theorem_. it doesn't just hold in a vector space, but even in a metric space.\n\nlet $s$ be  closed set $s \\subseteq \\mathbb{r}^n$\nand $g:\\mathbb{r}^n \\to \\mathbb{r}^n$, if there exists $0\\leq c \\lt 1$ such that\n$$\\vert g(x) - g(x') \\vert \\leq c\\vert x - x'\\vert$$\nfor $x, x' \\in s$, the we call $g$ a _contraction_ on $s$ and we are guaranteed a solution to $g(x)=x$ on $s$, which is\n$$x^k = \\lim_{k \\to \\infty} g^k(x_0)$$\nfor any $x_0 \\in s$\n\nquestion: can we transform \"$f(x)=0$\" to \"$g(x)=x$\"? the answer is yes, it's easy, but most choices are terrible.\n\nfor example, if you pick $g(x) = x - f(x)$, you usually repel solutions. look at example 5-8 in the book, it gives 4 different ways of rewriting, some are repulsors and some attracters.\n\nhow can we make it attractive? let's analyze the error (in 1d, because it's easier):\n\n$$\\vert\\, e_{k+1} \\,\\vert = \\vert\\, x_{k+1} - x^* \\,\\vert $$\n$$ = \\vert\\, x_{k+1} - g(x^*) \\,\\vert $$\n$$ = \\vert\\, g(x_k) - g(x^*) \\,\\vert $$\n\nnow we bring in the _mean value theorem_: $\\exists \\theta \\in [x_{k+1}, x^*]$ for which\n$$ = \\vert\\,g'(\\theta) (x"
    },
    {
      "topicId": "scientific-computing",
      "topicTitle": "Scientific Computing",
      "routeSlug": "scientific-computing",
      "lessonSlug": "partialDifferentialEquations",
      "lessonTitle": "Partial Differential Equations",
      "x": 0.7131413221359253,
      "y": 0.42728886008262634,
      "searchText": "partial differential equations\n# partial differential equations\n\n## classification\n\npartial differential equations (pdes) are classified by the nature of their highest-order terms. a second-order linear pde in two variables has the general form\n\n$$\na u_{xx} + 2b u_{xy} + c u_{yy} + \\text{lower order terms} = 0.\n$$\n\nthe **discriminant** $b^2 - ac$ determines the type:\n\n- **elliptic** ($b^2 - ac < 0$): e.g., laplace equation $\\nabla^2 u = 0$. describes equilibrium states.\n- **parabolic** ($b^2 - ac = 0$): e.g., heat equation $u_t = \\alpha \\nabla^2 u$. describes diffusion processes.\n- **hyperbolic** ($b^2 - ac > 0$): e.g., wave equation $u_{tt} = c^2 \\nabla^2 u$. describes wave propagation.\n\neach type requires different numerical strategies and boundary conditions. elliptic problems need boundary values on the entire domain boundary. parabolic and hyperbolic problems need initial conditions plus boundary conditions.\n\n## finite difference methods\n\nthe fundamental idea is to replace continuous derivatives with **discrete approximations** on a grid. for a uniform grid with spacing $\\delta x$, the standard finite difference formulas are\n\n$$\n\\frac{\\partial u}{\\partial x} \\approx \\frac{u_{i+1} - u_{i-1}}{2\\delta x} \\quad \\text{(central, } o(\\delta x^2)\\text{)},\n$$\n\n$$\n\\frac{\\partial^2 u}{\\partial x^2} \\approx \\frac{u_{i+1} - 2u_i + u_{i-1}}{\\delta x^2} \\quad \\text{(} o(\\delta x^2)\\text{)}.\n$$\n\nthese replace the pde at each interior grid point with an algebraic equation, producing a system of equations that can be solved by linear algebra techniques.\n\n## the heat equation\n\nthe one-dimensional heat equation $u_t = \\alpha u_{xx}$ is the prototypical parabolic pde. the **ftcs scheme** (forward time, central space) discretizes as\n\n$$\n\\frac{u_i^{n+1} - u_i^n}{\\delta t} = \\alpha \\frac{u_{i+1}^n - 2u_i^n + u_{i-1}^n}{\\delta x^2},\n$$\n\ngiving the explicit update\n\n$$\nu_i^{n+1} = u_i^n + r(u_{i+1}^n - 2u_i^n + u_{i-1}^n),\n$$\n\nwhere $r = \\alpha \\delta t / \\delta x^2$. this scheme is **conditionally stable**: the solution blows up unless $r \\leq 1/2$ (the **cfl condition** for this problem).\n\nthe **implicit (backward euler)** scheme evaluates spatial derivatives at the new time level:\n\n$$\nu_i^{n+1} - r(u_{i+1}^{n+1} - 2u_i^{n+1} + u_{i-1}^{n+1}) = u_i^n.\n$$\n\nthis is unconditionally stable but requires solving a tridiagonal linear system at each time step. the **crank-nicolson** scheme averages the explicit and implicit forms, achieving $o(\\delta t^2, \\delta x^2)$ accuracy while remaining unconditionally stable.\n\n## the wave equation\n\nthe one-dimensional wave equation $u_{tt} = c^2 u_{xx}$ is discretized with central differences in both time and space:\n\n$$\n\\frac{u_i^{n+1} - 2u_i^n + u_i^{n-1}}{\\delta t^2} = c^2 \\frac{u_{i+1}^n - 2u_i^n + u_{i-1}^n}{\\delta x^2}.\n$$\n\nthis leapfrog scheme is second-order accurate and stable when the **courant number** satisfies $c = c\\delta t / \\delta x \\leq 1$. the courant condition ensures that the numerical domain of dependence contains the physical domain of dependence.\n\n## elliptic problems\n\nfor laplace's equation $\\nabla^2 u = 0$ on a 2d grid, the five-point stencil gives\n\n$$\nu_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j} = 0.\n$$\n\nthis produces a large sparse linear system $a\\mathbf{u} = \\mathbf{b}$ where boundary values enter through the right-hand side. direct solvers (lu decomposition) work for moderate grids, but **iterative methods** are preferred for large problems:\n\n- **jacobi iteration**: update each point from its neighbors' previous values.\n- **gauss-seidel**: use updated values as soon as available (faster convergence).\n- **successive over-relaxation (sor)**: accelerates gauss-seidel with a relaxation parameter $\\omega$.\n\nfor poisson's equation $\\nabla^2 u = f$, the same stencil applies with $f_{i,j}$ on the right-hand side.\n\n## boundary conditions\n\nthe three standard types are:\n\n- **dirichlet**: $u = g$ on $\\partial\\omega$. the boundary values are known and directly substituted.\n- **neumann**: $\\partial u / \\partial n = g$ on $\\partial\\omega$. discretized using one-sided or ghost-point differences.\n- **robin (mixed)**: $\\alpha u + \\beta \\partial u / \\partial n = g$. combines the above.\n\nghost points outside the domain are a clean way to implement neumann conditions: introduce a fictitious point $u_{-1}$ and use the centered difference $u_1 - u_{-1} = 2\\delta x \\cdot g$ to eliminate it.\n\n## spectral methods\n\nfor problems with smooth solutions and periodic boundary conditions, **spectral methods** represent the solution in a basis of trigonometric functions. the spatial derivative of $u(x) = \\sum_k \\hat{u}_k e^{ikx}$ is computed exactly in fourier space:\n\n$$\n\\frac{\\partial u}{\\partial x} \\longleftrightarrow ik\\hat{u}_k.\n$$\n\nthe **fast fourier transform** (fft) makes this approach computationally efficient with $o(n\\log n)$ operations. spectral methods achieve exponential convergence for smooth solutions, far outperforming finite differences.\n\nfor non-periodic domains, **chebyshev spectral methods** use chebyshev polynomials as the basis, with clustering of grid points near boundaries to handle boundary layers.\n\n[[simulation reaction-diffusion]]\n\n## method of lines\n\nthe **method of lines** (mol) semi-discretizes the pde by replacing spatial derivatives with finite differences while leaving time continuous. this converts the pde into a system of odes:\n\n$$\n\\frac{d\\mathbf{u}}{dt} = \\mathbf{f}(\\mathbf{u}),\n$$\n\nwhich can then be integrated with any ode solver (euler, rk4, bdf). this approach cleanly separates spatial and temporal discretization, allowing established ode solvers to handle time integration including adaptive step size control.\n\n## stability and convergence\n\nthe **lax equivalence theorem** states that for a consistent finite difference scheme applied to a well-posed linear pde, **stability is equivalent to convergence**. this means we only need to verify stability (via von neumann analysis or matrix methods) to guarantee that the numerical solutio"
    }
  ]
}