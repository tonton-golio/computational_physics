# Advanced Deep Learning

A single artificial neuron can only draw a straight line. Stack a few hundred of them, let them talk to each other, and something unreasonable happens: the whole contraption can approximate *any* function you can dream up. Any function. That is not a slogan -- it is a theorem. And yet the theorem tells you nothing about why it actually works in practice, or how to make it work well.

That gap between "in principle" and "in practice" is where the real adventure lives. Give the network convolutional filters and it starts to see edges, textures, objects. Replace convolutions with attention and it can read a sentence, translate a language, caption a photograph. Let two networks compete -- a forger against a detective -- and the forgeries become indistinguishable from reality.

And the deepest mystery of all is still staring at us: why do these giant machines, with far more knobs than data points, refuse to memorize and instead generalize? That is where the real adventure begins.
